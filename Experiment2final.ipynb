{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "PFMM94CvB3OF"
      },
      "outputs": [],
      "source": [
        "!pip install fredapi requests yahoo_fin bs4 tabulate openai==0.28 anthropic google-generativeai rouge_score ace_tools\n",
        "#!pip install llama_cpp_python\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import random\n",
        "from fredapi import Fred\n",
        "import requests\n",
        "from yahoo_fin import news\n",
        "from bs4 import BeautifulSoup\n",
        "from tabulate import tabulate\n",
        "import random\n",
        "import openai\n",
        "import anthropic\n",
        "#from llama_cpp import Llama\n",
        "import google.generativeai as genai\n",
        "import re\n",
        "import random\n",
        "import nltk\n",
        "import pandas as pd\n",
        "from yahoo_fin import news\n",
        "from datetime import datetime, timedelta\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from rouge_score import rouge_scorer\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "#NOTE TO SELF - for testing am just training on 2021 data, and evaluation on 2022 - NEED TO CHANGE for actual data\n",
        "#To change - Time period for training data, time period for evaluation data, list of tickers\n",
        "#Add meta llama or gemini as well\n",
        "#To uncomment - time values for all LLMs; the number of values and number of non-NONE values for each LLM\n",
        "#Possibly add - a feature that compares LLMs predictions for more specific things - e.g, equity types, time periods"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocessing training data for financial news articles\n",
        "nltk_resources = [\"punkt\", \"stopwords\", \"wordnet\"]\n",
        "\n",
        "for resource in nltk_resources:\n",
        "    try:\n",
        "        nltk.data.find(f\"tokenizers/{resource}\")\n",
        "    except LookupError:\n",
        "        print(f\"🔹 Downloading missing NLTK resource: {resource}\")\n",
        "        nltk.download(resource)\n",
        "\n",
        "\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "import re\n",
        "import random\n",
        "import nltk\n",
        "import pandas as pd\n",
        "from yahoo_fin import news\n",
        "from datetime import datetime, timedelta\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# 🔹 Download necessary NLTK resources (only needed once)\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"wordnet\")\n",
        "\n",
        "# 🔹 Initialize NLP components\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# 🔹 List of S&P 500 stock tickers (expandable)\n",
        "sp500_tickers = [\n",
        "    \"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"TSLA\", \"NVDA\", \"FB\", \"JPM\", \"V\", \"DIS\",\n",
        "    \"PG\", \"MA\", \"NFLX\", \"INTC\", \"PYPL\", \"PFE\", \"PEP\", \"KO\", \"CSCO\", \"XOM\",\n",
        "    \"IBM\", \"GE\", \"BA\", \"GS\", \"C\", \"ADBE\", \"NFLX\", \"T\", \"UNH\", \"MRK\",\n",
        "    \"MMM\", \"LMT\", \"MDT\", \"CAT\", \"MO\", \"HON\", \"F\", \"GM\", \"MCD\", \"WMT\",\n",
        "    \"NKE\", \"CVX\", \"TMO\", \"ORCL\", \"DOW\", \"SO\", \"DUK\", \"AEP\", \"USB\", \"MET\",\n",
        "    \"BK\", \"TGT\", \"BLK\", \"SCHW\", \"CME\", \"AON\", \"SPGI\", \"MS\", \"AXP\", \"CI\",\n",
        "    \"ISRG\", \"ZTS\", \"PLD\", \"DE\", \"ADP\", \"SYK\", \"GILD\", \"GM\", \"TFC\", \"CSX\",\n",
        "    \"EL\", \"FDX\", \"EMR\", \"ECL\", \"ADI\", \"MMC\", \"WM\", \"AMT\", \"SLB\", \"AIG\",\n",
        "    \"CTSH\", \"DHR\", \"NSC\", \"COF\", \"DG\", \"FIS\", \"PGR\", \"ITW\", \"CDNS\", \"APD\",\n",
        "    \"AFL\", \"OXY\", \"VLO\", \"HES\", \"PSX\", \"TRGP\", \"MRO\", \"HAL\", \"NEM\", \"BKR\"\n",
        "]\n",
        "sp500_tickers_test = [\n",
        "    \"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"TSLA\", \"NVDA\", \"FB\", \"JPM\", \"V\", \"DIS\"\n",
        "]\n",
        "\n",
        "# 🔹 Function to generate a random date between 2011 and 2021\n",
        "def random_date():\n",
        "    start_date = datetime(2011, 1, 1)\n",
        "    end_date = datetime(2021, 12, 31)\n",
        "    return start_date + timedelta(days=random.randint(0, (end_date - start_date).days))\n",
        "\n",
        "# 🔹 Function to clean and preprocess text\n",
        "def clean_text(text):\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "    words = word_tokenize(text)  # Tokenization\n",
        "    words = [word for word in words if word not in stop_words]  # Remove stopwords\n",
        "    words = [lemmatizer.lemmatize(word) for word in words]  # Lemmatization\n",
        "    return \" \".join(words)\n",
        "\n",
        "# 🔹 Fetch and process financial news for at least 100 random ticker-date pairs\n",
        "news_data = []\n",
        "attempts = 0\n",
        "\n",
        "while len(news_data) < 500 and attempts < 2000:\n",
        "    attempts += 1\n",
        "    ticker = random.choice(sp500_tickers_test)\n",
        "    date = random_date().strftime('%Y-%m-%d')\n",
        "\n",
        "    try:\n",
        "\n",
        "        latest_news = news.get_yf_rss(ticker)\n",
        "\n",
        "        if latest_news:\n",
        "            for article in latest_news[:1]:\n",
        "                title = article[\"title\"]\n",
        "                link = article[\"link\"]\n",
        "                cleaned_title = clean_text(title)\n",
        "\n",
        "                news_data.append({\n",
        "                    \"Ticker\": ticker,\n",
        "                    \"Date\": date,\n",
        "                    \"Original Title\": title,\n",
        "                    \"Cleaned Title\": cleaned_title,\n",
        "                    \"Link\": link\n",
        "                })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Error fetching news for {ticker} on {date}: {e}\")\n",
        "\n",
        "df_news = pd.DataFrame(news_data)\n",
        "\n",
        "import tabulate\n",
        "print(\"\\n📊 Processed Historical Financial News:\\n\")\n",
        "print(tabulate.tabulate(df_news.head(100), headers=\"keys\", tablefmt=\"fancy_grid\"))\n",
        "\n",
        "df_news.to_csv(\"historical_financial_news.csv\", index=False)\n",
        "print(\"Processed financial news saved to 'historical_financial_news.csv'\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "TJ_nfRPODME8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pre-Processing Training Numerical data\n",
        "sp500_tickers = [\n",
        "    \"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"TSLA\", \"NVDA\", \"FB\", \"JPM\", \"V\", \"DIS\",\n",
        "    \"PG\", \"MA\", \"NFLX\", \"INTC\", \"PYPL\", \"PFE\", \"PEP\", \"KO\", \"CSCO\", \"XOM\",\n",
        "    \"IBM\", \"GE\", \"BA\", \"GS\", \"C\", \"ADBE\", \"T\", \"UNH\", \"MRK\", \"MMM\", \"LMT\",\n",
        "    \"MDT\", \"CAT\", \"MO\", \"HON\", \"F\", \"GM\", \"MCD\", \"WMT\", \"NKE\", \"CVX\", \"TMO\",\n",
        "    \"ORCL\", \"DOW\", \"SO\", \"DUK\", \"AEP\", \"USB\", \"MET\", \"BK\", \"TGT\", \"BLK\",\n",
        "    \"SCHW\", \"CME\", \"AON\", \"SPGI\", \"MS\", \"AXP\", \"CI\", \"ISRG\", \"ZTS\", \"PLD\",\n",
        "    \"DE\", \"ADP\", \"SYK\", \"GILD\", \"GM\", \"TFC\", \"CSX\", \"EL\", \"FDX\", \"EMR\",\n",
        "    \"ECL\", \"ADI\", \"MMC\", \"WM\", \"AMT\", \"SLB\", \"AIG\", \"CTSH\", \"DHR\", \"NSC\",\n",
        "    \"COF\", \"DG\", \"FIS\", \"PGR\", \"ITW\", \"CDNS\", \"APD\", \"AFL\", \"OXY\", \"VLO\",\n",
        "    \"HES\", \"PSX\", \"TRGP\", \"MRO\", \"HAL\", \"NEM\", \"BKR\"\n",
        "]\n",
        "\n",
        "sp500_tickers_test = [\n",
        "    \"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"TSLA\", \"NVDA\", \"FB\", \"JPM\", \"V\", \"DIS\"\n",
        "]\n",
        "\n",
        "# 🔹 Define financial features to extract\n",
        "financial_features = [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
        "\n",
        "# 🔹 Time range (matching news dataset: 2011-2021)\n",
        "start_date = \"2011-01-01\"\n",
        "end_date = \"2021-12-31\"\n",
        "\n",
        "# 🔹 Dictionary to store financial data\n",
        "financial_data = []\n",
        "\n",
        "# 🔹 Fetch data for each ticker\n",
        "for ticker in sp500_tickers:\n",
        "    try:\n",
        "        stock = yf.Ticker(ticker)\n",
        "        df = stock.history(start=start_date, end=end_date)\n",
        "\n",
        "        if not df.empty:\n",
        "            df.reset_index(inplace=True)  # Ensure 'Date' is a column\n",
        "            df[\"Ticker\"] = ticker  # Add ticker column\n",
        "\n",
        "            # 🔹 Ensure \"Adj Close\" is available, else use \"Close\"\n",
        "            if \"Adj Close\" in df.columns:\n",
        "                df[\"Adj Close\"] = df[\"Adj Close\"]\n",
        "            else:\n",
        "                df[\"Adj Close\"] = df[\"Close\"]  # Use Close if Adj Close is missing\n",
        "\n",
        "            # 🔹 Select relevant columns\n",
        "            df = df[[\"Date\", \"Ticker\"] + financial_features + [\"Adj Close\"]]\n",
        "\n",
        "            financial_data.append(df)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Error fetching data for {ticker}: {e}\")\n",
        "\n",
        "# 🔹 Combine data into a single DataFrame\n",
        "df_financials = pd.concat(financial_data, ignore_index=True)\n",
        "\n",
        "# ✅ Step 1: Handle Missing Values\n",
        "df_financials.dropna(inplace=True)  # Remove rows with missing values\n",
        "\n",
        "# ✅ Step 2: Convert Date Column to Datetime\n",
        "df_financials[\"Date\"] = pd.to_datetime(df_financials[\"Date\"])\n",
        "\n",
        "# ✅ Step 3: Remove Outliers (Using IQR Method)\n",
        "for column in [\"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\"]:\n",
        "    Q1 = df_financials[column].quantile(0.25)\n",
        "    Q3 = df_financials[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    df_financials = df_financials[(df_financials[column] >= lower_bound) & (df_financials[column] <= upper_bound)]\n",
        "\n",
        "# ✅ Step 4: Normalize Numerical Features (Min-Max Scaling)\n",
        "for column in [\"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\"]:\n",
        "    df_financials[column] = (df_financials[column] - df_financials[column].min()) / (df_financials[column].max() - df_financials[column].min())\n",
        "\n",
        "# ✅ Save Cleaned Numerical Financial Data to CSV\n",
        "df_financials.to_csv(\"financial_forecasting_cleaned.csv\", index=False)\n",
        "print(\"\\n✅ Cleaned financial forecasting data saved to 'financial_forecasting_cleaned.csv'\")\n",
        "\n",
        "df_financials2 = pd.read_csv(\"financial_forecasting_cleaned.csv\")\n",
        "\n",
        "# 🔹 Display the first few rows using tabulate\n",
        "print(\"\\n📊 Cleaned Financial Forecasting Data (2011-2021):\\n\")\n",
        "print(tabulate.tabulate(df_financials.head(20), headers=\"keys\", tablefmt=\"fancy_grid\"))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "bAadKALDVRnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#PreProcessing Evaluation Numerical Data\n",
        "# 🔹 Define test tickers (subset of S&P 500)\n",
        "sp500_tickers_test = [\n",
        "    \"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"TSLA\", \"NVDA\", \"FB\", \"JPM\", \"V\", \"DIS\"\n",
        "]\n",
        "\n",
        "# 🔹 Time range for data collection (2022)\n",
        "start_date = \"2022-01-01\"\n",
        "end_date = \"2024-12-31\"\n",
        "\n",
        "# 🔹 List to store financial data\n",
        "financial_data = []\n",
        "\n",
        "# 🔹 Fetch data for each ticker\n",
        "for ticker in sp500_tickers:\n",
        "    try:\n",
        "        stock = yf.Ticker(ticker)\n",
        "        df = stock.history(start=start_date, end=end_date)\n",
        "\n",
        "        if not df.empty:\n",
        "            df.reset_index(inplace=True)  # Ensure 'Date' is a column\n",
        "            df[\"Ticker\"] = ticker  # Add ticker column\n",
        "\n",
        "            # 🔹 Use \"Adj Close\" if available, else default to \"Close\"\n",
        "            if \"Adj Close\" not in df.columns:\n",
        "                df[\"Adj Close\"] = df[\"Close\"]\n",
        "\n",
        "            # 🔹 Convert Date to YYYY-MM-DD format\n",
        "            df[\"Date\"] = df[\"Date\"].dt.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "            # 🔹 Select relevant columns (Ticker, Date, Adjusted Close Price)\n",
        "            df = df[[\"Ticker\", \"Date\", \"Adj Close\"]]\n",
        "\n",
        "            financial_data.append(df)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Error fetching data for {ticker}: {e}\")\n",
        "\n",
        "# 🔹 Combine data into a single DataFrame\n",
        "df_financials = pd.concat(financial_data, ignore_index=True)\n",
        "\n",
        "# ✅ Step 1: Handle Missing Values\n",
        "df_financials.dropna(inplace=True)  # Remove rows with missing values\n",
        "\n",
        "# ✅ Save Cleaned Financial Data to CSV (only Ticker, Date, Adj Close)\n",
        "csv_path = \"financial_forecasting_cleaned_two.csv\"\n",
        "df_financials.to_csv(csv_path, index=False)\n",
        "print(f\"\\n✅ Cleaned financial forecasting data saved to '{csv_path}'\")\n",
        "\n",
        "# 🔹 Display first few rows\n",
        "print(\"\\n📊 Cleaned Financial Forecasting Data:\\n\")\n",
        "print(tabulate.tabulate(df_financials.head(20), headers=\"keys\", tablefmt=\"fancy_grid\"))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "YS52NG81l0Ub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sorting numerical and textual data based on ticker\n",
        "import pandas as pd\n",
        "from tabulate import tabulate\n",
        "\n",
        "# 🔹 Load financial news dataset (Experiment 1)\n",
        "df_news = pd.read_csv(\"historical_financial_news.csv\")\n",
        "\n",
        "# 🔹 Load numerical financial data (Experiment 2)\n",
        "df_financials = pd.read_csv(\"financial_forecasting_cleaned.csv\")\n",
        "df_financials2 = pd.read_csv(\"financial_forecasting_cleaned_two.csv\")\n",
        "\n",
        "# 🔹 Convert Date column to datetime format in both datasets\n",
        "df_news[\"Date\"] = pd.to_datetime(df_news[\"Date\"])\n",
        "df_financials[\"Date\"] = pd.to_datetime(df_financials[\"Date\"])\n",
        "df_financials2[\"Date\"] = pd.to_datetime(df_financials2[\"Date\"])\n",
        "# 🔹 Sort each dataset by Ticker and Date\n",
        "df_news_sorted = df_news.sort_values(by=[\"Ticker\", \"Date\"])\n",
        "df_financials_sorted = df_financials.sort_values(by=[\"Ticker\", \"Date\"])\n",
        "df_financials2_sorted = df_financials2.sort_values(by=[\"Ticker\", \"Date\"])\n",
        "# ✅ Save sorted datasets to separate CSVs\n",
        "df_news_sorted.to_csv(\"sorted_financial_news.csv\", index=False)\n",
        "df_financials_sorted.to_csv(\"sorted_financial_numerical_data.csv\", index=False)\n",
        "df_financials_sorted.to_csv(\"sorted_financial_numerical_data_two.csv\", index=False)\n",
        "\n",
        "print(\"\\n✅ Financial news sorted by Ticker and Date saved as 'sorted_financial_news.csv'\")\n",
        "print(\"✅ Numerical financial data sorted by Ticker and Date saved as 'sorted_financial_numerical_data.csv'\")\n",
        "\n",
        "# 📊 Display first few rows of each dataset\n",
        "print(\"\\n📊 Sorted Financial News Data:\\n\")\n",
        "print(tabulate(df_news_sorted.head(20), headers=\"keys\", tablefmt=\"fancy_grid\"))\n",
        "\n",
        "print(\"\\n📊 Sorted Numerical Financial Data:\\n\")\n",
        "print(tabulate(df_financials_sorted.head(20), headers=\"keys\", tablefmt=\"fancy_grid\"))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "9jOeDY5eYlOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Time series alignment of numerical and textual data simultaneously\n",
        "\n",
        "# 🔹 Load the sorted numerical financial data\n",
        "df_financials = pd.read_csv(\"sorted_financial_numerical_data.csv\")\n",
        "\n",
        "# 🔹 Load the sorted financial news data\n",
        "df_news = pd.read_csv(\"sorted_financial_news.csv\")\n",
        "\n",
        "# 🔹 Convert Date column to datetime format in both datasets\n",
        "df_financials[\"Date\"] = pd.to_datetime(df_financials[\"Date\"])\n",
        "df_news[\"Date\"] = pd.to_datetime(df_news[\"Date\"])\n",
        "\n",
        "# 🔹 Create a list to store ordered rows (numerical data followed by news articles)\n",
        "merged_data = []\n",
        "\n",
        "# 🔹 Iterate through each unique ticker\n",
        "for ticker in df_financials[\"Ticker\"].unique():\n",
        "    # 🔹 Filter financial and news data for the current ticker\n",
        "    financial_subset = df_financials[df_financials[\"Ticker\"] == ticker]\n",
        "    news_subset = df_news[df_news[\"Ticker\"] == ticker]\n",
        "\n",
        "    # 🔹 Iterate through each row in financial data\n",
        "    for _, fin_row in financial_subset.iterrows():\n",
        "        merged_data.append(fin_row.to_dict())  # Append financial row first\n",
        "\n",
        "        # 🔹 Find matching news articles by date\n",
        "        matching_news = news_subset[news_subset[\"Date\"] == fin_row[\"Date\"]]\n",
        "        for _, news_row in matching_news.iterrows():\n",
        "            merged_data.append(news_row.to_dict())  # Append matching news article\n",
        "\n",
        "# 🔹 Convert ordered list into DataFrame\n",
        "df_ordered = pd.DataFrame(merged_data)\n",
        "\n",
        "# ✅ Save the final dataset\n",
        "df_ordered.to_csv(\"ordered_financial_data.csv\", index=False)\n",
        "print(\"\\n✅ Ordered dataset with numerical data followed by matching news saved as 'ordered_financial_data.csv'\")\n",
        "\n",
        "# 📊 Display the first few rows of the final dataset\n",
        "print(\"\\n📊 Ordered Financial Data:\\n\")\n",
        "print(tabulate(df_ordered.head(20), headers=\"keys\", tablefmt=\"fancy_grid\"))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "l3vQlQubeq9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sentiment analysis\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "df_news = pd.read_csv(\"sorted_financial_news.csv\")\n",
        "\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "df_news[\"Sentiment Score\"] = df_news[\"Cleaned Title\"].apply(lambda text: sia.polarity_scores(str(text))[\"compound\"])\n",
        "\n",
        "df_news[\"Sentiment\"] = df_news[\"Sentiment Score\"].apply(\n",
        "    lambda score: \"Positive\" if score > 0.05 else \"Negative\" if score < -0.05 else \"Neutral\"\n",
        ")\n",
        "\n",
        "print(\"\\n📊 VADER Sentiment Analysis Results:\\n\")\n",
        "print(df_news[[\"Ticker\", \"Date\", \"Cleaned Title\", \"Sentiment Score\", \"Sentiment\"]].head(10))\n",
        "\n",
        "df_news.to_csv(\"vader_sentiment_analysis_results.csv\", index=False)\n",
        "print(\"\\n✅ Sentiment analysis results saved to 'vader_sentiment_analysis_results.csv'\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "GpZjPaZ2f-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "# 🔹 Load the ordered financial dataset and VADER sentiment analysis results\n",
        "df_ordered = pd.read_csv(\"ordered_financial_data.csv\")\n",
        "df_vader = pd.read_csv(\"vader_sentiment_analysis_results.csv\")\n",
        "\n",
        "# 🔹 Convert Date column to datetime format\n",
        "df_ordered[\"Date\"] = pd.to_datetime(df_ordered[\"Date\"])\n",
        "df_vader[\"Date\"] = pd.to_datetime(df_vader[\"Date\"])\n",
        "\n",
        "# 🔹 Manually align sentiment scores by iterating through the datasets\n",
        "sentiment_scores = []\n",
        "close_prices = []\n",
        "\n",
        "for index, row in df_ordered.iterrows():\n",
        "    ticker = row[\"Ticker\"]\n",
        "    date = row[\"Date\"]\n",
        "\n",
        "    # Find matching sentiment score in df_vader\n",
        "    sentiment_row = df_vader[(df_vader[\"Ticker\"] == ticker) & (df_vader[\"Date\"] == date)]\n",
        "\n",
        "    if not sentiment_row.empty:\n",
        "        sentiment_scores.append(sentiment_row[\"Sentiment Score\"].values[0])\n",
        "        close_prices.append(row[\"Close\"])\n",
        "\n",
        "# 🔹 Ensure lists have values before computing correlation\n",
        "if len(sentiment_scores) > 1 and len(close_prices) > 1:\n",
        "    pearson_corr, _ = pearsonr(sentiment_scores, close_prices)\n",
        "else:\n",
        "    pearson_corr = None\n",
        "\n",
        "# 📊 Plot Stock Performance vs. Sentiment Trends\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.scatterplot(x=sentiment_scores, y=close_prices, alpha=0.6)\n",
        "plt.title(f\"Stock Close Price vs. VADER Sentiment Trends (Correlation: {pearson_corr:.2f})\" if pearson_corr else \"Stock Close Price vs. VADER Sentiment Trends\")\n",
        "plt.xlabel(\"VADER Sentiment Score (-1: Negative, 0: Neutral, +1: Positive)\")\n",
        "plt.ylabel(\"Stock Close Price\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# ✅ Display correlation result\n",
        "if pearson_corr:\n",
        "    print(f\"\\n✅ Pearson Correlation between VADER Sentiment & Stock Close Price: {pearson_corr:.2f}\")\n",
        "else:\n",
        "    print(\"\\n⚠️ Not enough data points to compute Pearson Correlation.\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "x2hEjf_gfZwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the date range from January to June 2022 (trialed on small dataset) - changed to Jan 2022 to Dec 2024 for evaluation\n",
        "date_range = pd.date_range(start=\"2022-01-01\", end=\"2024-12-31\", freq='D')\n",
        "\n",
        "# Create a DataFrame\n",
        "df_dates = pd.DataFrame(date_range, columns=[\"Date\"])\n",
        "\n",
        "# Save to CSV\n",
        "df_dates.to_csv(\"dates_jan_jun_2022.csv\", index=False)\n",
        "\n",
        "print(\"\\n✅ CSV file 'dates_jan_jun_2022.csv' created successfully!\")"
      ],
      "metadata": {
        "id": "UH6CT8fkM6EY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the financial data (Ensure the correct file path)\n",
        "df_financials = pd.read_csv(\"sorted_financial_numerical_data.csv\")\n",
        "\n",
        "# Extract unique tickers\n",
        "tickers = [\n",
        "    \"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"TSLA\", \"NVDA\", \"FB\", \"JPM\", \"V\", \"DIS\"\n",
        "]\n",
        "tickers_new = [\n",
        "    \"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"TSLA\", \"NVDA\", \"FB\", \"JPM\", \"V\", \"DIS\",\n",
        "    \"PG\", \"MA\", \"NFLX\", \"INTC\", \"PYPL\", \"PFE\", \"PEP\", \"KO\", \"CSCO\", \"XOM\",\n",
        "    \"IBM\", \"GE\", \"BA\", \"GS\", \"C\", \"ADBE\", \"NFLX\", \"T\", \"UNH\", \"MRK\",\n",
        "    \"MMM\", \"LMT\", \"MDT\", \"CAT\", \"MO\", \"HON\", \"F\", \"GM\", \"MCD\", \"WMT\",\n",
        "    \"NKE\", \"CVX\", \"TMO\", \"ORCL\", \"DOW\", \"SO\", \"DUK\", \"AEP\", \"USB\", \"MET\",\n",
        "    \"BK\", \"TGT\", \"BLK\", \"SCHW\", \"CME\", \"AON\", \"SPGI\", \"MS\", \"AXP\", \"CI\",\n",
        "    \"ISRG\", \"ZTS\", \"PLD\", \"DE\", \"ADP\", \"SYK\", \"GILD\", \"GM\", \"TFC\", \"CSX\",\n",
        "    \"EL\", \"FDX\", \"EMR\", \"ECL\", \"ADI\", \"MMC\", \"WM\", \"AMT\", \"SLB\", \"AIG\",\n",
        "    \"CTSH\", \"DHR\", \"NSC\", \"COF\", \"DG\", \"FIS\", \"PGR\", \"ITW\", \"CDNS\", \"APD\",\n",
        "    \"AFL\", \"OXY\", \"VLO\", \"HES\", \"PSX\", \"TRGP\", \"MRO\", \"HAL\", \"NEM\", \"BKR\"\n",
        "]\n",
        "\n",
        "# Create a DataFrame\n",
        "df_tickers = pd.DataFrame(tickers_new, columns=[\"Ticker\"])\n",
        "\n",
        "# Save to CSV\n",
        "df_tickers.to_csv(\"ticker_list.csv\", index=False)\n",
        "\n",
        "print(\"\\n✅ CSV file 'ticker_list.csv' created successfully!\")"
      ],
      "metadata": {
        "id": "lWbP4ANVQn8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training of Anthropic Claude using Chain-of-Thought prompting and Reinforcement Learning\n",
        "\n",
        "# 🔹 Load the sorted financial news and numerical stock data\n",
        "df_news = pd.read_csv(\"sorted_financial_news.csv\")\n",
        "df_financials = pd.read_csv(\"sorted_financial_numerical_data.csv\")\n",
        "df_financials2 = pd.read_csv(\"sorted_financial_numerical_data_two.csv\")\n",
        "# 🔹 Convert Date column to datetime format\n",
        "df_news[\"Date\"] = pd.to_datetime(df_news[\"Date\"])\n",
        "df_financials[\"Date\"] = pd.to_datetime(df_financials[\"Date\"])\n",
        "df_financials2[\"Date\"] = pd.to_datetime(df_financials2[\"Date\"])\n",
        "# 🔹 Initialize Anthropic Claude API\n",
        "CLAUDE_API_KEY = \"\"  # Replace with your actual API key\n",
        "client = anthropic.Anthropic(api_key=CLAUDE_API_KEY)\n",
        "\n",
        "# ✅ Step 1: Sentiment Prediction (Save to CSV)\n",
        "sentiment_results = []\n",
        "begin = time.time()\n",
        "sentiment_prompt_template = \"\"\"\n",
        "You are an AI trained for financial sentiment analysis.\n",
        "You will, in the future, be prompted to perform predictions on financial information.\n",
        "Analyze the financial news article below and assign a sentiment score between -1 (Negative), 0 (Neutral), and +1 (Positive).\n",
        "Use the sentiment of these articles, and their dates, to assist you in your predictions further down the line.\n",
        "\n",
        "Article: \"{article}\"\n",
        "---\n",
        "Final Answer: [Numeric Sentiment Score]\n",
        "\"\"\"\n",
        "\n",
        "for index, row in df_news.iterrows():\n",
        "    ticker = row[\"Ticker\"]\n",
        "    date = row[\"Date\"]\n",
        "    article_text = row[\"Cleaned Title\"]\n",
        "\n",
        "    # Format sentiment prompt\n",
        "    formatted_prompt = sentiment_prompt_template.format(article=article_text)\n",
        "\n",
        "    # Query Claude for sentiment analysis\n",
        "    response = client.messages.create(\n",
        "        model=\"claude-3-7-sonnet-20250219\",\n",
        "        max_tokens=50,\n",
        "        temperature=0.5,\n",
        "        messages=[{\"role\": \"user\", \"content\": formatted_prompt}]\n",
        "    )\n",
        "\n",
        "    # Extract sentiment prediction\n",
        "    response_text = response.content[0].text\n",
        "    try:\n",
        "        predicted_sentiment = float(response_text.split(\"Final Answer: \")[-1].strip())\n",
        "    except ValueError:\n",
        "        predicted_sentiment = None\n",
        "\n",
        "    # Store result\n",
        "    sentiment_results.append({\"Ticker\": ticker, \"Date\": date, \"Sentiment Score\": predicted_sentiment})\n",
        "\n",
        "# Save sentiment predictions to CSV\n",
        "df_sentiment = pd.DataFrame(sentiment_results)\n",
        "df_sentiment.to_csv(\"claude_sentiment_predictions.csv\", index=False)\n",
        "print(\"\\n✅ Sentiment analysis results saved to 'claude_sentiment_predictions.csv'\")\n",
        "\n",
        "# ✅ Step 2: Stock Price Prediction with Reinforcement Learning\n",
        "reward_score = 0  # Start with neutral reward\n",
        "\n",
        "stock_prediction_prompt_template = \"\"\"\n",
        "You are an AI trained for financial market forecasting.\n",
        "Analyze the given financial data and predict the next day's closing stock price step by step. Limit your answer to 500 characters.\n",
        "You have already been fed financial news articles pertinent to the time period of the given financial data.\n",
        "If possible, use that information as well\n",
        "\n",
        "1. **Identify Historical Market Trends**: Examine the last few days' price trends.\n",
        "2. **Assess Trading Volume**: Identify how volume has impacted price changes.\n",
        "3. **Compare Market Conditions**: Identify macro trends affecting the asset.\n",
        "4. **Compute Expected Price Movement**: Use past patterns to estimate the next day's close price.\n",
        "5. **Justify Your Prediction**: Explain why the predicted price movement is logical.\n",
        "\n",
        "Based on your analysis, provide an explanation.\n",
        "Additionally, if the date is the last date of the month, provide the predicted next-day closing stock price.\n",
        "Only provide a numerical value for the predicted next-day closing stock price.\n",
        "If you are providing a predicted next-day closing stock price, please do so in the format -> Predicted Next-Day Close Price: NUM.\n",
        "---\n",
        "Ticker: {ticker}\n",
        "Date: {date}\n",
        "Previous Close: {prev_close}\n",
        "\n",
        "Final Prediction:\n",
        "- **Explanation** → [Detailed reasoning]\n",
        "- **Predicted Next-Day Close Price** → [Numeric value]\n",
        "\"\"\"\n",
        "\n",
        "for index in range(len(df_financials) - 1):  # Iterate through financial data\n",
        "    row_financials = df_financials.iloc[index]\n",
        "    print(row_financials)\n",
        "    ticker = row_financials[\"Ticker\"]\n",
        "    date = row_financials[\"Date\"]\n",
        "    prev_close = row_financials[\"Adj Close\"]\n",
        "\n",
        "    # Format the stock prediction prompt\n",
        "    formatted_prompt = stock_prediction_prompt_template.format(\n",
        "        ticker=ticker, date=date, prev_close=prev_close\n",
        "    )\n",
        "\n",
        "    # Send the prompt to Claude AI\n",
        "    response = client.messages.create(\n",
        "        model=\"claude-3-7-sonnet-20250219\",\n",
        "        max_tokens=500,\n",
        "        temperature=0.5,\n",
        "        messages=[{\"role\": \"user\", \"content\": formatted_prompt}]\n",
        "    )\n",
        "    print(\"Response: \" + str(response))\n",
        "    # Extract Claude's predicted next-day close price\n",
        "    response_text = response.content[0].text\n",
        "    try:\n",
        "        predicted_close = float(response_text.split(\"Predicted Next-Day Close Price: \")[-1].strip())\n",
        "    except ValueError:\n",
        "        predicted_close = None\n",
        "\n",
        "    # Get the actual next-day stock close price\n",
        "    next_day_financials = df_financials[\n",
        "        (df_financials[\"Ticker\"] == ticker) & (df_financials[\"Date\"] == date + pd.Timedelta(days=1))\n",
        "    ]\n",
        "\n",
        "    if next_day_financials.empty or predicted_close is None:\n",
        "        continue  # Skip if no next-day data or prediction failed\n",
        "\n",
        "    actual_close = next_day_financials[\"Adj Close\"].values[0]\n",
        "\n",
        "    # 🔹 Compute reward/penalty based on prediction accuracy (Mean Squared Error approach)\n",
        "    error = abs(predicted_close - actual_close)\n",
        "    reward_score -= error  # Penalize large errors, reward small errors\n",
        "\n",
        "    # 🔹 Update Prompt for Next Iteration Based on Reinforcement Learning\n",
        "    if reward_score < -1:\n",
        "        formatted_prompt += \"\\n\\n⚠️ Previous predictions had large errors. Pay closer attention to price trends.\"\n",
        "    elif reward_score > 1:\n",
        "        formatted_prompt += \"\\n\\n✅ Previous predictions have been accurate. Continue applying the same logic.\"\n",
        "\n",
        "    # 🔹 Print results\n",
        "    print(f\"✅ {ticker} - {date}\")\n",
        "    print(f\"🔹 Predicted Close: {predicted_close}\")\n",
        "    print(f\"🔹 Actual Close: {actual_close}\")\n",
        "    print(f\"🔹 Prediction Error: {error:.2f}\")\n",
        "    print(f\"🔹 Reward Score: {reward_score}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "print(\"\\n✅ Training complete! Claude AI has processed financial news for sentiment and adapted stock price forecasting using reinforcement learning.\")\n",
        "\n",
        "predictions = []\n",
        "explanations = []\n",
        "\n",
        "stock_prediction_two_prompt_template = \"\"\"\n",
        "You are an AI trained for financial market forecasting.\n",
        "You have already been fed with financial news articles and numerical data for the year 2021, and were trained to make accurate predictions.\n",
        "Now, you will be fed with dates from 2022 and be asked to use your prior knowledge and training to make predictions.\n",
        "Using the knowledge gained from previous financial data, predict the closing stock price for the given dates.\n",
        "\n",
        "1. **Identify Historical Market Trends**: Examine previous trends based on past learned patterns.\n",
        "2. **Assess Trading Volume**: Identify how volume has impacted price changes.\n",
        "3. **Compare Market Conditions**: Consider economic trends that could affect stock price movement.\n",
        "4. **Compute Expected Price Movement**: Estimate the likely close price for the given date.\n",
        "5. **Justify Your Prediction**: Explain why the predicted price movement is logical.\n",
        "\n",
        "Based on your analysis, provide an explanation.\n",
        "Only provide the predicted closing stock price in the format -> Predicted Close Price: NUM.\n",
        "---\n",
        "Ticker: {ticker}\n",
        "Date: {date}\n",
        "\n",
        "Final Prediction:\n",
        "- **Explanation** → [Detailed reasoning]\n",
        "- **Predicted Close Price** → [Numeric value]\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# ✅ Step 3: Predict Closing Prices for January - June 2022\n",
        "print(\"\\n🚀 Now predicting closing prices for January - June 2022...\")\n",
        "# Iterate through all tickers and all dates between Jan and June 2022\n",
        "\n",
        "df_dates = pd.read_csv(\"dates_jan_jun_2022.csv\", dtype={\"Date\": str})\n",
        "\n",
        "tickers = [\n",
        "    \"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"TSLA\", \"NVDA\", \"FB\", \"JPM\", \"V\", \"DIS\"\n",
        "]\n",
        "numofClaudeValues = 0\n",
        "numofactualCValues = 0\n",
        "for ticker in tickers:\n",
        "\n",
        "    for date in df_dates[\"Date\"]:\n",
        "        numofClaudeValues = numofClaudeValues + 1\n",
        "        # Format the stock prediction prompt\n",
        "        formatted_prompt = stock_prediction_two_prompt_template.format(\n",
        "            ticker=ticker, date=date\n",
        "        )\n",
        "\n",
        "        # Send the prompt to Claude AI\n",
        "        response = client.messages.create(\n",
        "            model=\"claude-3-7-sonnet-20250219\",\n",
        "            max_tokens=500,\n",
        "            temperature=0.5,\n",
        "            messages=[{\"role\": \"user\", \"content\": formatted_prompt}]\n",
        "        )\n",
        "\n",
        "        # Extract Claude's predicted closing price\n",
        "        response_text = response.content[0].text\n",
        "        try:\n",
        "            predicted_close = float(response_text.split(\"Predicted Close Price: \")[-1].strip())\n",
        "            numofactualCValues = numofactualCValues + 1\n",
        "        except ValueError:\n",
        "            predicted_close = None\n",
        "\n",
        "        explanation = response_text.split(\"Final Prediction:\\n- **Explanation** → \")[-1].split(\"\\n- **Predicted Close Price**\")[0].strip()\n",
        "\n",
        "        # Store results\n",
        "        predictions.append({\n",
        "            \"Ticker\": ticker,\n",
        "            \"Date\": date,\n",
        "            \"Predicted Close Price\": predicted_close\n",
        "        })\n",
        "\n",
        "        explanations.append({\n",
        "            \"Ticker\": ticker,\n",
        "            \"Date\": date,\n",
        "            \"Explanation\": explanation\n",
        "        })\n",
        "\n",
        "        # Print progress\n",
        "        print(f\"✅ Predicted for {ticker} on {date}: {predicted_close}\")\n",
        "\n",
        "time.sleep(1)\n",
        "end = time.time()\n",
        "totalClaudetime = (end-begin)\n",
        "# 🔹 Save predictions to CSV\n",
        "df_predictions = pd.DataFrame(predictions)\n",
        "df_predictions.to_csv(\"claude_predictions_jan_jun_2022.csv\", index=False)\n",
        "df_explanations = pd.DataFrame(explanations)\n",
        "df_explanations.to_csv(\"claude_explanations_jan_jun_2022.csv\", index=False)\n",
        "\n",
        "print(\"\\n✅ Predictions saved to 'claude_predictions_jan_jun_2022.csv'\")\n",
        "print(\"\\n✅ Explanations saved to 'claude_explanations_jan_jun_2022.csv'\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "pGaqmEzyg4HN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training of ChatGPT using Chain-of-Thought Prompting and Reinforcement Learning\n",
        "\n",
        "\n",
        "# 🔹 Load the sorted financial news and numerical stock data\n",
        "df_news = pd.read_csv(\"sorted_financial_news.csv\")\n",
        "df_financials = pd.read_csv(\"sorted_financial_numerical_data.csv\")\n",
        "df_financials2 = pd.read_csv(\"sorted_financial_numerical_data_two.csv\")\n",
        "# 🔹 Convert Date column to datetime format\n",
        "df_news[\"Date\"] = pd.to_datetime(df_news[\"Date\"])\n",
        "df_financials[\"Date\"] = pd.to_datetime(df_financials[\"Date\"])\n",
        "df_financials2[\"Date\"] = pd.to_datetime(df_financials2[\"Date\"])\n",
        "\n",
        "OPENAI_API_KEY = ''\n",
        "openai.api_key = OPENAI_API_KEY\n",
        "\n",
        "\n",
        "sentiment_results = []\n",
        "begin = time.time()\n",
        "sentiment_prompt_template = \"\"\"\n",
        "You are an AI trained for financial sentiment analysis.\n",
        "You will, in the future, be prompted to perform predictions on financial information.\n",
        "Analyze the financial news article below and assign a sentiment score between -1 (Negative), 0 (Neutral), and +1 (Positive).\n",
        "Use the sentiment of these articles, and their dates, to assist you in your predictions further down the line.\n",
        "Article: \"{article}\"\n",
        "---\n",
        "Final Answer: [Numeric Sentiment Score]\n",
        "\"\"\"\n",
        "\n",
        "for index, row in df_news.iterrows():\n",
        "    ticker = row[\"Ticker\"]\n",
        "    date = row[\"Date\"]\n",
        "    article_text = row[\"Cleaned Title\"]\n",
        "\n",
        "    # Format sentiment prompt\n",
        "    formatted_prompt = sentiment_prompt_template.format(article=article_text)\n",
        "\n",
        "    # Query GPT-4 for sentiment analysis\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[{\"role\": \"user\", \"content\": formatted_prompt}],\n",
        "        max_tokens=50,\n",
        "        temperature=0.5\n",
        "    )\n",
        "\n",
        "    # Extract sentiment prediction\n",
        "    response_text = response[\"choices\"][0][\"message\"][\"content\"]\n",
        "    try:\n",
        "        predicted_sentiment = float(response_text.split(\"Final Answer: \")[-1].strip())\n",
        "    except ValueError:\n",
        "        predicted_sentiment = None\n",
        "\n",
        "    # Store result\n",
        "    sentiment_results.append({\"Ticker\": ticker, \"Date\": date, \"Sentiment Score\": predicted_sentiment})\n",
        "\n",
        "# Save sentiment predictions to CSV\n",
        "df_sentiment = pd.DataFrame(sentiment_results)\n",
        "df_sentiment.to_csv(\"gpt_sentiment_predictions.csv\", index=False)\n",
        "print(\"\\n✅ Sentiment analysis results saved to 'gpt_sentiment_predictions.csv'\")\n",
        "\n",
        "# ✅ Step 2: Stock Price Prediction with Reinforcement Learning\n",
        "reward_score = 0\n",
        "\n",
        "stock_prediction_prompt_template = \"\"\"\n",
        "You are an AI trained for financial market forecasting.\n",
        "Analyze the given financial data and predict the next day's closing stock price step by step. Limit your answer to 500 characters.\n",
        "You have already been fed financial news articles pertinent to the time period of the given financial data.\n",
        "If possible, use that information as well.\n",
        "\n",
        "1. **Identify Historical Market Trends**: Examine the last few days' price trends.\n",
        "2. **Assess Trading Volume**: Identify how volume has impacted price changes.\n",
        "3. **Compare Market Conditions**: Identify macro trends affecting the asset.\n",
        "4. **Compute Expected Price Movement**: Use past patterns to estimate the next day's close price.\n",
        "5. **Justify Your Prediction**: Explain why the predicted price movement is logical.\n",
        "\n",
        "Based on your analysis, provide an explanation.\n",
        "Additionally, if the date is the last date of the month, provide the predicted next-day closing stock price.\n",
        "Only provide a numerical value for the predicted next-day closing stock price.\n",
        "If you are providing a predicted next-day closing stock price, please do so in the format -> Predicted Next-Day Close Price: NUM.\n",
        "---\n",
        "Ticker: {ticker}\n",
        "Date: {date}\n",
        "Previous Close: {prev_close}\n",
        "\n",
        "Final Prediction:\n",
        "- **Explanation** → [Detailed reasoning]\n",
        "- **Predicted Next-Day Close Price** → [Numeric value]\n",
        "\"\"\"\n",
        "\n",
        "for index in range(len(df_financials) - 1):  # Iterate through financial data\n",
        "    row_financials = df_financials.iloc[index]\n",
        "\n",
        "    ticker = row_financials[\"Ticker\"]\n",
        "    date = row_financials[\"Date\"]\n",
        "    prev_close = row_financials[\"Adj Close\"]\n",
        "\n",
        "    # Format the stock prediction prompt\n",
        "    formatted_prompt = stock_prediction_prompt_template.format(\n",
        "        ticker=ticker, date=date, prev_close=prev_close\n",
        "    )\n",
        "\n",
        "    # Send the prompt to GPT-4\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[{\"role\": \"user\", \"content\": formatted_prompt}],\n",
        "        max_tokens=500,\n",
        "        temperature=0.5\n",
        "    )\n",
        "\n",
        "    # Extract GPT-4's predicted next-day close price\n",
        "    response_text = response[\"choices\"][0][\"message\"][\"content\"]\n",
        "    try:\n",
        "        predicted_close = float(response_text.split(\"Predicted Next-Day Close Price: \")[-1].strip())\n",
        "    except ValueError:\n",
        "        predicted_close = None\n",
        "\n",
        "    # Get the actual next-day stock close price\n",
        "    next_day_financials = df_financials[\n",
        "        (df_financials[\"Ticker\"] == ticker) & (df_financials[\"Date\"] == date + pd.Timedelta(days=1))\n",
        "    ]\n",
        "\n",
        "    if next_day_financials.empty or predicted_close is None:\n",
        "        continue  # Skip if no next-day data or prediction failed\n",
        "\n",
        "    actual_close = next_day_financials[\"Adj Close\"].values[0]\n",
        "\n",
        "    # 🔹 Compute reward/penalty based on prediction accuracy (Mean Squared Error approach)\n",
        "    error = abs(predicted_close - actual_close)\n",
        "    reward_score -= error  # Penalize large errors, reward small errors\n",
        "\n",
        "    # 🔹 Update Prompt for Next Iteration Based on Reinforcement Learning\n",
        "    if reward_score < -1:\n",
        "        formatted_prompt += \"\\n\\n⚠️ Previous predictions had large errors. Pay closer attention to price trends.\"\n",
        "    elif reward_score > 1:\n",
        "        formatted_prompt += \"\\n\\n✅ Previous predictions have been accurate. Continue applying the same logic.\"\n",
        "\n",
        "    # 🔹 Print results\n",
        "    print(f\"✅ {ticker} - {date}\")\n",
        "    print(f\"🔹 Predicted Close: {predicted_close}\")\n",
        "    print(f\"🔹 Actual Close: {actual_close}\")\n",
        "    print(f\"🔹 Prediction Error: {error:.2f}\")\n",
        "    print(f\"🔹 Reward Score: {reward_score}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "print(\"\\n✅ Training complete! GPT-4 has processed financial news for sentiment and adapted stock price forecasting using reinforcement learning.\")\n",
        "\n",
        "\n",
        "\n",
        "predictions = []\n",
        "explanations = []\n",
        "\n",
        "stock_prediction_two_prompt_template = \"\"\"\n",
        "You are an AI trained for financial market forecasting.\n",
        "You have already been fed with financial news articles and numerical data for the year 2021, and were trained to make accurate predictions.\n",
        "Now, you will be fed with dates from 2022 and be asked to use your prior knowledge and training to make predictions.\n",
        "Using the knowledge gained from previous financial data, predict the closing stock price for the given dates.\n",
        "\n",
        "1. **Identify Historical Market Trends**: Examine previous trends based on past learned patterns.\n",
        "2. **Assess Trading Volume**: Identify how volume has impacted price changes.\n",
        "3. **Compare Market Conditions**: Consider economic trends that could affect stock price movement.\n",
        "4. **Compute Expected Price Movement**: Estimate the likely close price for the given date.\n",
        "5. **Justify Your Prediction**: Explain why the predicted price movement is logical.\n",
        "\n",
        "Based on your analysis, provide an explanation.\n",
        "Only provide the predicted closing stock price in the format -> Predicted Close Price: NUM.\n",
        "---\n",
        "Ticker: {ticker}\n",
        "Date: {date}\n",
        "\n",
        "Final Prediction:\n",
        "- **Explanation** → [Detailed reasoning]\n",
        "- **Predicted Close Price** → [Numeric value]\n",
        "\"\"\"\n",
        "#tickers = [\n",
        "#    \"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"TSLA\", \"NVDA\", \"FB\", \"JPM\", \"V\", \"DIS\"\n",
        "#]\n",
        "\n",
        "\n",
        "print(\"\\n🚀 Now predicting closing prices for January - June 2022...\")\n",
        "numofGPTvalues = 0\n",
        "numofactualvalues = 0\n",
        "for ticker in tickers:\n",
        "    for date in df_dates[\"Date\"]:\n",
        "        numofGPTvalues = numofGPTvalues + 1\n",
        "        # Format the stock prediction prompt\n",
        "        formatted_prompt = stock_prediction_two_prompt_template.format(\n",
        "            ticker=ticker, date=date\n",
        "        )\n",
        "\n",
        "        # Send the prompt to OpenAI GPT-4\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-4o\",\n",
        "            messages=[{\"role\": \"user\", \"content\": formatted_prompt}],\n",
        "            max_tokens=500,\n",
        "            temperature=0.5\n",
        "        )\n",
        "\n",
        "\n",
        "        # Extract GPT-4's predicted closing price\n",
        "        response_text = response[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "        try:\n",
        "            predicted_close = float(response_text.split(\"**Predicted Close Price** → \")[-1].strip())\n",
        "            numofactualvalues = numofactualvalues + 1\n",
        "        except ValueError:\n",
        "            predicted_close = None\n",
        "\n",
        "        explanation = response_text.split(\"Final Prediction:\\n- **Explanation** → \")[-1].split(\"\\n- **Predicted Close Price**\")[0].strip()\n",
        "\n",
        "        # Store results\n",
        "        predictions.append({\n",
        "            \"Ticker\": ticker,\n",
        "            \"Date\": date,\n",
        "            \"Predicted Close Price\": predicted_close\n",
        "        })\n",
        "\n",
        "        explanations.append({\n",
        "            \"Ticker\": ticker,\n",
        "            \"Date\": date,\n",
        "            \"Explanation\": explanation\n",
        "        })\n",
        "\n",
        "\n",
        "        # Print progress\n",
        "        print(f\"✅ Predicted for {ticker} on {date}: {predicted_close}\")\n",
        "time.sleep(1)\n",
        "end = time.time()\n",
        "totalGPTtime = (end-begin)\n",
        "# 🔹 Save predictions to CSV\n",
        "df_predictions = pd.DataFrame(predictions)\n",
        "df_predictions.to_csv(\"gpt4_predictions_jan_jun_2022.csv\", index=False)\n",
        "\n",
        "df_explanations = pd.DataFrame(explanations)\n",
        "df_explanations.to_csv(\"gpt4_explanations_jan_jun_2022.csv\", index=False)\n",
        "\n",
        "print(\"\\n✅ Predictions saved to 'gpt4_predictions_jan_jun_2022.csv'\")\n",
        "print(\"\\n✅ Explanations saved to 'gpt4_explanations_jan_jun_2022.csv'\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "xPdDbmYNu7Xj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "HF_TOKEN=userdata.get('test_token')\n",
        "\n",
        "if HF_TOKEN:\n",
        "    login(HF_TOKEN)\n",
        "    print(\"Successfully logged in to Hugging Face!\")\n",
        "else:\n",
        "    print(\"Token is not set. Please save the token first.\")"
      ],
      "metadata": {
        "id": "Kits03DXI3XP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training of Meta LLaMa : Use a GPU to run this - Did not use this, but could do future work involving it\n",
        "\n",
        "'''!pip install torch transformers accelerate sentencepiece\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# 🔹 Load the sorted financial news and numerical stock data\n",
        "df_news = pd.read_csv(\"sorted_financial_news.csv\")\n",
        "df_financials = pd.read_csv(\"sorted_financial_numerical_data.csv\")\n",
        "\n",
        "# 🔹 Convert Date column to datetime format\n",
        "df_news[\"Date\"] = pd.to_datetime(df_news[\"Date\"])\n",
        "df_financials[\"Date\"] = pd.to_datetime(df_financials[\"Date\"])\n",
        "\n",
        "# 🔹 Load Meta LLaMA 3.2 3B Instruct Model & Tokenizer\n",
        "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "# ✅ Step 1: Sentiment Prediction (Save to CSV)\n",
        "sentiment_results = []\n",
        "begin = time.time()\n",
        "sentiment_prompt_template = \"\"\"\n",
        "You are an AI trained for financial sentiment analysis.\n",
        "You will, in the future, be prompted to perform predictions on financial information.\n",
        "Analyze the financial news article below and assign a sentiment score between -1 (Negative), 0 (Neutral), and +1 (Positive).\n",
        "Use the sentiment of these articles, and their dates, to assist you in your predictions further down the line.\n",
        "\n",
        "Article: \"{article}\"\n",
        "---\n",
        "Final Answer: [Numeric Sentiment Score]\n",
        "\"\"\"\n",
        "\n",
        "for index, row in df_news.iterrows():\n",
        "    ticker = row[\"Ticker\"]\n",
        "    date = row[\"Date\"]\n",
        "    article_text = row[\"Cleaned Title\"]\n",
        "\n",
        "    # Format sentiment prompt\n",
        "    formatted_prompt = sentiment_prompt_template.format(article=article_text)\n",
        "\n",
        "    # Tokenize and generate output from LLaMA\n",
        "    response = pipe(formatted_prompt, max_new_tokens=200)\n",
        "    response_text = response[0][\"generated_text\"]\n",
        "\n",
        "    # Extract sentiment prediction\n",
        "    try:\n",
        "        predicted_sentiment = float(response_text.split(\"Final Answer: \")[-1].strip())\n",
        "    except ValueError:\n",
        "        predicted_sentiment = None\n",
        "\n",
        "    # Store result\n",
        "    sentiment_results.append({\"Ticker\": ticker, \"Date\": date, \"Sentiment Score\": predicted_sentiment})\n",
        "\n",
        "# Save sentiment predictions to CSV\n",
        "df_sentiment = pd.DataFrame(sentiment_results)\n",
        "df_sentiment.to_csv(\"llama_sentiment_predictions.csv\", index=False)\n",
        "print(\"\\n✅ Sentiment analysis results saved to 'llama_sentiment_predictions.csv'\")\n",
        "\n",
        "# ✅ Step 2: Stock Price Prediction with Reinforcement Learning\n",
        "reward_score = 0  # Start with neutral reward\n",
        "\n",
        "stock_prediction_prompt_template = \"\"\"\n",
        "You are an AI trained for financial market forecasting.\n",
        "Analyze the given financial data and predict the next day's closing stock price step by step. Limit your answer to 500 characters.\n",
        "You have already been fed financial news articles pertinent to the time period of the given financial data.\n",
        "If possible, use that information as well.\n",
        "\n",
        "1. **Identify Historical Market Trends**: Examine the last few days' price trends.\n",
        "2. **Assess Trading Volume**: Identify how volume has impacted price changes.\n",
        "3. **Compare Market Conditions**: Identify macro trends affecting the asset.\n",
        "4. **Compute Expected Price Movement**: Use past patterns to estimate the next day's close price.\n",
        "5. **Justify Your Prediction**: Explain why the predicted price movement is logical.\n",
        "\n",
        "Based on your analysis, provide an explanation.\n",
        "Additionally, if the date is the last date of the month, provide the predicted next-day closing stock price.\n",
        "Only provide a numerical value for the predicted next-day closing stock price.\n",
        "If you are providing a predicted next-day closing stock price, please do so in the format -> Predicted Next-Day Close Price: NUM.\n",
        "---\n",
        "Ticker: {ticker}\n",
        "Date: {date}\n",
        "Previous Close: {prev_close}\n",
        "\n",
        "Final Prediction:\n",
        "- **Explanation** → [Detailed reasoning]\n",
        "- **Predicted Next-Day Close Price** → [Numeric value]\n",
        "\"\"\"\n",
        "\n",
        "for index in range(len(df_financials) - 1):  # Iterate through financial data\n",
        "    row_financials = df_financials.iloc[index]\n",
        "\n",
        "    ticker = row_financials[\"Ticker\"]\n",
        "    date = row_financials[\"Date\"]\n",
        "    prev_close = row_financials[\"Close\"]\n",
        "\n",
        "    # Format the stock prediction prompt\n",
        "    formatted_prompt = stock_prediction_prompt_template.format(\n",
        "        ticker=ticker, date=date, prev_close=prev_close\n",
        "    )\n",
        "\n",
        "    # Tokenize and generate output from LLaMA\n",
        "    response = pipe(formatted_prompt, max_new_tokens=200)\n",
        "    response_text = response[0][\"generated_text\"]\n",
        "\n",
        "    # Extract LLaMA's predicted next-day close price\n",
        "    try:\n",
        "        predicted_close = float(response_text.split(\"Predicted Next-Day Close Price: \")[-1].strip())\n",
        "    except ValueError:\n",
        "        predicted_close = None\n",
        "\n",
        "    # Get the actual next-day stock close price\n",
        "    next_day_financials = df_financials[\n",
        "        (df_financials[\"Ticker\"] == ticker) & (df_financials[\"Date\"] == date + pd.Timedelta(days=1))\n",
        "    ]\n",
        "\n",
        "    if next_day_financials.empty or predicted_close is None:\n",
        "        continue  # Skip if no next-day data or prediction failed\n",
        "\n",
        "    actual_close = next_day_financials[\"Close\"].values[0]\n",
        "\n",
        "    # 🔹 Compute reward/penalty based on prediction accuracy (Mean Squared Error approach)\n",
        "    error = abs(predicted_close - actual_close)\n",
        "    reward_score -= error  # Penalize large errors, reward small errors\n",
        "\n",
        "    # 🔹 Update Prompt for Next Iteration Based on Reinforcement Learning\n",
        "    if reward_score < -1:\n",
        "        formatted_prompt += \"\\n\\n⚠️ Previous predictions had large errors. Pay closer attention to price trends.\"\n",
        "    elif reward_score > 1:\n",
        "        formatted_prompt += \"\\n\\n✅ Previous predictions have been accurate. Continue applying the same logic.\"\n",
        "\n",
        "    # 🔹 Print results\n",
        "    print(f\"✅ {ticker} - {date}\")\n",
        "    print(f\"🔹 Predicted Close: {predicted_close}\")\n",
        "    print(f\"🔹 Actual Close: {actual_close}\")\n",
        "    print(f\"🔹 Prediction Error: {error:.2f}\")\n",
        "    print(f\"🔹 Reward Score: {reward_score}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "print(\"\\n✅ Training complete! LLaMA 3.2 has processed financial news for sentiment and adapted stock price forecasting using reinforcement learning.\")\n",
        "\n",
        "predictions = []\n",
        "explanations = []\n",
        "\n",
        "stock_prediction_two_prompt_template = \"\"\"\n",
        "You are an AI trained for financial market forecasting.\n",
        "You have already been fed with financial news articles and numerical data for the year 2021, and were trained to make accurate predictions.\n",
        "Now, you will be fed with dates from 2022 and be asked to use your prior knowledge and training to make predictions.\n",
        "Using the knowledge gained from previous financial data, predict the closing stock price for the given dates.\n",
        "\n",
        "1. **Identify Historical Market Trends**: Examine previous trends based on past learned patterns.\n",
        "2. **Assess Trading Volume**: Identify how volume has impacted price changes.\n",
        "3. **Compare Market Conditions**: Consider economic trends that could affect stock price movement.\n",
        "4. **Compute Expected Price Movement**: Estimate the likely close price for the given date.\n",
        "5. **Justify Your Prediction**: Explain why the predicted price movement is logical.\n",
        "\n",
        "Based on your analysis, provide an explanation.\n",
        "Only provide the predicted closing stock price in the format -> Predicted Close Price: NUM.\n",
        "---\n",
        "Ticker: {ticker}\n",
        "Date: {date}\n",
        "\n",
        "Final Prediction:\n",
        "- **Explanation** → [Detailed reasoning]\n",
        "- **Predicted Close Price** → [Numeric value]\n",
        "\"\"\"\n",
        "numofLlamaValues = 0\n",
        "numofactualLvalues = 0\n",
        "for ticker in tickers:\n",
        "    for date in df_dates[\"Date\"]:\n",
        "      numofLlamaValues = numofLlamaValues + 1\n",
        "        # Format the stock prediction prompt\n",
        "        formatted_prompt = stock_prediction_prompt_template.format(\n",
        "            ticker=ticker, date=date\n",
        "        )\n",
        "\n",
        "        response = pipe(formatted_prompt, max_new_tokens=200)\n",
        "        response_text = response[0][\"generated_text\"]\n",
        "\n",
        "        # Extract LLaMA’s predicted closing price\n",
        "        try:\n",
        "            predicted_close = float(response_text.split(\"Predicted Close Price: \")[-1].strip())\n",
        "            numofactualLvalues=numofactualLvalues+1\n",
        "        except ValueError:\n",
        "            predicted_close = None\n",
        "\n",
        "       explanation = response_text.split(\"Final Prediction:\\n- **Explanation** → \")[-1].split(\"\\n- **Predicted Close Price**\")[0].strip()\n",
        "\n",
        "        # Store results\n",
        "        predictions.append({\n",
        "            \"Ticker\": ticker,\n",
        "            \"Date\": date,\n",
        "            \"Predicted Close Price\": predicted_close\n",
        "        })\n",
        "\n",
        "        explanations.append({\n",
        "            \"Ticker\": ticker,\n",
        "            \"Date\": date,\n",
        "            \"Explanation\": explanation\n",
        "        })\n",
        "\n",
        "        # Print progress\n",
        "        print(f\"✅ Predicted for {ticker} on {date}: {predicted_close}\")\n",
        "#time.sleep(1)\n",
        "#end = time.time()\n",
        "#totalLlamatime = (end-begin)\n",
        "# 🔹 Save predictions to CSV\n",
        "df_predictions = pd.DataFrame(predictions)\n",
        "df_predictions.to_csv(\"llama_predictions_jan_jun_2022.csv\", index=False)\n",
        "\n",
        "# 🔹 Save explanations to CSV\n",
        "df_explanations = pd.DataFrame(explanations)\n",
        "df_explanations.to_csv(\"llama_explanations_jan_jun_2022.csv\", index=False)\n",
        "\n",
        "print(\"\\n✅ Predictions saved to 'llama_predictions_jan_jun_2022.csv'\")\n",
        "print(\"\\n✅ Explanations saved to 'llama_explanations_jan_jun_2022.csv'\")\n",
        "'''"
      ],
      "metadata": {
        "id": "GNPFR__Bwirt",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training of Google Gemini using Chain-of-Thought Prompting and Reinforcement Learning\n",
        "\n",
        "\n",
        "df_news = pd.read_csv(\"sorted_financial_news.csv\")\n",
        "df_financials = pd.read_csv(\"sorted_financial_numerical_data.csv\")\n",
        "df_financials_new = pd.read_csv(\"financial_forecasting_cleaned.csv\")\n",
        "df_financials_new[\"Date\"] = pd.to_datetime(df_news[\"Date\"])\n",
        "df_news[\"Date\"] = pd.to_datetime(df_news[\"Date\"])\n",
        "df_financials[\"Date\"] = pd.to_datetime(df_financials[\"Date\"])\n",
        "df_financials2 = pd.read_csv(\"sorted_financial_numerical_data_two.csv\")\n",
        "df_financials2[\"Date\"] = pd.to_datetime(df_financials2[\"Date\"])\n",
        "reward_scores_list = []\n",
        "GEMINI_API_KEY = \"\"  # Replace with actual API key\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
        "\n",
        "sentiment_results = []\n",
        "begin = time.time()\n",
        "sentiment_prompt_template = \"\"\"\n",
        "You are an AI trained for financial sentiment analysis.\n",
        "You will, in the future, be prompted to perform predictions on financial information.\n",
        "Analyze the financial news article below and assign a sentiment score between -1 (Negative), 0 (Neutral), and +1 (Positive).\n",
        "Use the sentiment of these articles, and their dates, to assist you in your predictions further down the line.\n",
        "Article: \"{article}\"\n",
        "---\n",
        "Final Answer: [Numeric Sentiment Score]\n",
        "\"\"\"\n",
        "\n",
        "for index, row in df_news.iterrows():\n",
        "    ticker = row[\"Ticker\"]\n",
        "    date = row[\"Date\"]\n",
        "    article_text = row[\"Cleaned Title\"]\n",
        "\n",
        "    # Format sentiment prompt\n",
        "    formatted_prompt = sentiment_prompt_template.format(article=article_text)\n",
        "\n",
        "    response = model.generate_content(formatted_prompt)\n",
        "\n",
        "    try:\n",
        "        predicted_sentiment = float(response.text.split(\"Final Answer: \")[-1].strip())\n",
        "    except ValueError:\n",
        "        predicted_sentiment = None\n",
        "\n",
        "    # Store result\n",
        "    sentiment_results.append({\"Ticker\": ticker, \"Date\": date, \"Sentiment Score\": predicted_sentiment})\n",
        "\n",
        "# Save sentiment predictions to CSV\n",
        "df_sentiment = pd.DataFrame(sentiment_results)\n",
        "df_sentiment.to_csv(\"gemini_sentiment_predictions.csv\", index=False)\n",
        "print(\"\\n✅ Sentiment analysis results saved to 'gemini_sentiment_predictions.csv'\")\n",
        "\n",
        "# ✅ Step 2: Stock Price Prediction with Reinforcement Learning\n",
        "reward_score = 0\n",
        "\n",
        "stock_prediction_prompt_template = \"\"\"\n",
        "You are an AI trained for financial market forecasting.\n",
        "Analyze the given financial data and predict the next day's closing stock price step by step. Limit your answer to 500 characters.\n",
        "You have already been fed financial news articles pertinent to the time period of the given financial data.\n",
        "If possible, use that information as well.\n",
        "\n",
        "1. **Identify Historical Market Trends**: Examine the last few days' price trends.\n",
        "2. **Assess Trading Volume**: Identify how volume has impacted price changes.\n",
        "3. **Compare Market Conditions**: Identify macro trends affecting the asset.\n",
        "4. **Compute Expected Price Movement**: Use past patterns to estimate the next day's close price.\n",
        "5. **Justify Your Prediction**: Explain why the predicted price movement is logical.\n",
        "\n",
        "Based on your analysis, provide an explanation.\n",
        "Additionally, if the date is the last date of the month, provide the predicted next-day closing stock price.\n",
        "Only provide a numerical value for the predicted next-day closing stock price.\n",
        "If you are providing a predicted next-day closing stock price, please do so in the format -> Predicted Next-Day Close Price: NUM.\n",
        "---\n",
        "Ticker: {ticker}\n",
        "Date: {date}\n",
        "Previous Close: {prev_close}\n",
        "\n",
        "Final Prediction:\n",
        "- **Explanation** → [Detailed reasoning]\n",
        "- **Predicted Next-Day Close Price** → [Numeric value]\n",
        "\"\"\"\n",
        "\n",
        "for index in range(len(df_financials) - 1):  # Iterate through financial data\n",
        "    row_financials = df_financials.iloc[index]\n",
        "\n",
        "    ticker = row_financials[\"Ticker\"]\n",
        "    date = row_financials[\"Date\"]\n",
        "    prev_close = row_financials[\"Adj Close\"]\n",
        "\n",
        "    # Format the stock prediction prompt\n",
        "    formatted_prompt = stock_prediction_prompt_template.format(\n",
        "        ticker=ticker, date=date, prev_close=prev_close\n",
        "    )\n",
        "\n",
        "\n",
        "    response = model.generate_content(formatted_prompt)\n",
        "    try:\n",
        "        predicted_close = float(response.text.split(\"**Predicted Next-Day Close Price** → \")[-1].strip())\n",
        "    except ValueError:\n",
        "        predicted_close = None\n",
        "\n",
        "    # Get the actual next-day stock close price\n",
        "    next_day_financials = df_financials[\n",
        "        (df_financials[\"Ticker\"] == ticker) & (df_financials[\"Date\"] == date + pd.Timedelta(days=1))\n",
        "    ]\n",
        "\n",
        "    if next_day_financials.empty or predicted_close is None:\n",
        "        continue  # Skip if no next-day data or prediction failed\n",
        "\n",
        "    actual_close = next_day_financials[\"Adj Close\"].values[0]\n",
        "\n",
        "    # 🔹 Compute reward/penalty based on prediction accuracy (Mean Squared Error approach)\n",
        "    error = abs(predicted_close - actual_close)\n",
        "    reward_score -= error  # Penalize large errors, reward small errors\n",
        "\n",
        "    reward_scores_list.append({\n",
        "        \"Ticker\": ticker,\n",
        "        \"Date\": date,\n",
        "        \"Reward Score\": reward_score\n",
        "    })\n",
        "\n",
        "    # 🔹 Update Prompt for Next Iteration Based on Reinforcement Learning\n",
        "    if reward_score < -1:\n",
        "        formatted_prompt += \"\\n\\n⚠️ Previous predictions had large errors. Pay closer attention to price trends.\"\n",
        "    elif reward_score > 1:\n",
        "        formatted_prompt += \"\\n\\n✅ Previous predictions have been accurate. Continue applying the same logic.\"\n",
        "\n",
        "    # 🔹 Print results\n",
        "    print(f\"✅ {ticker} - {date}\")\n",
        "    print(f\"🔹 Predicted Close: {predicted_close}\")\n",
        "    print(f\"🔹 Actual Close: {actual_close}\")\n",
        "    print(f\"🔹 Prediction Error: {error:.2f}\")\n",
        "    print(f\"🔹 Reward Score: {reward_score}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "print(\"\\n✅ Training complete! Gemini has processed financial news for sentiment and adapted stock price forecasting using reinforcement learning.\")\n",
        "\n",
        "\n",
        "\n",
        "predictions = []\n",
        "explanations = []\n",
        "\n",
        "stock_prediction_two_prompt_template = \"\"\"\n",
        "You are an AI trained for financial market forecasting.\n",
        "You have already been fed with financial news articles and numerical data for the year 2021, and were trained to make accurate predictions.\n",
        "Now, you will be fed with dates from 2022 and be asked to use your prior knowledge and training to make predictions.\n",
        "Using the knowledge gained from previous financial data, predict the closing stock price for the given dates.\n",
        "Limit your answer to 500 characters.\n",
        "\n",
        "1. **Identify Historical Market Trends**: Examine previous trends based on past learned patterns.\n",
        "2. **Assess Trading Volume**: Identify how volume has impacted price changes.\n",
        "3. **Compare Market Conditions**: Consider economic trends that could affect stock price movement.\n",
        "4. **Compute Expected Price Movement**: Estimate the likely close price for the given date.\n",
        "5. **Justify Your Prediction**: Explain why the predicted price movement is logical.\n",
        "\n",
        "Based on your analysis, provide an explanation.\n",
        "Only provide the predicted closing stock price in the format -> Predicted Close Price: NUM.\n",
        "---\n",
        "Ticker: {ticker}\n",
        "Date: {date}\n",
        "\n",
        "Final Prediction:\n",
        "- **Explanation** → [Detailed reasoning]\n",
        "- **Predicted Close Price** → [Numeric value]\n",
        "\"\"\"\n",
        "#tickers = [\n",
        "#    \"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"TSLA\", \"NVDA\", \"FB\", \"JPM\", \"V\", \"DIS\"\n",
        "#]\n",
        "\n",
        "\n",
        "print(\"\\n🚀 Now predicting closing prices for January - June 2022...\")\n",
        "numofGeminivalues = 0\n",
        "numofactualGvalues = 0\n",
        "for ticker in tickers:\n",
        "    for date in df_dates[\"Date\"]:\n",
        "        numofGeminivalues = numofGeminivalues + 1\n",
        "        # Format the stock prediction prompt\n",
        "        formatted_prompt = stock_prediction_two_prompt_template.format(\n",
        "            ticker=ticker, date=date\n",
        "        )\n",
        "\n",
        "        response = model.generate_content(formatted_prompt)\n",
        "        try:\n",
        "            predicted_close = float(response.text.split(\"**Predicted Close Price** → \")[-1].strip())\n",
        "            numofactualGvalues = numofactualGvalues + 1\n",
        "        except ValueError:\n",
        "            predicted_close = None\n",
        "\n",
        "        explanation = response.text.split(\"Final Prediction:\\n- **Explanation** → \")[-1].split(\"\\n- **Predicted Close Price**\")[0].strip()\n",
        "\n",
        "        # Store results\n",
        "        predictions.append({\n",
        "            \"Ticker\": ticker,\n",
        "            \"Date\": date,\n",
        "            \"Predicted Close Price\": predicted_close\n",
        "        })\n",
        "\n",
        "        explanations.append({\n",
        "            \"Ticker\": ticker,\n",
        "            \"Date\": date,\n",
        "            \"Explanation\": explanation\n",
        "        })\n",
        "\n",
        "\n",
        "        # Print progress\n",
        "        print(f\"✅ Predicted for {ticker} on {date}: {predicted_close}\")\n",
        "time.sleep(1)\n",
        "end = time.time()\n",
        "totalGeminitime = (end-begin)\n",
        "# 🔹 Save predictions to CSV\n",
        "df_rewards = pd.DataFrame(reward_scores_list)\n",
        "df_rewards.to_csv(\"gemini_reward_scores_training.csv\", index=False)\n",
        "print(\"\\n✅ Reward scores saved to 'gemini_reward_scores_training.csv'\")\n",
        "\n",
        "df_predictions = pd.DataFrame(predictions)\n",
        "df_predictions.to_csv(\"gemini_predictions_jan_jun_2022.csv\", index=False)\n",
        "\n",
        "df_explanations = pd.DataFrame(explanations)\n",
        "df_explanations.to_csv(\"gemini_explanations_jan_jun_2022.csv\", index=False)\n",
        "\n",
        "print(\"\\n✅ Predictions saved to 'gemini_predictions_jan_jun_2022.csv'\")\n",
        "print(\"\\n✅ Explanations saved to 'gemini_explanations_jan_jun_2022.csv'\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ho9BNbGODP8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from rouge_score import rouge_scorer\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "# 🔹 Load the explanation CSV files\n",
        "df_claude = pd.read_csv(\"claude_explanations_jan_jun_2022.csv\")\n",
        "df_gpt = pd.read_csv(\"gpt4_explanations_jan_jun_2022.csv\")\n",
        "df_gemini = pd.read_csv(\"gemini_explanations_jan_jun_2022.csv\")\n",
        "\n",
        "# 🔹 Merge explanations based on Ticker and Date\n",
        "df_merged = pd.merge(df_claude, df_gpt, on=[\"Ticker\", \"Date\"], suffixes=(\"_claude\", \"_gpt\"))\n",
        "df_merged = pd.merge(df_merged, df_gemini, on=[\"Ticker\", \"Date\"])\n",
        "df_merged.rename(columns={\"Explanation\": \"Explanation_gemini\"}, inplace=True)\n",
        "\n",
        "# 🔹 Initialize ROUGE scorer\n",
        "rouge_scorer_instance = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True)\n",
        "\n",
        "# 🔹 Compute ROUGE-F1 and BLEU scores\n",
        "rouge_f1_scores_claude_gpt = []\n",
        "bleu_scores_claude_gpt = []\n",
        "\n",
        "rouge_f1_scores_claude_gemini = []\n",
        "bleu_scores_claude_gemini = []\n",
        "\n",
        "rouge_f1_scores_gpt_gemini = []\n",
        "bleu_scores_gpt_gemini = []\n",
        "\n",
        "for _, row in df_merged.iterrows():\n",
        "    explanation_claude = str(row[\"Explanation_claude\"])\n",
        "    explanation_gpt = str(row[\"Explanation_gpt\"])\n",
        "    explanation_gemini = str(row[\"Explanation_gemini\"])\n",
        "\n",
        "    # Compute ROUGE-F1 scores\n",
        "    rouge_scores_claude_gpt = rouge_scorer_instance.score(explanation_claude, explanation_gpt)\n",
        "    rouge_scores_claude_gemini = rouge_scorer_instance.score(explanation_claude, explanation_gemini)\n",
        "    rouge_scores_gpt_gemini = rouge_scorer_instance.score(explanation_gpt, explanation_gemini)\n",
        "\n",
        "    rouge_f1_scores_claude_gpt.append(rouge_scores_claude_gpt[\"rouge1\"].fmeasure)\n",
        "    rouge_f1_scores_claude_gemini.append(rouge_scores_claude_gemini[\"rouge1\"].fmeasure)\n",
        "    rouge_f1_scores_gpt_gemini.append(rouge_scores_gpt_gemini[\"rouge1\"].fmeasure)\n",
        "\n",
        "    # Compute BLEU scores\n",
        "    reference_claude = explanation_claude.split()\n",
        "    candidate_gpt = explanation_gpt.split()\n",
        "    candidate_gemini = explanation_gemini.split()\n",
        "\n",
        "    bleu_score_claude_gpt = sentence_bleu([reference_claude], candidate_gpt)\n",
        "    bleu_score_claude_gemini = sentence_bleu([reference_claude], candidate_gemini)\n",
        "    bleu_score_gpt_gemini = sentence_bleu([candidate_gpt], candidate_gemini)\n",
        "\n",
        "    if bleu_score_claude_gpt != 0:\n",
        "        bleu_scores_claude_gpt.append(bleu_score_claude_gpt)\n",
        "    if bleu_score_claude_gemini != 0:\n",
        "        bleu_scores_claude_gemini.append(bleu_score_claude_gemini)\n",
        "    if bleu_score_gpt_gemini != 0:\n",
        "        bleu_scores_gpt_gemini.append(bleu_score_gpt_gemini)\n",
        "\n",
        "# 🔹 Add scores to dataframe\n",
        "df_merged[\"ROUGE_F1_Claude_GPT\"] = rouge_f1_scores_claude_gpt\n",
        "\n",
        "\n",
        "df_merged[\"ROUGE_F1_Claude_Gemini\"] = rouge_f1_scores_claude_gemini\n",
        "\n",
        "\n",
        "df_merged[\"ROUGE_F1_GPT_Gemini\"] = rouge_f1_scores_gpt_gemini\n",
        "\n",
        "\n",
        "bleu_scores_claude_gpt = [score if score > 0 else 0 for score in bleu_scores_claude_gpt]\n",
        "bleu_scores_claude_gemini = [score if score > 0 else 0 for score in bleu_scores_claude_gemini]\n",
        "bleu_scores_gpt_gemini = [score if score > 0 else 0 for score in bleu_scores_gpt_gemini]\n",
        "\n",
        "# Ensure lists have the same length as the DataFrame by filling missing values\n",
        "while len(bleu_scores_claude_gpt) < len(df_merged):\n",
        "    bleu_scores_claude_gpt.append(0)\n",
        "\n",
        "while len(bleu_scores_claude_gemini) < len(df_merged):\n",
        "    bleu_scores_claude_gemini.append(0)\n",
        "\n",
        "while len(bleu_scores_gpt_gemini) < len(df_merged):\n",
        "    bleu_scores_gpt_gemini.append(0)\n",
        "\n",
        "# Now assign safely\n",
        "df_merged[\"BLEU_Claude_GPT\"] = bleu_scores_claude_gpt\n",
        "df_merged[\"BLEU_Claude_Gemini\"] = bleu_scores_claude_gemini\n",
        "df_merged[\"BLEU_GPT_Gemini\"] = bleu_scores_gpt_gemini\n",
        "\n",
        "# 🔹 Remove entries where any of the similarity scores are 0\n",
        "df_filtered = df_merged[\n",
        "    (df_merged[\"ROUGE_F1_Claude_GPT\"] > 0) & (df_merged[\"BLEU_Claude_GPT\"] > 0) &\n",
        "    (df_merged[\"ROUGE_F1_Claude_Gemini\"] > 0) & (df_merged[\"BLEU_Claude_Gemini\"] > 0) &\n",
        "    (df_merged[\"ROUGE_F1_GPT_Gemini\"] > 0) & (df_merged[\"BLEU_GPT_Gemini\"] > 0)\n",
        "]\n",
        "\n",
        "# 🔹 Save the filtered results to CSV\n",
        "df_filtered.to_csv(\"llm_explanation_comparison_filtered.csv\", index=False)\n",
        "\n",
        "# 🔹 Plot ROUGE-F1 scores\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(df_filtered.index, df_filtered[\"ROUGE_F1_Claude_GPT\"], label=\"Claude vs GPT\", color=\"blue\", marker=\"o\", linestyle=\"-\")\n",
        "plt.plot(df_filtered.index, df_filtered[\"ROUGE_F1_Claude_Gemini\"], label=\"Claude vs Gemini\", color=\"green\", marker=\"s\", linestyle=\"-\")\n",
        "plt.plot(df_filtered.index, df_filtered[\"ROUGE_F1_GPT_Gemini\"], label=\"GPT vs Gemini\", color=\"red\", marker=\"^\", linestyle=\"-\")\n",
        "\n",
        "plt.xlabel(\"Explanations\")\n",
        "plt.ylabel(\"ROUGE F1 Score\")\n",
        "plt.title(\"ROUGE F1 Score Comparison (Claude, GPT-4, Gemini) - Filtered\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# 🔹 Plot BLEU scores\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(df_filtered.index, df_filtered[\"BLEU_Claude_GPT\"], label=\"Claude vs GPT\", color=\"blue\", marker=\"o\", linestyle=\"-\")\n",
        "plt.plot(df_filtered.index, df_filtered[\"BLEU_Claude_Gemini\"], label=\"Claude vs Gemini\", color=\"green\", marker=\"s\", linestyle=\"-\")\n",
        "plt.plot(df_filtered.index, df_filtered[\"BLEU_GPT_Gemini\"], label=\"GPT vs Gemini\", color=\"red\", marker=\"^\", linestyle=\"-\")\n",
        "\n",
        "plt.xlabel(\"Explanations\")\n",
        "plt.ylabel(\"BLEU Score\")\n",
        "plt.title(\"BLEU Score Comparison (Claude, GPT-4, Gemini) - Filtered\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n✅ Filtered ROUGE F1 and BLEU scores computed and saved to 'llm_explanation_comparison_filtered.csv'.\")\n"
      ],
      "metadata": {
        "id": "gptamKUtwsdf",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from rouge_score import rouge_scorer\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "# 🔹 Load explanation CSV files for Claude, GPT-4, and Gemini\n",
        "df_claude = pd.read_csv(\"claude_explanations_jan_jun_2022.csv\")\n",
        "df_gpt = pd.read_csv(\"gpt4_explanations_jan_jun_2022.csv\")\n",
        "df_gemini = pd.read_csv(\"gemini_explanations_jan_jun_2022.csv\")\n",
        "\n",
        "# 🔹 Merge explanations based on Ticker and Date\n",
        "df_merged = pd.merge(df_claude, df_gpt, on=[\"Ticker\", \"Date\"], suffixes=(\"_claude\", \"_gpt\"))\n",
        "df_merged = pd.merge(df_merged, df_gemini, on=[\"Ticker\", \"Date\"])\n",
        "df_merged.rename(columns={\"Explanation\": \"Explanation_gemini\"}, inplace=True)\n",
        "\n",
        "# 🔹 Initialize ROUGE scorer\n",
        "rouge_scorer_instance = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True)\n",
        "\n",
        "# 🔹 Compute ROUGE-F1 and BLEU scores\n",
        "rouge_f1_scores_claude_gpt = []\n",
        "bleu_scores_claude_gpt = []\n",
        "\n",
        "rouge_f1_scores_claude_gemini = []\n",
        "bleu_scores_claude_gemini = []\n",
        "\n",
        "rouge_f1_scores_gpt_gemini = []\n",
        "bleu_scores_gpt_gemini = []\n",
        "\n",
        "for _, row in df_merged.iterrows():\n",
        "    explanation_claude = str(row[\"Explanation_claude\"])\n",
        "    explanation_gpt = str(row[\"Explanation_gpt\"])\n",
        "    explanation_gemini = str(row[\"Explanation_gemini\"])\n",
        "\n",
        "    # Compute ROUGE-F1 scores\n",
        "    rouge_scores_claude_gpt = rouge_scorer_instance.score(explanation_claude, explanation_gpt)\n",
        "    rouge_scores_claude_gemini = rouge_scorer_instance.score(explanation_claude, explanation_gemini)\n",
        "    rouge_scores_gpt_gemini = rouge_scorer_instance.score(explanation_gpt, explanation_gemini)\n",
        "\n",
        "    rouge_f1_scores_claude_gpt.append(rouge_scores_claude_gpt[\"rouge1\"].fmeasure)\n",
        "    rouge_f1_scores_claude_gemini.append(rouge_scores_claude_gemini[\"rouge1\"].fmeasure)\n",
        "    rouge_f1_scores_gpt_gemini.append(rouge_scores_gpt_gemini[\"rouge1\"].fmeasure)\n",
        "\n",
        "    # Compute BLEU scores\n",
        "    reference_claude = explanation_claude.split()\n",
        "    candidate_gpt = explanation_gpt.split()\n",
        "    candidate_gemini = explanation_gemini.split()\n",
        "\n",
        "    bleu_score_claude_gpt = sentence_bleu([reference_claude], candidate_gpt)\n",
        "    bleu_score_claude_gemini = sentence_bleu([reference_claude], candidate_gemini)\n",
        "    bleu_score_gpt_gemini = sentence_bleu([candidate_gpt], candidate_gemini)\n",
        "\n",
        "    if bleu_score_claude_gpt != 0:\n",
        "        bleu_scores_claude_gpt.append(bleu_score_claude_gpt)\n",
        "    if bleu_score_claude_gemini != 0:\n",
        "        bleu_scores_claude_gemini.append(bleu_score_claude_gemini)\n",
        "    if bleu_score_gpt_gemini != 0:\n",
        "        bleu_scores_gpt_gemini.append(bleu_score_gpt_gemini)\n",
        "\n",
        "# 🔹 Add scores to dataframe\n",
        "df_merged[\"ROUGE_F1_Claude_GPT\"] = rouge_f1_scores_claude_gpt\n",
        "\n",
        "\n",
        "df_merged[\"ROUGE_F1_Claude_Gemini\"] = rouge_f1_scores_claude_gemini\n",
        "\n",
        "\n",
        "df_merged[\"ROUGE_F1_GPT_Gemini\"] = rouge_f1_scores_gpt_gemini\n",
        "\n",
        "\n",
        "bleu_scores_claude_gpt = [score if score > 0 else 0 for score in bleu_scores_claude_gpt]\n",
        "bleu_scores_claude_gemini = [score if score > 0 else 0 for score in bleu_scores_claude_gemini]\n",
        "bleu_scores_gpt_gemini = [score if score > 0 else 0 for score in bleu_scores_gpt_gemini]\n",
        "\n",
        "# Ensure lists have the same length as the DataFrame by filling missing values\n",
        "while len(bleu_scores_claude_gpt) < len(df_merged):\n",
        "    bleu_scores_claude_gpt.append(0)\n",
        "\n",
        "while len(bleu_scores_claude_gemini) < len(df_merged):\n",
        "    bleu_scores_claude_gemini.append(0)\n",
        "\n",
        "while len(bleu_scores_gpt_gemini) < len(df_merged):\n",
        "    bleu_scores_gpt_gemini.append(0)\n",
        "\n",
        "# Now assign safely\n",
        "df_merged[\"BLEU_Claude_GPT\"] = bleu_scores_claude_gpt\n",
        "df_merged[\"BLEU_Claude_Gemini\"] = bleu_scores_claude_gemini\n",
        "df_merged[\"BLEU_GPT_Gemini\"] = bleu_scores_gpt_gemini\n",
        "\n",
        "# 🔹 Remove entries where any of the similarity scores are 0\n",
        "df_filtered = df_merged[\n",
        "    (df_merged[\"ROUGE_F1_Claude_GPT\"] > 0) & (df_merged[\"BLEU_Claude_GPT\"] > 0) &\n",
        "    (df_merged[\"ROUGE_F1_Claude_Gemini\"] > 0) & (df_merged[\"BLEU_Claude_Gemini\"] > 0) &\n",
        "    (df_merged[\"ROUGE_F1_GPT_Gemini\"] > 0) & (df_merged[\"BLEU_GPT_Gemini\"] > 0)\n",
        "]\n",
        "\n",
        "# 🔹 Save the filtered results to CSV\n",
        "df_filtered.to_csv(\"llm_explanation_comparison_filtered.csv\", index=False)\n",
        "\n",
        "# 🔹 Plot ROUGE-F1 scores\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(df_filtered.index, df_filtered[\"ROUGE_F1_Claude_GPT\"], label=\"Claude vs GPT\", color=\"blue\", marker=\"o\", linestyle=\"-\")\n",
        "plt.plot(df_filtered.index, df_filtered[\"ROUGE_F1_Claude_Gemini\"], label=\"Claude vs Gemini\", color=\"green\", marker=\"s\", linestyle=\"-\")\n",
        "plt.plot(df_filtered.index, df_filtered[\"ROUGE_F1_GPT_Gemini\"], label=\"GPT vs Gemini\", color=\"red\", marker=\"^\", linestyle=\"-\")\n",
        "\n",
        "plt.xlabel(\"Explanations\")\n",
        "plt.ylabel(\"ROUGE F1 Score\")\n",
        "plt.title(\"ROUGE F1 Score Comparison (Claude, GPT-4, Gemini) - Filtered\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# 🔹 Plot BLEU scores\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(df_filtered.index, df_filtered[\"BLEU_Claude_GPT\"], label=\"Claude vs GPT\", color=\"blue\", marker=\"o\", linestyle=\"-\")\n",
        "plt.plot(df_filtered.index, df_filtered[\"BLEU_Claude_Gemini\"], label=\"Claude vs Gemini\", color=\"green\", marker=\"s\", linestyle=\"-\")\n",
        "plt.plot(df_filtered.index, df_filtered[\"BLEU_GPT_Gemini\"], label=\"GPT vs Gemini\", color=\"red\", marker=\"^\", linestyle=\"-\")\n",
        "\n",
        "plt.xlabel(\"Explanations\")\n",
        "plt.ylabel(\"BLEU Score\")\n",
        "plt.title(\"BLEU Score Comparison (Claude, GPT-4, Gemini) - Filtered\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# 🔹 Plot Combined ROUGE-F1 & BLEU scores\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(df_filtered.index, df_filtered[\"ROUGE_F1_Claude_GPT\"], label=\"ROUGE-F1 Claude vs GPT\", linestyle='-', marker='o')\n",
        "plt.plot(df_filtered.index, df_filtered[\"BLEU_Claude_GPT\"], label=\"BLEU Claude vs GPT\", linestyle='--', marker='o')\n",
        "\n",
        "plt.plot(df_filtered.index, df_filtered[\"ROUGE_F1_Claude_Gemini\"], label=\"ROUGE-F1 Claude vs Gemini\", linestyle='-', marker='s')\n",
        "plt.plot(df_filtered.index, df_filtered[\"BLEU_Claude_Gemini\"], label=\"BLEU Claude vs Gemini\", linestyle='--', marker='s')\n",
        "\n",
        "plt.plot(df_filtered.index, df_filtered[\"ROUGE_F1_GPT_Gemini\"], label=\"ROUGE-F1 GPT vs Gemini\", linestyle='-', marker='^')\n",
        "plt.plot(df_filtered.index, df_filtered[\"BLEU_GPT_Gemini\"], label=\"BLEU GPT vs Gemini\", linestyle='--', marker='^')\n",
        "\n",
        "plt.xlabel(\"Explanations\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.title(\"ROUGE-F1 & BLEU Comparison (Claude, GPT-4, Gemini) - Filtered\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "kGeyelFWtZY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error\n",
        "from scipy.stats import pearsonr\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error\n",
        "from scipy.stats import pearsonr\n"
      ],
      "metadata": {
        "id": "AcEVXZTsEMGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 🔹 Load numerical prediction CSV files for Claude, GPT-4, and Gemini\n",
        "df_claude = pd.read_csv(\"claude_predictions_jan_jun_2022.csv\")\n",
        "df_gpt = pd.read_csv(\"gpt4_predictions_jan_jun_2022.csv\")\n",
        "df_gemini = pd.read_csv(\"gemini_predictions_jan_jun_2022.csv\")\n",
        "\n",
        "# 🔹 Merge numerical predictions based on Ticker and Date\n",
        "df_merged = pd.merge(df_claude, df_gpt, on=[\"Ticker\", \"Date\"], suffixes=(\"_claude\", \"_gpt\"))\n",
        "df_merged = pd.merge(df_merged, df_gemini, on=[\"Ticker\", \"Date\"])\n",
        "df_merged.rename(columns={\"Predicted Close Price\": \"Predicted Close Price_gemini\"}, inplace=True)\n",
        "\n",
        "# 🔹 Convert \"Predicted Close Price\" columns to numeric, handling 'None' and NaN values\n",
        "df_merged[\"Predicted Close Price_claude\"] = pd.to_numeric(df_merged[\"Predicted Close Price_claude\"], errors='coerce')\n",
        "df_merged[\"Predicted Close Price_gpt\"] = pd.to_numeric(df_merged[\"Predicted Close Price_gpt\"], errors='coerce')\n",
        "df_merged[\"Predicted Close Price_gemini\"] = pd.to_numeric(df_merged[\"Predicted Close Price_gemini\"], errors='coerce')\n",
        "\n",
        "# 🔹 Drop rows where any value is NaN (invalid or missing predictions)\n",
        "df_filtered = df_merged.dropna(subset=[\"Predicted Close Price_claude\", \"Predicted Close Price_gpt\", \"Predicted Close Price_gemini\"])\n",
        "\n",
        "# ✅ Compute Metrics for Claude vs GPT, Claude vs Gemini, and GPT vs Gemini\n",
        "mape_claude_gpt = mean_absolute_percentage_error(df_filtered[\"Predicted Close Price_claude\"], df_filtered[\"Predicted Close Price_gpt\"])\n",
        "mape_claude_gemini = mean_absolute_percentage_error(df_filtered[\"Predicted Close Price_claude\"], df_filtered[\"Predicted Close Price_gemini\"])\n",
        "mape_gpt_gemini = mean_absolute_percentage_error(df_filtered[\"Predicted Close Price_gpt\"], df_filtered[\"Predicted Close Price_gemini\"])\n",
        "\n",
        "rmse_claude_gpt = np.sqrt(mean_squared_error(df_filtered[\"Predicted Close Price_claude\"], df_filtered[\"Predicted Close Price_gpt\"]))\n",
        "rmse_claude_gemini = np.sqrt(mean_squared_error(df_filtered[\"Predicted Close Price_claude\"], df_filtered[\"Predicted Close Price_gemini\"]))\n",
        "rmse_gpt_gemini = np.sqrt(mean_squared_error(df_filtered[\"Predicted Close Price_gpt\"], df_filtered[\"Predicted Close Price_gemini\"]))\n",
        "\n",
        "pearson_claude_gpt, _ = pearsonr(df_filtered[\"Predicted Close Price_claude\"], df_filtered[\"Predicted Close Price_gpt\"])\n",
        "pearson_claude_gemini, _ = pearsonr(df_filtered[\"Predicted Close Price_claude\"], df_filtered[\"Predicted Close Price_gemini\"])\n",
        "pearson_gpt_gemini, _ = pearsonr(df_filtered[\"Predicted Close Price_gpt\"], df_filtered[\"Predicted Close Price_gemini\"])\n",
        "\n",
        "# 🔹 Plot MAPE Comparison\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(df_filtered.index, abs(df_filtered[\"Predicted Close Price_claude\"] - df_filtered[\"Predicted Close Price_gpt\"]) / df_filtered[\"Predicted Close Price_claude\"], label=f\"MAPE Claude vs GPT-4 ({mape_claude_gpt:.4f})\", color=\"blue\", marker=\"o\", linestyle=\"-\")\n",
        "plt.plot(df_filtered.index, abs(df_filtered[\"Predicted Close Price_claude\"] - df_filtered[\"Predicted Close Price_gemini\"]) / df_filtered[\"Predicted Close Price_claude\"], label=f\"MAPE Claude vs Gemini ({mape_claude_gemini:.4f})\", color=\"green\", marker=\"s\", linestyle=\"-\")\n",
        "plt.plot(df_filtered.index, abs(df_filtered[\"Predicted Close Price_gpt\"] - df_filtered[\"Predicted Close Price_gemini\"]) / df_filtered[\"Predicted Close Price_gpt\"], label=f\"MAPE GPT-4 vs Gemini ({mape_gpt_gemini:.4f})\", color=\"red\", marker=\"^\", linestyle=\"-\")\n",
        "\n",
        "plt.xlabel(\"Predictions\")\n",
        "plt.ylabel(\"MAPE\")\n",
        "plt.title(\"MAPE Comparison (Claude vs GPT-4 vs Gemini)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# 🔹 Plot RMSE Comparison\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(df_filtered.index, (df_filtered[\"Predicted Close Price_claude\"] - df_filtered[\"Predicted Close Price_gpt\"])**2, label=f\"RMSE Claude vs GPT-4 ({rmse_claude_gpt:.4f})\", color=\"blue\", marker=\"o\", linestyle=\"-\")\n",
        "plt.plot(df_filtered.index, (df_filtered[\"Predicted Close Price_claude\"] - df_filtered[\"Predicted Close Price_gemini\"])**2, label=f\"RMSE Claude vs Gemini ({rmse_claude_gemini:.4f})\", color=\"green\", marker=\"s\", linestyle=\"-\")\n",
        "plt.plot(df_filtered.index, (df_filtered[\"Predicted Close Price_gpt\"] - df_filtered[\"Predicted Close Price_gemini\"])**2, label=f\"RMSE GPT-4 vs Gemini ({rmse_gpt_gemini:.4f})\", color=\"red\", marker=\"^\", linestyle=\"-\")\n",
        "\n",
        "plt.xlabel(\"Predictions\")\n",
        "plt.ylabel(\"RMSE\")\n",
        "plt.title(\"RMSE Comparison (Claude vs GPT-4 vs Gemini)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# 🔹 Plot Pearson Correlation for Each Pair\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.scatter(df_filtered[\"Predicted Close Price_claude\"], df_filtered[\"Predicted Close Price_gpt\"], label=f\"Pearson R Claude vs GPT-4: {pearson_claude_gpt:.4f}\", color=\"blue\", alpha=0.6)\n",
        "plt.scatter(df_filtered[\"Predicted Close Price_claude\"], df_filtered[\"Predicted Close Price_gemini\"], label=f\"Pearson R Claude vs Gemini: {pearson_claude_gemini:.4f}\", color=\"green\", alpha=0.6)\n",
        "plt.scatter(df_filtered[\"Predicted Close Price_gpt\"], df_filtered[\"Predicted Close Price_gemini\"], label=f\"Pearson R GPT-4 vs Gemini: {pearson_gpt_gemini:.4f}\", color=\"red\", alpha=0.6)\n",
        "\n",
        "plt.xlabel(\"Claude / GPT Predictions\")\n",
        "plt.ylabel(\"Gemini Predictions\")\n",
        "plt.title(\"Pearson Correlation: Claude vs GPT-4 vs Gemini\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# ✅ Print Results\n",
        "print(f\"\\n📊 Comparison Results:\")\n",
        "print(f\"🔹 MAPE Claude vs GPT-4: {mape_claude_gpt:.4f}\")\n",
        "print(f\"🔹 MAPE Claude vs Gemini: {mape_claude_gemini:.4f}\")\n",
        "print(f\"🔹 MAPE GPT-4 vs Gemini: {mape_gpt_gemini:.4f}\")\n",
        "\n",
        "print(f\"\\n🔹 RMSE Claude vs GPT-4: {rmse_claude_gpt:.4f}\")\n",
        "print(f\"🔹 RMSE Claude vs Gemini: {rmse_claude_gemini:.4f}\")\n",
        "print(f\"🔹 RMSE GPT-4 vs Gemini: {rmse_gpt_gemini:.4f}\")\n",
        "\n",
        "print(f\"\\n🔹 Pearson R Claude vs GPT-4: {pearson_claude_gpt:.4f}\")\n",
        "print(f\"🔹 Pearson R Claude vs Gemini: {pearson_claude_gemini:.4f}\")\n",
        "print(f\"🔹 Pearson R GPT-4 vs Gemini: {pearson_gpt_gemini:.4f}\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ZsaaleljCCxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# 🔹 Load the numerical prediction CSV files\n",
        "df_claude = pd.read_csv(\"claude_predictions_jan_jun_2022.csv\")\n",
        "df_actual = pd.read_csv(\"financial_forecasting_cleaned_two.csv\")\n",
        "\n",
        "# 🔹 Standardize column names to match\n",
        "df_actual.rename(columns={\"Adj Close\": \"Actual Close Price\"}, inplace=True)\n",
        "\n",
        "# 🔹 Convert Date column to datetime format\n",
        "df_claude[\"Date\"] = pd.to_datetime(df_claude[\"Date\"])\n",
        "df_actual[\"Date\"] = pd.to_datetime(df_actual[\"Date\"])\n",
        "\n",
        "# 🔹 Merge numerical predictions based on Ticker and Date\n",
        "df_merged = pd.merge(df_claude, df_actual, on=[\"Ticker\", \"Date\"], how=\"inner\")\n",
        "\n",
        "# 🔹 Convert values to numeric and handle missing values\n",
        "df_merged[\"Predicted Close Price\"] = pd.to_numeric(df_merged[\"Predicted Close Price\"], errors='coerce')\n",
        "df_merged[\"Actual Close Price\"] = pd.to_numeric(df_merged[\"Actual Close Price\"], errors='coerce')\n",
        "\n",
        "# 🔹 Drop rows where either value is NaN (due to 'None' or missing values)\n",
        "df_filtered = df_merged.dropna(subset=[\"Predicted Close Price\", \"Actual Close Price\"])\n",
        "\n",
        "# ✅ Compute Metrics\n",
        "mape = mean_absolute_percentage_error(df_filtered[\"Actual Close Price\"], df_filtered[\"Predicted Close Price\"])\n",
        "rmse = np.sqrt(mean_squared_error(df_filtered[\"Actual Close Price\"], df_filtered[\"Predicted Close Price\"]))\n",
        "pearson_r, _ = pearsonr(df_filtered[\"Actual Close Price\"], df_filtered[\"Predicted Close Price\"])\n",
        "\n",
        "# 🔹 Plot MAPE\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(df_filtered.index, abs(df_filtered[\"Actual Close Price\"] - df_filtered[\"Predicted Close Price\"]) / df_filtered[\"Actual Close Price\"], label=\"MAPE\", color=\"blue\", marker=\"o\", linestyle=\"-\")\n",
        "plt.xlabel(\"Predictions\")\n",
        "plt.ylabel(\"MAPE\")\n",
        "plt.title(f\"MAPE Comparison (Claude vs. Actual Data) - Mean: {mape:.4f}\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# 🔹 Plot RMSE\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(df_filtered.index, (df_filtered[\"Actual Close Price\"] - df_filtered[\"Predicted Close Price\"])**2, label=\"RMSE\", color=\"red\", marker=\"o\", linestyle=\"-\")\n",
        "plt.xlabel(\"Predictions\")\n",
        "plt.ylabel(\"RMSE\")\n",
        "plt.title(f\"RMSE Comparison (Claude vs. Actual Data) - RMSE: {rmse:.4f}\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# 🔹 Plot Pearson R Correlation\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.scatter(df_filtered[\"Actual Close Price\"], df_filtered[\"Predicted Close Price\"], label=f\"Pearson R: {pearson_r:.4f}\", color=\"green\", alpha=0.6)\n",
        "plt.xlabel(\"Actual Close Price\")\n",
        "plt.ylabel(\"Claude Predictions\")\n",
        "plt.title(\"Pearson Correlation: Claude vs Actual Prices\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# ✅ Print Results\n",
        "print(f\"\\n📊 Comparison Results:\")\n",
        "print(f\"🔹 MAPE: {mape:.4f}\")\n",
        "print(f\"🔹 RMSE: {rmse:.4f}\")\n",
        "print(f\"🔹 Pearson R Correlation: {pearson_r:.4f}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "IDD7RGe6VNTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔹 Load the numerical prediction CSV files\n",
        "df_gpt = pd.read_csv(\"gpt4_predictions_jan_jun_2022.csv\")\n",
        "df_actual = pd.read_csv(\"financial_forecasting_cleaned_two.csv\")\n",
        "\n",
        "# 🔹 Standardize column names to match\n",
        "df_actual.rename(columns={\"Adj Close\": \"Actual Close Price\"}, inplace=True)\n",
        "\n",
        "# 🔹 Convert Date column to datetime format\n",
        "df_gpt[\"Date\"] = pd.to_datetime(df_gpt[\"Date\"])\n",
        "df_actual[\"Date\"] = pd.to_datetime(df_actual[\"Date\"])\n",
        "\n",
        "# 🔹 Merge numerical predictions based on Ticker and Date\n",
        "df_merged = pd.merge(df_gpt, df_actual, on=[\"Ticker\", \"Date\"], how=\"inner\")\n",
        "\n",
        "# 🔹 Convert values to numeric and handle missing values\n",
        "df_merged[\"Predicted Close Price\"] = pd.to_numeric(df_merged[\"Predicted Close Price\"], errors='coerce')\n",
        "df_merged[\"Actual Close Price\"] = pd.to_numeric(df_merged[\"Actual Close Price\"], errors='coerce')\n",
        "\n",
        "# 🔹 Drop rows where either value is NaN (due to 'None' or missing values)\n",
        "df_filtered = df_merged.dropna(subset=[\"Predicted Close Price\", \"Actual Close Price\"])\n",
        "\n",
        "# ✅ Compute Metrics\n",
        "mape = mean_absolute_percentage_error(df_filtered[\"Actual Close Price\"], df_filtered[\"Predicted Close Price\"])\n",
        "rmse = np.sqrt(mean_squared_error(df_filtered[\"Actual Close Price\"], df_filtered[\"Predicted Close Price\"]))\n",
        "pearson_r, _ = pearsonr(df_filtered[\"Actual Close Price\"], df_filtered[\"Predicted Close Price\"])\n",
        "\n",
        "# 🔹 Plot MAPE\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(df_filtered.index, abs(df_filtered[\"Actual Close Price\"] - df_filtered[\"Predicted Close Price\"]) / df_filtered[\"Actual Close Price\"], label=\"MAPE\", color=\"blue\", marker=\"o\", linestyle=\"-\")\n",
        "plt.xlabel(\"Predictions\")\n",
        "plt.ylabel(\"MAPE\")\n",
        "plt.title(f\"MAPE Comparison (GPT-4 vs. Actual Data) - Mean: {mape:.4f}\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# 🔹 Plot RMSE\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(df_filtered.index, (df_filtered[\"Actual Close Price\"] - df_filtered[\"Predicted Close Price\"])**2, label=\"RMSE\", color=\"red\", marker=\"o\", linestyle=\"-\")\n",
        "plt.xlabel(\"Predictions\")\n",
        "plt.ylabel(\"RMSE\")\n",
        "plt.title(f\"RMSE Comparison (GPT-4 vs. Actual Data) - RMSE: {rmse:.4f}\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# 🔹 Plot Pearson R Correlation\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.scatter(df_filtered[\"Actual Close Price\"], df_filtered[\"Predicted Close Price\"], label=f\"Pearson R: {pearson_r:.4f}\", color=\"green\", alpha=0.6)\n",
        "plt.xlabel(\"Actual Close Price\")\n",
        "plt.ylabel(\"GPT-4 Predictions\")\n",
        "plt.title(\"Pearson Correlation: GPT-4 vs Actual Prices\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# ✅ Print Results\n",
        "print(f\"\\n📊 Comparison Results:\")\n",
        "print(f\"🔹 MAPE: {mape:.4f}\")\n",
        "print(f\"🔹 RMSE: {rmse:.4f}\")\n",
        "print(f\"🔹 Pearson R Correlation: {pearson_r:.4f}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "1btYGqYkVfsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "# 🔹 Load the numerical prediction CSV files\n",
        "df_gemini = pd.read_csv(\"gemini_predictions_jan_jun_2022.csv\")\n",
        "df_actual = pd.read_csv(\"financial_forecasting_cleaned_two.csv\")\n",
        "\n",
        "# 🔹 Standardize column names to match\n",
        "df_actual.rename(columns={\"Adj Close\": \"Actual Close Price\"}, inplace=True)\n",
        "\n",
        "# 🔹 Convert Date column to datetime format\n",
        "df_gemini[\"Date\"] = pd.to_datetime(df_gemini[\"Date\"])\n",
        "df_actual[\"Date\"] = pd.to_datetime(df_actual[\"Date\"])\n",
        "\n",
        "# 🔹 Merge numerical predictions based on Ticker and Date\n",
        "df_merged = pd.merge(df_gemini, df_actual, on=[\"Ticker\", \"Date\"], how=\"inner\")\n",
        "\n",
        "# 🔹 Convert values to numeric and handle missing values\n",
        "df_merged[\"Predicted Close Price\"] = pd.to_numeric(df_merged[\"Predicted Close Price\"], errors='coerce')\n",
        "df_merged[\"Actual Close Price\"] = pd.to_numeric(df_merged[\"Actual Close Price\"], errors='coerce')\n",
        "\n",
        "# 🔹 Drop rows where either value is NaN (due to 'None' or missing values)\n",
        "df_filtered = df_merged.dropna(subset=[\"Predicted Close Price\", \"Actual Close Price\"])\n",
        "\n",
        "# ✅ Compute Metrics\n",
        "mape = mean_absolute_percentage_error(df_filtered[\"Actual Close Price\"], df_filtered[\"Predicted Close Price\"])\n",
        "rmse = np.sqrt(mean_squared_error(df_filtered[\"Actual Close Price\"], df_filtered[\"Predicted Close Price\"]))\n",
        "pearson_r, _ = pearsonr(df_filtered[\"Actual Close Price\"], df_filtered[\"Predicted Close Price\"])\n",
        "\n",
        "# 🔹 Plot MAPE (Gemini vs Actual)\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(df_filtered.index, abs(df_filtered[\"Actual Close Price\"] - df_filtered[\"Predicted Close Price\"]) / df_filtered[\"Actual Close Price\"], label=\"MAPE\", color=\"blue\", marker=\"o\", linestyle=\"-\")\n",
        "plt.xlabel(\"Predictions\")\n",
        "plt.ylabel(\"MAPE\")\n",
        "plt.title(f\"MAPE Comparison (Gemini vs. Actual Data) - Mean: {mape:.4f}\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# 🔹 Plot RMSE (Gemini vs Actual)\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(df_filtered.index, (df_filtered[\"Actual Close Price\"] - df_filtered[\"Predicted Close Price\"])**2, label=\"RMSE\", color=\"red\", marker=\"o\", linestyle=\"-\")\n",
        "plt.xlabel(\"Predictions\")\n",
        "plt.ylabel(\"RMSE\")\n",
        "plt.title(f\"RMSE Comparison (Gemini vs. Actual Data) - RMSE: {rmse:.4f}\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# 🔹 Plot Pearson R Correlation (Gemini vs Actual)\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.scatter(df_filtered[\"Actual Close Price\"], df_filtered[\"Predicted Close Price\"], label=f\"Pearson R: {pearson_r:.4f}\", color=\"green\", alpha=0.6)\n",
        "plt.xlabel(\"Actual Close Price\")\n",
        "plt.ylabel(\"Gemini Predictions\")\n",
        "plt.title(\"Pearson Correlation: Gemini vs Actual Prices\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# ✅ Print Results\n",
        "print(f\"\\n📊 Comparison Results:\")\n",
        "print(f\"🔹 MAPE: {mape:.4f}\")\n",
        "print(f\"🔹 RMSE: {rmse:.4f}\")\n",
        "print(f\"🔹 Pearson R Correlation: {pearson_r:.4f}\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "pAW2tXe5ALHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 🔹 Load the reward scores CSV\n",
        "df_rewards = pd.read_csv(\"gemini_reward_scores_training.csv\")\n",
        "\n",
        "# 🔹 Generate X-axis values (Number of closing prices processed)\n",
        "num_prices_processed = list(range(1, len(df_rewards) + 1))  # Sequential numbering\n",
        "\n",
        "# 🔹 Extract Reward Scores\n",
        "reward_scores = df_rewards[\"Reward Score\"]\n",
        "\n",
        "# 🔹 Plot the Reward Score Trend\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(num_prices_processed, reward_scores, marker=\"o\", linestyle=\"-\", color=\"blue\", label=\"Reward Score\")\n",
        "\n",
        "# 🔹 Graph Labels & Customization\n",
        "plt.xlabel(\"Number of Closing Prices Processed\")\n",
        "plt.ylabel(\"Reward Score\")\n",
        "plt.title(\"Gemini Training Reward Score vs. Number of Closing Prices Processed\")\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
        "\n",
        "# 📈 Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "2oBz0UuSGB2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Claude Time taken = \" + str(totalClaudetime))\n",
        "print(\"GPT Time taken = \" + str(totalGPTtime))\n",
        "print(\"Gemini Time taken = \" + str(totalGeminitime))\n",
        "\n",
        "models = [\"Claude\", \"GPT-4\", \"Gemini\"]\n",
        "time_taken = [totalClaudetime, totalGPTtime, totalGeminitime]\n",
        "\n",
        "# Create bar plot\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(models, time_taken, color=['blue', 'red', 'green'])\n",
        "\n",
        "# Labels and title\n",
        "plt.xlabel(\"Model\")\n",
        "plt.ylabel(\"Time Taken (minutes)\")\n",
        "plt.title(\"Comparison of Time Taken for Claude, GPT-4, and Gemini\")\n",
        "\n",
        "# Show grid and plot\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Q_aGdHt-6Xto",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ClaudeAccuracy=numofactualCValues/numofClaudeValues\n",
        "GPTAccuracy=numofGPTvalues/numofactualvalues\n",
        "#LlamaAccuracy=numofactualLvalues/numofLlamaValues\n",
        "GeminiAccuracy=numofactualGvalues/numofGeminivalues\n",
        "\n",
        "print(\"Claude Accuracy = \" + str(ClaudeAccuracy))\n",
        "print(\"GPT Accuracy = \" + str(GPTAccuracy))\n",
        "print(\"Gemini Accuracy = \" + str(GeminiAccuracy))\n",
        "\n",
        "models = [\"Claude\", \"GPT-4\", \"Gemini\"]\n",
        "accuracy = [ClaudeAccuracy,GPTAccuracy,GeminiAccuracy]\n",
        "\n",
        "# Create bar plot\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(models, accuracy, color=['blue', 'red', 'green'])\n",
        "\n",
        "# Labels and title\n",
        "plt.xlabel(\"Model\")\n",
        "plt.ylabel(\"% of values which generated results\")\n",
        "plt.title(\"Comparison of Accuracy for Claude, GPT-4, and Gemini\")\n",
        "\n",
        "# Show grid and plot\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9vof6nMG_VgX",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}