{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "NaE6jgBxxyef",
        "outputId": "6dc59f0a-75c6-4499-e334-b61c419e2e77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fredapi in /usr/local/lib/python3.11/dist-packages (0.5.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: yahoo_fin in /usr/local/lib/python3.11/dist-packages (0.8.9.1)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.11/dist-packages (0.0.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.11/dist-packages (0.28.0)\n",
            "Requirement already satisfied: anthropic in /usr/local/lib/python3.11/dist-packages (0.49.0)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.4)\n",
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.11/dist-packages (0.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (3.11.15)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from fredapi) (2.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: requests-html in /usr/local/lib/python3.11/dist-packages (from yahoo_fin) (0.10.0)\n",
            "Requirement already satisfied: feedparser in /usr/local/lib/python3.11/dist-packages (from yahoo_fin) (6.0.11)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from bs4) (4.13.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (2.11.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from anthropic) (4.13.2)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.24.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.164.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.4)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge_score) (2.0.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->anthropic) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.4.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.19.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->bs4) (2.6)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.11/dist-packages (from feedparser->yahoo_fin) (1.0.0)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (2024.11.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->fredapi) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->fredapi) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->fredapi) (2025.2)\n",
            "Requirement already satisfied: pyquery in /usr/local/lib/python3.11/dist-packages (from requests-html->yahoo_fin) (2.0.1)\n",
            "Requirement already satisfied: fake-useragent in /usr/local/lib/python3.11/dist-packages (from requests-html->yahoo_fin) (2.2.0)\n",
            "Requirement already satisfied: parse in /usr/local/lib/python3.11/dist-packages (from requests-html->yahoo_fin) (1.20.2)\n",
            "Requirement already satisfied: w3lib in /usr/local/lib/python3.11/dist-packages (from requests-html->yahoo_fin) (2.3.1)\n",
            "Requirement already satisfied: pyppeteer>=0.0.14 in /usr/local/lib/python3.11/dist-packages (from requests-html->yahoo_fin) (2.0.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in /usr/local/lib/python3.11/dist-packages (from pyppeteer>=0.0.14->requests-html->yahoo_fin) (1.4.4)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.11/dist-packages (from pyppeteer>=0.0.14->requests-html->yahoo_fin) (8.6.1)\n",
            "Requirement already satisfied: pyee<12.0.0,>=11.0.0 in /usr/local/lib/python3.11/dist-packages (from pyppeteer>=0.0.14->requests-html->yahoo_fin) (11.1.1)\n",
            "Requirement already satisfied: websockets<11.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from pyppeteer>=0.0.14->requests-html->yahoo_fin) (10.4)\n",
            "Requirement already satisfied: lxml>=2.1 in /usr/local/lib/python3.11/dist-packages (from pyquery->requests-html->yahoo_fin) (5.3.2)\n",
            "Requirement already satisfied: cssselect>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from pyquery->requests-html->yahoo_fin) (1.3.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-html->yahoo_fin) (3.21.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install fredapi requests yahoo_fin bs4 tabulate openai==0.28 anthropic google-generativeai rouge_score\n",
        "\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import random\n",
        "from fredapi import Fred\n",
        "import requests\n",
        "from yahoo_fin import news\n",
        "from bs4 import BeautifulSoup\n",
        "from tabulate import tabulate\n",
        "import random\n",
        "import openai\n",
        "import anthropic\n",
        "#from llama_cpp import Llama\n",
        "import google.generativeai as genai\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "baBhwg_xcuRW",
        "outputId": "c8eda9c5-36c7-4f10-a39a-5ce676fbb421"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "import re\n",
        "import random\n",
        "import nltk\n",
        "import pandas as pd\n",
        "from yahoo_fin import news\n",
        "from datetime import datetime, timedelta\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "import time\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qW34_Iqe4MiE",
        "outputId": "d74c2d08-e284-4b7f-a9bc-fe4890d313c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. What the falling US dollar has historically meant for stocks: By the numbers\n",
            "2. Market Chatter: European Commission President Asks X, Meta, TikTok to Comply With EU Digital Rulebook\n",
            "3. Apple may have a key problem bringing back manufacturing to beat Trump tariffs, former Intel CEO warns\n",
            "4. EU says it will enforce digital rules irrespective of CEO and location\n",
            "5. 1 \"Magnificent Seven\" Stock You'll Regret Not Buying During the Dip\n",
            "6. TSMC Warns of Limits of Ability to Keep Its AI Chips From China\n",
            "7. Trump Raised Record $239 Million for Inaugural Festivities\n",
            "8. Big Tech's \"Magnificent Seven\" heads into earnings season reeling from Trump turbulence\n",
            "9. Street Calls of the Week\n",
            "10. 2 Semiconductor Stocks That Could Help Make You a Fortune\n"
          ]
        }
      ],
      "source": [
        "#Financial News Articles - For Stock (readily available w/ ticker)\n",
        "from yahoo_fin import news\n",
        "\n",
        "latest_news = news.get_yf_rss('AAPL')\n",
        "\n",
        "for i, article in enumerate(latest_news[:10], start=1):\n",
        "    print(f\"{i}. {article['title']}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "GzjNzoxo4bGU",
        "outputId": "4a0c7aa3-5882-4871-8168-3b91d14a27cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ”¹ Downloading missing NLTK resource: stopwords\n",
            "ğŸ”¹ Downloading missing NLTK resource: wordnet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“Š Processed Historical Financial News:\n",
            "\n",
            "â•’â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••\n",
            "â”‚    â”‚ Ticker   â”‚ Date       â”‚ Original Title                                                                                               â”‚ Cleaned Title                                                                                  â”‚ Link                                                                                                                                                              â”‚\n",
            "â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
            "â”‚  0 â”‚ SO       â”‚ 2016-08-13 â”‚ The Southern Company (SO): Among the Best Renewable Energy Stocks to Buy in 2025                             â”‚ southern company among best renewable energy stock buy 2025                                    â”‚ https://finance.yahoo.com/news/southern-company-among-best-renewable-201247281.html?.tsrc=rss                                                                     â”‚\n",
            "â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚  1 â”‚ VLO      â”‚ 2012-10-16 â”‚ Valero Energy to Report Q1 Earnings: What's in the Cards?                                                    â”‚ valero energy report q1 earnings whats card                                                    â”‚ https://finance.yahoo.com/news/valero-energy-report-q1-earnings-123400086.html?.tsrc=rss                                                                          â”‚\n",
            "â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚  2 â”‚ IBM      â”‚ 2021-11-19 â”‚ Google, Tesla, and IBM earnings lead a make-or-break week for stocks                                         â”‚ google tesla ibm earnings lead makeorbreak week stock                                          â”‚ https://finance.yahoo.com/news/google-tesla-ibm-earnings-lead-110000181.html?.tsrc=rss                                                                            â”‚\n",
            "â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚  3 â”‚ EMR      â”‚ 2015-04-26 â”‚ Here is What to Know Beyond Why Emerson Electric Co. (EMR) is a Trending Stock                               â”‚ know beyond emerson electric co emr trending stock                                             â”‚ https://finance.yahoo.com/news/know-beyond-why-emerson-electric-130010317.html?.tsrc=rss                                                                          â”‚\n",
            "â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚  4 â”‚ DE       â”‚ 2016-12-17 â”‚ CAT Vs DE: Which Heavy Machinery Stock is the Better Bet Now?                                                â”‚ cat v de heavy machinery stock better bet                                                      â”‚ https://finance.yahoo.com/news/cat-vs-heavy-machinery-stock-155900128.html?.tsrc=rss                                                                              â”‚\n",
            "â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚  5 â”‚ DOW      â”‚ 2017-10-28 â”‚ When Should You Buy Dow Inc. (NYSE:DOW)?                                                                     â”‚ buy dow inc nysedow                                                                            â”‚ https://finance.yahoo.com/news/buy-dow-inc-nyse-dow-183238512.html?.tsrc=rss                                                                                      â”‚\n",
            "â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚  6 â”‚ NEM      â”‚ 2020-08-13 â”‚ Gold miners shares rise as bullion hits record high                                                          â”‚ gold miner share rise bullion hit record high                                                  â”‚ https://finance.yahoo.com/news/gold-miners-shares-rise-bullion-122438420.html?.tsrc=rss                                                                           â”‚\n",
            "â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚  7 â”‚ MO       â”‚ 2020-04-22 â”‚ Altria Group, Inc. (MO): One of the Safe Dividend Stocks with Yields Above 5%                                â”‚ altria group inc mo one safe dividend stock yield 5                                            â”‚ https://finance.yahoo.com/news/altria-group-inc-mo-one-141944060.html?.tsrc=rss                                                                                   â”‚\n",
            "â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚  8 â”‚ EMR      â”‚ 2013-10-20 â”‚ Here is What to Know Beyond Why Emerson Electric Co. (EMR) is a Trending Stock                               â”‚ know beyond emerson electric co emr trending stock                                             â”‚ https://finance.yahoo.com/news/know-beyond-why-emerson-electric-130010317.html?.tsrc=rss                                                                          â”‚\n",
            "â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚  9 â”‚ AMZN     â”‚ 2015-11-08 â”‚ Amazon stock falls as Raymond James downgrades shares, citing tariff headwinds and 'limited' AI monetization â”‚ amazon stock fall raymond james downgrade share citing tariff headwind limited ai monetization â”‚ https://finance.yahoo.com/news/amazon-stock-falls-as-raymond-james-downgrades-shares-citing-tariff-headwinds-and-limited-ai-monetization-144747355.html?.tsrc=rss â”‚\n",
            "â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ 10 â”‚ AMZN     â”‚ 2011-02-03 â”‚ Amazon stock falls as Raymond James downgrades shares, citing tariff headwinds and 'limited' AI monetization â”‚ amazon stock fall raymond james downgrade share citing tariff headwind limited ai monetization â”‚ https://finance.yahoo.com/news/amazon-stock-falls-as-raymond-james-downgrades-shares-citing-tariff-headwinds-and-limited-ai-monetization-144747355.html?.tsrc=rss â”‚\n",
            "â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ 11 â”‚ SLB      â”‚ 2013-12-31 â”‚ Schlumberger (SLB) Expected to Beat Earnings Estimates: Can the Stock Move Higher?                           â”‚ schlumberger slb expected beat earnings estimate stock move higher                             â”‚ https://finance.yahoo.com/news/schlumberger-slb-expected-beat-earnings-140017458.html?.tsrc=rss                                                                   â”‚\n",
            "â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ 12 â”‚ UNH      â”‚ 2016-03-25 â”‚ These Stocks Are Moving the Most Today: Netflix, Tesla, Nvidia, Amazon, Discover, Salesforce, and More       â”‚ stock moving today netflix tesla nvidia amazon discover salesforce                             â”‚ https://finance.yahoo.com/m/a9118993-25f1-3b30-beee-58f562ad5dca/these-stocks-are-moving-the.html?.tsrc=rss                                                       â”‚\n",
            "â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ 13 â”‚ FDX      â”‚ 2014-10-12 â”‚ FedEx Corporation (FDX) Fell in Q1 due to Macro Headwinds                                                    â”‚ fedex corporation fdx fell q1 due macro headwind                                               â”‚ https://finance.yahoo.com/news/fedex-corporation-fdx-fell-q1-122145149.html?.tsrc=rss                                                                             â”‚\n",
            "â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ 14 â”‚ IBM      â”‚ 2017-09-30 â”‚ Google, Tesla, and IBM earnings lead a make-or-break week for stocks                                         â”‚ google tesla ibm earnings lead makeorbreak week stock                                          â”‚ https://finance.yahoo.com/news/google-tesla-ibm-earnings-lead-110000181.html?.tsrc=rss                                                                            â”‚\n",
            "â•˜â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›\n",
            "Processed financial news saved to 'historical_financial_news.csv'\n"
          ]
        }
      ],
      "source": [
        "#preprocessing training data\n",
        "nltk_resources = [\"punkt\", \"stopwords\", \"wordnet\"]\n",
        "\n",
        "for resource in nltk_resources:\n",
        "    try:\n",
        "        nltk.data.find(f\"tokenizers/{resource}\")\n",
        "    except LookupError:\n",
        "        print(f\"ğŸ”¹ Downloading missing NLTK resource: {resource}\")\n",
        "        nltk.download(resource)\n",
        "\n",
        "\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "import re\n",
        "import random\n",
        "import nltk\n",
        "import pandas as pd\n",
        "from yahoo_fin import news\n",
        "from datetime import datetime, timedelta\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# ğŸ”¹ Download necessary NLTK resources (only needed once)\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"wordnet\")\n",
        "\n",
        "# ğŸ”¹ Initialize NLP components\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# ğŸ”¹ List of S&P 500 stock tickers (expandable)\n",
        "sp500_tickers = [\n",
        "    \"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"TSLA\", \"NVDA\", \"FB\", \"JPM\", \"V\", \"DIS\",\n",
        "    \"PG\", \"MA\", \"NFLX\", \"INTC\", \"PYPL\", \"PFE\", \"PEP\", \"KO\", \"CSCO\", \"XOM\",\n",
        "    \"IBM\", \"GE\", \"BA\", \"GS\", \"C\", \"ADBE\", \"NFLX\", \"T\", \"UNH\", \"MRK\",\n",
        "    \"MMM\", \"LMT\", \"MDT\", \"CAT\", \"MO\", \"HON\", \"F\", \"GM\", \"MCD\", \"WMT\",\n",
        "    \"NKE\", \"CVX\", \"TMO\", \"ORCL\", \"DOW\", \"SO\", \"DUK\", \"AEP\", \"USB\", \"MET\",\n",
        "    \"BK\", \"TGT\", \"BLK\", \"SCHW\", \"CME\", \"AON\", \"SPGI\", \"MS\", \"AXP\", \"CI\",\n",
        "    \"ISRG\", \"ZTS\", \"PLD\", \"DE\", \"ADP\", \"SYK\", \"GILD\", \"GM\", \"TFC\", \"CSX\",\n",
        "    \"EL\", \"FDX\", \"EMR\", \"ECL\", \"ADI\", \"MMC\", \"WM\", \"AMT\", \"SLB\", \"AIG\",\n",
        "    \"CTSH\", \"DHR\", \"NSC\", \"COF\", \"DG\", \"FIS\", \"PGR\", \"ITW\", \"CDNS\", \"APD\",\n",
        "    \"AFL\", \"OXY\", \"VLO\", \"HES\", \"PSX\", \"TRGP\", \"MRO\", \"HAL\", \"NEM\", \"BKR\"\n",
        "]\n",
        "\n",
        "# ğŸ”¹ Function to generate a random date between 2011 and 2021\n",
        "def random_date():\n",
        "    start_date = datetime(2011, 1, 1)\n",
        "    end_date = datetime(2021, 12, 31)\n",
        "    return start_date + timedelta(days=random.randint(0, (end_date - start_date).days))\n",
        "\n",
        "# ğŸ”¹ Function to clean and preprocess text\n",
        "def clean_text(text):\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "    words = word_tokenize(text)  # Tokenization\n",
        "    words = [word for word in words if word not in stop_words]  # Remove stopwords\n",
        "    words = [lemmatizer.lemmatize(word) for word in words]  # Lemmatization\n",
        "    return \" \".join(words)\n",
        "\n",
        "# ğŸ”¹ Fetch and process financial news for at least 100 random ticker-date pairs\n",
        "news_data = []\n",
        "attempts = 0\n",
        "\n",
        "while len(news_data) < 150 and attempts < 2000:\n",
        "    attempts += 1\n",
        "    ticker = random.choice(sp500_tickers)\n",
        "    date = random_date().strftime('%Y-%m-%d')\n",
        "\n",
        "    try:\n",
        "\n",
        "        latest_news = news.get_yf_rss(ticker)\n",
        "\n",
        "        if latest_news:\n",
        "            for article in latest_news[:1]:\n",
        "                title = article[\"title\"]\n",
        "                link = article[\"link\"]\n",
        "                cleaned_title = clean_text(title)\n",
        "\n",
        "                news_data.append({\n",
        "                    \"Ticker\": ticker,\n",
        "                    \"Date\": date,\n",
        "                    \"Original Title\": title,\n",
        "                    \"Cleaned Title\": cleaned_title,\n",
        "                    \"Link\": link\n",
        "                })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ Error fetching news for {ticker} on {date}: {e}\")\n",
        "\n",
        "df_news = pd.DataFrame(news_data)\n",
        "\n",
        "import tabulate\n",
        "print(\"\\nğŸ“Š Processed Historical Financial News:\\n\")\n",
        "print(tabulate.tabulate(df_news.head(100), headers=\"keys\", tablefmt=\"fancy_grid\"))\n",
        "\n",
        "df_news.to_csv(\"historical_financial_news.csv\", index=False)\n",
        "print(\"Processed financial news saved to 'historical_financial_news.csv'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "zfZKUMyhykxP",
        "outputId": "c78b1a69-f416-4e1e-f11f-be253573f4d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ”¹ Downloading missing NLTK resource: stopwords\n",
            "ğŸ”¹ Downloading missing NLTK resource: wordnet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“Š Processed Recent Financial News:\n",
            "\n",
            "â•’â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••\n",
            "â”‚    â”‚ Ticker   â”‚ Date       â”‚ Original Title                                                                                         â”‚ Cleaned Title                                                                              â”‚ Link                                                                                                                                                                                                                                                â”‚\n",
            "â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
            "â”‚  0 â”‚ NVDA     â”‚ 2024-06-14 â”‚ The Dow plunges 800 points and the Nasdaq reels as Trump blames Powell and Tesla adds to tech woes     â”‚ dow plunge 800 point nasdaq reel trump blame powell tesla add tech woe                     â”‚ https://finance.yahoo.com/news/dow-drops-400-points-nasdaq-122200277.html?.tsrc=rss                                                                                                                                                                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚  1 â”‚ SO       â”‚ 2024-11-09 â”‚ The Southern Company (SO): Among the Best Renewable Energy Stocks to Buy in 2025                       â”‚ southern company among best renewable energy stock buy 2025                                â”‚ https://finance.yahoo.com/news/southern-company-among-best-renewable-201247281.html?.tsrc=rss                                                                                                                                                       â”‚\n",
            "â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚  2 â”‚ INTC     â”‚ 2023-04-30 â”‚ Apple may have a key problem bringing back manufacturing to beat Trump tariffs, former Intel CEO warns â”‚ apple may key problem bringing back manufacturing beat trump tariff former intel ceo warns â”‚ https://finance.yahoo.com/news/apple-may-have-a-key-problem-bringing-back-manufacturing-to-beat-trump-tariffs-former-intel-ceo-warns-132151346.html?.tsrc=rss                                                                                       â”‚\n",
            "â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚  3 â”‚ ISRG     â”‚ 2024-07-15 â”‚ Earnings To Watch: Intuitive Surgical (ISRG) Reports Q1 Results Tomorrow                               â”‚ earnings watch intuitive surgical isrg report q1 result tomorrow                           â”‚ https://finance.yahoo.com/news/earnings-watch-intuitive-surgical-isrg-120148496.html?.tsrc=rss                                                                                                                                                      â”‚\n",
            "â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚  4 â”‚ CSCO     â”‚ 2024-10-21 â”‚ 3 Magnificent S&P 500 Dividend Stocks Down 11% to 63% to Buy and Hold Forever                          â”‚ 3 magnificent sp 500 dividend stock 11 63 buy hold forever                                 â”‚ https://www.fool.com/investing/2025/04/18/3-magnificent-sp-500-dividend-stocks-down-11-to-63/?source=eptyholnk0000202&utm_source=yahoo-host-full&utm_medium=feed&utm_campaign=article&referring_guid=9a09f08b-0e18-40b6-b18a-6ff39643e7af&.tsrc=rss â”‚\n",
            "â•˜â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›\n",
            "Processed financial news saved to 'evaluation_financial_news.csv'\n"
          ]
        }
      ],
      "source": [
        "#preprocessing evaluation data\n",
        "nltk_resources = [\"punkt\", \"stopwords\", \"wordnet\"]\n",
        "\n",
        "for resource in nltk_resources:\n",
        "    try:\n",
        "        nltk.data.find(f\"tokenizers/{resource}\")\n",
        "    except LookupError:\n",
        "        print(f\"ğŸ”¹ Downloading missing NLTK resource: {resource}\")\n",
        "        nltk.download(resource)\n",
        "\n",
        "\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "\n",
        "\n",
        "# ğŸ”¹ Download necessary NLTK resources (only needed once)\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"wordnet\")\n",
        "\n",
        "# ğŸ”¹ Initialize NLP components\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# ğŸ”¹ List of S&P 500 stock tickers (expandable)\n",
        "sp500_tickers = [\n",
        "    \"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"TSLA\", \"NVDA\", \"FB\", \"JPM\", \"V\", \"DIS\",\n",
        "    \"PG\", \"MA\", \"NFLX\", \"INTC\", \"PYPL\", \"PFE\", \"PEP\", \"KO\", \"CSCO\", \"XOM\",\n",
        "    \"IBM\", \"GE\", \"BA\", \"GS\", \"C\", \"ADBE\", \"NFLX\", \"T\", \"UNH\", \"MRK\",\n",
        "    \"MMM\", \"LMT\", \"MDT\", \"CAT\", \"MO\", \"HON\", \"F\", \"GM\", \"MCD\", \"WMT\",\n",
        "    \"NKE\", \"CVX\", \"TMO\", \"ORCL\", \"DOW\", \"SO\", \"DUK\", \"AEP\", \"USB\", \"MET\",\n",
        "    \"BK\", \"TGT\", \"BLK\", \"SCHW\", \"CME\", \"AON\", \"SPGI\", \"MS\", \"AXP\", \"CI\",\n",
        "    \"ISRG\", \"ZTS\", \"PLD\", \"DE\", \"ADP\", \"SYK\", \"GILD\", \"GM\", \"TFC\", \"CSX\",\n",
        "    \"EL\", \"FDX\", \"EMR\", \"ECL\", \"ADI\", \"MMC\", \"WM\", \"AMT\", \"SLB\", \"AIG\",\n",
        "    \"CTSH\", \"DHR\", \"NSC\", \"COF\", \"DG\", \"FIS\", \"PGR\", \"ITW\", \"CDNS\", \"APD\",\n",
        "    \"AFL\", \"OXY\", \"VLO\", \"HES\", \"PSX\", \"TRGP\", \"MRO\", \"HAL\", \"NEM\", \"BKR\"\n",
        "]\n",
        "\n",
        "# ğŸ”¹ Function to generate a random date between 2011 and 2021\n",
        "def random_date():\n",
        "    start_date = datetime(2022, 1, 1)\n",
        "    end_date = datetime(2024, 12, 31)\n",
        "    return start_date + timedelta(days=random.randint(0, (end_date - start_date).days))\n",
        "\n",
        "# ğŸ”¹ Function to clean and preprocess text\n",
        "def clean_text(text):\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "    words = word_tokenize(text)  # Tokenization\n",
        "    words = [word for word in words if word not in stop_words]  # Remove stopwords\n",
        "    words = [lemmatizer.lemmatize(word) for word in words]  # Lemmatization\n",
        "    return \" \".join(words)\n",
        "\n",
        "# ğŸ”¹ Fetch and process financial news for at least 100 random ticker-date pairs\n",
        "news_data = []\n",
        "attempts = 0\n",
        "\n",
        "while len(news_data) < 45 and attempts < 2000:\n",
        "    attempts += 1\n",
        "    ticker = random.choice(sp500_tickers)\n",
        "    date = random_date().strftime('%Y-%m-%d')\n",
        "\n",
        "    try:\n",
        "\n",
        "        latest_news = news.get_yf_rss(ticker)\n",
        "\n",
        "        if latest_news:\n",
        "            for article in latest_news[:1]:\n",
        "                title = article[\"title\"]\n",
        "                link = article[\"link\"]\n",
        "                cleaned_title = clean_text(title)\n",
        "\n",
        "                news_data.append({\n",
        "                    \"Ticker\": ticker,\n",
        "                    \"Date\": date,\n",
        "                    \"Original Title\": title,\n",
        "                    \"Cleaned Title\": cleaned_title,\n",
        "                    \"Link\": link\n",
        "                })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ Error fetching news for {ticker} on {date}: {e}\")\n",
        "\n",
        "df_news = pd.DataFrame(news_data)\n",
        "\n",
        "import tabulate\n",
        "print(\"\\nğŸ“Š Processed Recent Financial News:\\n\")\n",
        "print(tabulate.tabulate(df_news.head(100), headers=\"keys\", tablefmt=\"fancy_grid\"))\n",
        "\n",
        "df_news.to_csv(\"evaluation_financial_news.csv\", index=False)\n",
        "print(\"Processed financial news saved to 'evaluation_financial_news.csv'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "FBPl7720jZf8",
        "outputId": "19d042c0-fa97-4dad-e1f1-52c1d523860f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“Š VADER Sentiment Analysis Results:\n",
            "\n",
            "  Ticker        Date                                      Cleaned Title  \\\n",
            "0     SO  2016-08-13  southern company among best renewable energy s...   \n",
            "1    VLO  2012-10-16        valero energy report q1 earnings whats card   \n",
            "2    IBM  2021-11-19  google tesla ibm earnings lead makeorbreak wee...   \n",
            "3    EMR  2015-04-26  know beyond emerson electric co emr trending s...   \n",
            "4     DE  2016-12-17          cat v de heavy machinery stock better bet   \n",
            "5    DOW  2017-10-28                                buy dow inc nysedow   \n",
            "6    NEM  2020-08-13      gold miner share rise bullion hit record high   \n",
            "7     MO  2020-04-22  altria group inc mo one safe dividend stock yi...   \n",
            "8    EMR  2013-10-20  know beyond emerson electric co emr trending s...   \n",
            "9   AMZN  2015-11-08  amazon stock fall raymond james downgrade shar...   \n",
            "\n",
            "   Sentiment Score Sentiment  \n",
            "0           0.7430  Positive  \n",
            "1           0.2732  Positive  \n",
            "2           0.0000   Neutral  \n",
            "3           0.0000   Neutral  \n",
            "4           0.4404  Positive  \n",
            "5           0.0000   Neutral  \n",
            "6           0.2960  Positive  \n",
            "7           0.4404  Positive  \n",
            "8           0.0000   Neutral  \n",
            "9           0.2500  Positive  \n",
            "\n",
            "âœ… Sentiment analysis results saved to 'vader_sentiment_analysis_results.csv'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#vader sentiment analysis on training data\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "df_news = pd.read_csv(\"historical_financial_news.csv\")\n",
        "\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "df_news[\"Sentiment Score\"] = df_news[\"Cleaned Title\"].apply(lambda text: sia.polarity_scores(str(text))[\"compound\"])\n",
        "\n",
        "df_news[\"Sentiment\"] = df_news[\"Sentiment Score\"].apply(\n",
        "    lambda score: \"Positive\" if score > 0.05 else \"Negative\" if score < -0.05 else \"Neutral\"\n",
        ")\n",
        "\n",
        "print(\"\\nğŸ“Š VADER Sentiment Analysis Results:\\n\")\n",
        "print(df_news[[\"Ticker\", \"Date\", \"Cleaned Title\", \"Sentiment Score\", \"Sentiment\"]].head(10))\n",
        "\n",
        "df_news.to_csv(\"vader_sentiment_analysis_results.csv\", index=False)\n",
        "print(\"\\nâœ… Sentiment analysis results saved to 'vader_sentiment_analysis_results.csv'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sHgziNhex6yw",
        "outputId": "a85c1c9b-8582-4876-c08f-cd43baf43748"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“Š VADER Sentiment Analysis Results (2022-2024):\n",
            "\n",
            "  Ticker        Date                                      Cleaned Title  \\\n",
            "0   NVDA  2024-06-14  dow plunge 800 point nasdaq reel trump blame p...   \n",
            "1     SO  2024-11-09  southern company among best renewable energy s...   \n",
            "2   INTC  2023-04-30  apple may key problem bringing back manufactur...   \n",
            "3   ISRG  2024-07-15  earnings watch intuitive surgical isrg report ...   \n",
            "4   CSCO  2024-10-21  3 magnificent sp 500 dividend stock 11 63 buy ...   \n",
            "\n",
            "   Sentiment Score Sentiment  \n",
            "0          -0.6369  Negative  \n",
            "1           0.7430  Positive  \n",
            "2          -0.4767  Negative  \n",
            "3           0.0000   Neutral  \n",
            "4           0.5994  Positive  \n",
            "\n",
            "âœ… Sentiment analysis results saved to 'vader_sentiment_analysis_results_2022_2024.csv'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#VADER sentiment analysis on evaluation data\n",
        "\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "df_eval_news = pd.read_csv(\"evaluation_financial_news.csv\")\n",
        "\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "df_eval_news[\"Sentiment Score\"] = df_eval_news[\"Cleaned Title\"].apply(lambda text: sia.polarity_scores(str(text))[\"compound\"])\n",
        "\n",
        "df_eval_news[\"Sentiment\"] = df_eval_news[\"Sentiment Score\"].apply(\n",
        "    lambda score: \"Positive\" if score > 0.05 else \"Negative\" if score < -0.05 else \"Neutral\"\n",
        ")\n",
        "\n",
        "print(\"\\nğŸ“Š VADER Sentiment Analysis Results (2022-2024):\\n\")\n",
        "print(df_eval_news[[\"Ticker\", \"Date\", \"Cleaned Title\", \"Sentiment Score\", \"Sentiment\"]].head(10))\n",
        "\n",
        "df_eval_news.to_csv(\"vader_sentiment_analysis_results_2022_2024.csv\", index=False)\n",
        "print(\"\\nâœ… Sentiment analysis results saved to 'vader_sentiment_analysis_results_2022_2024.csv'\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "collapsed": true,
        "id": "aBQoye5Djj59",
        "outputId": "50b8087e-e338-4999-b69b-5fefbb0fb68e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“° Article: southern company among best renewable energy stock buy 2025\n",
            "âœ… Claude Score: 0.78 | VADER Score: 0.743 | Reward: 0.96\n",
            "ğŸ”¹ Current Reward Score: 0.96\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-4dc39f268f8f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# Send the CoT prompt to Claude AI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     response = client.messages.create(\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"claude-3-7-sonnet-20250219\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/anthropic/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/anthropic/resources/messages/messages.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, max_tokens, messages, model, metadata, stop_sequences, stream, system, temperature, thinking, tool_choice, tools, top_k, top_p, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    951\u001b[0m             )\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 953\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    954\u001b[0m             \u001b[0;34m\"/v1/messages\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/anthropic/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1334\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m         )\n\u001b[0;32m-> 1336\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/anthropic/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1011\u001b[0m             \u001b[0mretries_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m   1014\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/anthropic/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m             response = self._client.send(\n\u001b[0m\u001b[1;32m   1050\u001b[0m                 \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m                 \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_stream_response_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[0mauth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_request_auth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m         response = self._send_handling_auth(\n\u001b[0m\u001b[1;32m    915\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m                 response = self._send_handling_redirects(\n\u001b[0m\u001b[1;32m    943\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m                     \u001b[0mfollow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_redirects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    977\u001b[0m                 \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_single_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_hooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"response\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSyncByteStream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_transports/default.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    248\u001b[0m         )\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_httpcore_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close_connections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;31m# Return the response. Note that in this case we still have to manage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    234\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m                     \u001b[0;31m# Send the request on the assigned connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m                     response = connection.handle_request(\n\u001b[0m\u001b[1;32m    237\u001b[0m                         \u001b[0mpool_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m                     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNetworkStream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    134\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"response_closed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_response_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;31m# Sending the request...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    104\u001b[0m                     \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                     \u001b[0mtrailing_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 ) = self._receive_response_headers(**kwargs)\n\u001b[0m\u001b[1;32m    107\u001b[0m                 trace.return_value = (\n\u001b[1;32m    108\u001b[0m                     \u001b[0mhttp_version\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_receive_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEED_DATA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                 data = self._network_stream.read(\n\u001b[0m\u001b[1;32m    218\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREAD_NUM_BYTES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_backends/sync.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1293\u001b[0m                     \u001b[0;34m\"non-zero flags not allowed in calls to recv() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m                     self.__class__)\n\u001b[0;32m-> 1295\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1296\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1166\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1168\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1169\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#Training of Anthropic Claude 3.7 using Chain of Thought prompting and Reinforcement Learning\n",
        "import time\n",
        "begin = time.time()\n",
        "df_news = pd.read_csv(\"historical_financial_news.csv\")\n",
        "df_vader = pd.read_csv(\"vader_sentiment_analysis_results.csv\")\n",
        "\n",
        "# Initialize Anthropic Claude API\n",
        "CLAUDE_API_KEY = \"\"\n",
        "  # Replace with actual API key\n",
        "client = anthropic.Anthropic(api_key=CLAUDE_API_KEY)\n",
        "\n",
        "# Initialize reward tracking\n",
        "reward_score = 0  # Start with neutral reward score\n",
        "previous_vader = None\n",
        "previous_claude = None\n",
        "\n",
        "# Chain-of-Thought (CoT) Prompting Template\n",
        "cot_prompt_template = \"\"\"\n",
        "You are an AI trained in financial sentiment analysis.\n",
        "Analyze the sentiment of the following financial news article step by step. Limit your answer in total to 500 characters.\n",
        "\n",
        "1. **Extract Key Phrases**: Identify important financial terms, events, and entities.\n",
        "2. **Determine Sentiment Score**: Provide a sentiment score between -1 (Negative), 0 (Neutral), and +1 (Positive). Do it to 2 decimal places\n",
        "3. **Explain Sentiment**: Justify the assigned sentiment score based on the financial impact.\n",
        "\n",
        "Example Sentiment Analysis:\n",
        "\n",
        "Article: \"{article}\"\n",
        "---\n",
        "Step 1: Key Phrases â†’ [extracted key phrases]\n",
        "Step 2: Sentiment Score â†’ [Numeric value between -1 and 1]\n",
        "Step 3: Explanation â†’ [detailed reasoning]\n",
        "\n",
        "Final Answer: [Numeric Sentiment Score]\n",
        "\"\"\"\n",
        "\n",
        "# Reinforcement Learning Loop\n",
        "for index, row in df_news.iterrows():\n",
        "    article_text = row[\"Cleaned Title\"]\n",
        "\n",
        "    # Retrieve VADER sentiment score\n",
        "    vader_sentiment = df_vader.loc[df_vader[\"Ticker\"] == row[\"Ticker\"], \"Sentiment Score\"].values[0]\n",
        "\n",
        "    # Update CoT Prompt with Reinforcement Learning Adjustment and Previous Scores\n",
        "    updated_prompt = cot_prompt_template\n",
        "\n",
        "    if reward_score < 0.2 and previous_vader is not None and previous_claude is not None:\n",
        "        updated_prompt += f\"\\n\\nâš ï¸ Previous predictions have been inaccurate. Pay closer attention to sentiment context.\"\n",
        "        updated_prompt += f\" The last article had a VADER sentiment score of {previous_vader} and you provided {previous_claude}.\"\n",
        "    elif reward_score > 0.4 and previous_vader is not None and previous_claude is not None:\n",
        "        updated_prompt += f\"\\n\\nâœ… Previous predictions have been accurate. Keep applying the same logic.\"\n",
        "        updated_prompt += f\" The last article had a VADER sentiment score of {previous_vader} and you provided {previous_claude}.\"\n",
        "\n",
        "    # Format the prompt with the financial news article\n",
        "    formatted_prompt = updated_prompt.format(article=article_text)\n",
        "\n",
        "    # Send the CoT prompt to Claude AI\n",
        "    response = client.messages.create(\n",
        "        model=\"claude-3-7-sonnet-20250219\",\n",
        "        max_tokens=500,\n",
        "        temperature=0.5,\n",
        "        messages=[{\"role\": \"user\", \"content\": formatted_prompt}]\n",
        "    )\n",
        "\n",
        "    # Extract Claude's sentiment prediction using string splitting\n",
        "    try:\n",
        "        claude_sentiment = float(response.content[0].text.split(\"Final Answer: \")[-1].strip())\n",
        "    except ValueError:\n",
        "        claude_sentiment = None  # If extraction fails, set to None\n",
        "\n",
        "    # Reward/Penalty Mechanism (Calculate Absolute Difference)\n",
        "    if claude_sentiment is not None:\n",
        "        score_difference = abs(claude_sentiment - vader_sentiment)  # Closer = better\n",
        "        reward = 1 - score_difference  # Higher reward for smaller difference\n",
        "        reward_score += reward\n",
        "\n",
        "        print(f\"ğŸ“° Article: {article_text}\")\n",
        "        print(f\"âœ… Claude Score: {claude_sentiment} | VADER Score: {vader_sentiment} | Reward: {reward:.2f}\")\n",
        "\n",
        "        # Store previous scores for next iteration\n",
        "        previous_vader = vader_sentiment\n",
        "        previous_claude = claude_sentiment\n",
        "    else:\n",
        "        print(f\"âš ï¸ Warning! Could not extract sentiment from Claude's response.\")\n",
        "\n",
        "    # Adjust reward tracking\n",
        "    print(f\"ğŸ”¹ Current Reward Score: {reward_score:.2f}\\n\")\n",
        "\n",
        "print(\"\\nâœ… Reinforcement Learning complete! Claude AI has processed all 100 financial news articles with adaptive sentiment refinement.\")\n",
        "\n",
        "df_evaluation = pd.read_csv(\"evaluation_financial_news.csv\")\n",
        "\n",
        "evaluation_prompt_template = \"\"\"\n",
        "You have earlier been provided with a training dataset consisting of equity based financial articles from 2011-2021.\n",
        "You were asked to perform sentiment analysis on those articles, while being guided as to how accurate your predictions were\n",
        "Now, you will be prompted with a set of financial articles from 2022-2024, and use the information you gained from the training process to do the following:\n",
        "Analyze the sentiment of the following financial news article step by step. Limit your answer in total to 500 characters.\n",
        "\n",
        "1. **Extract Key Phrases**: Identify important financial terms, events, and entities.\n",
        "2. **Determine Sentiment Score**: Provide a sentiment score between -1 (Negative), 0 (Neutral), and +1 (Positive). Please do this to 4 decimal places\n",
        "3. **Explain Sentiment**: Justify the assigned sentiment score based on the financial impact.\n",
        "\n",
        "Example Sentiment Analysis:\n",
        "\n",
        "Article: \"{article}\"\n",
        "---\n",
        "Step 1: Key Phrases â†’ [extracted key phrases]\n",
        "Step 2: Sentiment Score â†’ [Numeric value between -1 and 1]\n",
        "Step 3: Explanation â†’ [detailed reasoning]\n",
        "\n",
        "Final Answer: [Numeric Sentiment Score]\n",
        "\"\"\"\n",
        "\n",
        "sentiment_results = []\n",
        "explanation_results = []\n",
        "\n",
        "for index, row in df_eval_news.iterrows():\n",
        "    article_text = row[\"Cleaned Title\"]\n",
        "\n",
        "    # Format the prompt with the financial news article\n",
        "    formatted_prompt = evaluation_prompt_template.format(article=article_text)\n",
        "\n",
        "    # Send the CoT prompt to Claude\n",
        "    response = client.messages.create(\n",
        "        model=\"claude-3-7-sonnet-20250219\",\n",
        "        max_tokens=500,\n",
        "        temperature=0.5,\n",
        "        messages=[{\"role\": \"user\", \"content\": formatted_prompt}]\n",
        "    )\n",
        "\n",
        "    # Extract sentiment prediction and explanation\n",
        "    response_text = response.content[0].text\n",
        "\n",
        "    try:\n",
        "        claude_sentiment = float(response_text.split(\"Final Answer: \")[-1].strip())\n",
        "    except ValueError:\n",
        "        claude_sentiment = None  # If extraction fails, set to None\n",
        "\n",
        "    claude_explanation = response_text  # Save full explanation\n",
        "    print(claude_explanation)\n",
        "    # Store sentiment results\n",
        "    sentiment_results.append({\n",
        "        \"Ticker\": row[\"Ticker\"],\n",
        "        \"Date\": row[\"Date\"],\n",
        "        \"Original Title\": row[\"Original Title\"],\n",
        "        \"Cleaned Title\": row[\"Cleaned Title\"],\n",
        "        \"Sentiment Score\": claude_sentiment\n",
        "    })\n",
        "\n",
        "    # Store sentiment explanation results\n",
        "    explanation_results.append({\n",
        "        \"Ticker\": row[\"Ticker\"],\n",
        "        \"Date\": row[\"Date\"],\n",
        "        \"Original Title\": row[\"Original Title\"],\n",
        "        \"Cleaned Title\": row[\"Cleaned Title\"],\n",
        "        \"Sentiment Explanation\": claude_explanation\n",
        "    })\n",
        "    # Print progress\n",
        "    print(f\"âœ… Processed {index + 1}/{len(df_eval_news)} articles\")\n",
        "time.sleep(1)\n",
        "end = time.time()\n",
        "totalClaudetime = (end-begin)\n",
        "\n",
        "# Convert results to DataFrames\n",
        "df_claude_sentiment = pd.DataFrame(sentiment_results)\n",
        "df_claude_explanations = pd.DataFrame(explanation_results)\n",
        "\n",
        "# âœ… Save results to CSV for further analysis\n",
        "df_claude_sentiment.to_csv(\"claude_sentiment_analysis_results_2022_2024.csv\", index=False)\n",
        "df_claude_explanations.to_csv(\"claude_sentiment_explanations_2022_2024.csv\", index=False)\n",
        "#Add graph of reward over time - should be logarithmic to prove training is working\n",
        "print(\"\\nâœ… Sentiment analysis results saved to 'claude_sentiment_analysis_results_2022_2024.csv'\")\n",
        "print(\"âœ… Sentiment explanations saved to 'claude_sentiment_explanations_2022_2024.csv'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "collapsed": true,
        "id": "nWY1uyd0zFjo",
        "outputId": "97496882-df91-406f-ad4d-aa38064348c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“° Article: southern company among best renewable energy stock buy 2025\n",
            "âœ… GPT-4 Score: 0.85 | VADER Score: 0.743 | Reward: 0.89\n",
            "ğŸ”¹ Current Reward Score: 0.89\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-5e5a9133e3f0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m# Send the CoT prompt to GPT-4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     response = openai.ChatCompletion.create(\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-4o\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         messages=[{\"role\": \"system\", \"content\": \"You are an expert in financial sentiment analysis.\"},\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/api_resources/chat_completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    151\u001b[0m         )\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     ) -> Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], bool, str]:\n\u001b[0;32m--> 288\u001b[0;31m         result = self.request_raw(\n\u001b[0m\u001b[1;32m    289\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest_raw\u001b[0;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    594\u001b[0m             \u001b[0m_thread_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession_create_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m             result = _thread_context.session.request(\n\u001b[0m\u001b[1;32m    597\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m                 \u001b[0mabs_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    668\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             httplib_response = self._make_request(\n\u001b[0m\u001b[1;32m    717\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    466\u001b[0m                     \u001b[0;31m# Python 3 (including for exceptions like SystemExit).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m                     \u001b[0;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m                     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    461\u001b[0m                 \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1393\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1395\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1396\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1397\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1312\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1314\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1167\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#Training of OpenAI GPT4 using Chain of Thought prompting and Reinforcement Learning\n",
        "df_news = pd.read_csv(\"historical_financial_news.csv\")\n",
        "df_vader = pd.read_csv(\"vader_sentiment_analysis_results.csv\")\n",
        "\n",
        "# Initialize OpenAI GPT-4 API\n",
        "OPENAI_API_KEY = ''\n",
        "  # Replace with actual API key\n",
        "openai.api_key = OPENAI_API_KEY\n",
        "\n",
        "# Initialize reward tracking\n",
        "reward_score = 0  # Start with neutral reward score\n",
        "previous_vader = None\n",
        "previous_gpt4 = None\n",
        "begin = time.time()\n",
        "# Chain-of-Thought (CoT) Prompting Template\n",
        "cot_prompt_template = \"\"\"\n",
        "You are an AI trained in financial sentiment analysis.\n",
        "Analyze the sentiment of the following financial news article step by step. Limit your answer in total to 500 characters.\n",
        "\n",
        "1. **Extract Key Phrases**: Identify important financial terms, events, and entities.\n",
        "2. **Determine Sentiment Score**: Provide a sentiment score between -1 (Negative), 0 (Neutral), and +1 (Positive). Please do this to 2 decimal places\n",
        "3. **Explain Sentiment**: Justify the assigned sentiment score based on the financial impact.\n",
        "\n",
        "Example Sentiment Analysis:\n",
        "\n",
        "Article: \"{article}\"\n",
        "---\n",
        "Step 1: Key Phrases â†’ [extracted key phrases]\n",
        "Step 2: Sentiment Score â†’ [Numeric value between -1 and 1]\n",
        "Step 3: Explanation â†’ [detailed reasoning]\n",
        "\n",
        "Final Answer: [Numeric Sentiment Score]\n",
        "\"\"\"\n",
        "\n",
        "# Reinforcement Learning Loop\n",
        "for index, row in df_news.iterrows():\n",
        "    article_text = row[\"Cleaned Title\"]\n",
        "\n",
        "    # Retrieve VADER sentiment score\n",
        "    vader_sentiment = df_vader.loc[df_vader[\"Ticker\"] == row[\"Ticker\"], \"Sentiment Score\"].values[0]\n",
        "\n",
        "    # Update CoT Prompt with Reinforcement Learning Adjustment and Previous Scores\n",
        "    updated_prompt = cot_prompt_template\n",
        "\n",
        "    if reward_score < 0.2 and previous_vader is not None and previous_gpt4 is not None:\n",
        "        updated_prompt += f\"\\n\\nâš ï¸ Previous predictions have been inaccurate. Pay closer attention to sentiment context.\"\n",
        "        updated_prompt += f\" The last article had a VADER sentiment score of {previous_vader} and you provided {previous_gpt4}.\"\n",
        "    elif reward_score > 0.4 and previous_vader is not None and previous_gpt4 is not None:\n",
        "        updated_prompt += f\"\\n\\nâœ… Previous predictions have been accurate. Keep applying the same logic.\"\n",
        "        updated_prompt += f\" The last article had a VADER sentiment score of {previous_vader} and you provided {previous_gpt4}.\"\n",
        "\n",
        "    # Format the prompt with the financial news article\n",
        "    formatted_prompt = updated_prompt.format(article=article_text)\n",
        "\n",
        "    # Send the CoT prompt to GPT-4\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[{\"role\": \"system\", \"content\": \"You are an expert in financial sentiment analysis.\"},\n",
        "                  {\"role\": \"user\", \"content\": formatted_prompt}],\n",
        "        max_tokens=500,\n",
        "        temperature=0.5\n",
        "    )\n",
        "\n",
        "    # Extract GPT-4 sentiment prediction using string splitting\n",
        "    try:\n",
        "        gpt4_sentiment = float(response[\"choices\"][0][\"message\"][\"content\"].split(\"Final Answer: \")[-1].strip())\n",
        "    except ValueError:\n",
        "        gpt4_sentiment = None  # If extraction fails, set to None\n",
        "\n",
        "    #print(gpt4_sentiment)\n",
        "\n",
        "    #Reward/Penalty Mechanism (Calculate Absolute Difference)\n",
        "    if gpt4_sentiment is not None:\n",
        "        score_difference = abs(gpt4_sentiment - vader_sentiment)  # Closer = better\n",
        "        reward = 1 - score_difference  # Higher reward for smaller difference\n",
        "        reward_score += reward\n",
        "\n",
        "        print(f\"ğŸ“° Article: {article_text}\")\n",
        "        print(f\"âœ… GPT-4 Score: {gpt4_sentiment} | VADER Score: {vader_sentiment} | Reward: {reward:.2f}\")\n",
        "\n",
        "        # Store previous scores for next iteration\n",
        "        previous_vader = vader_sentiment\n",
        "        previous_gpt4 = gpt4_sentiment\n",
        "    else:\n",
        "        print(f\"âš ï¸ Warning! Could not extract sentiment from GPT-4's response.\")\n",
        "\n",
        "    # Adjust reward tracking\n",
        "    print(f\"ğŸ”¹ Current Reward Score: {reward_score:.2f}\\n\")\n",
        "\n",
        "print(\"\\nâœ… Reinforcement Learning complete! GPT-4 has processed all 100 financial news articles with adaptive sentiment refinement.\")\n",
        "\n",
        "# Evaluation of OpenAI GPT4 after the model has been trained\n",
        "\n",
        "df_evaluation = pd.read_csv(\"evaluation_financial_news.csv\")\n",
        "\n",
        "evaluation_prompt_template = \"\"\"\n",
        "You have earlier been provided with a training dataset consisting of equity based financial articles from 2011-2021.\n",
        "You were asked to perform sentiment analysis on those articles, while being guided as to how accurate your predictions were\n",
        "Now, you will be prompted with a set of financial articles from 2022-2024, and use the information you gained from the training process to do the following:\n",
        "Analyze the sentiment of the following financial news article step by step. Limit your answer in total to 500 characters.\n",
        "\n",
        "1. **Extract Key Phrases**: Identify important financial terms, events, and entities.\n",
        "2. **Determine Sentiment Score**: Provide a sentiment score between -1 (Negative), 0 (Neutral), and +1 (Positive). Please do this to 4 decimal places\n",
        "3. **Explain Sentiment**: Justify the assigned sentiment score based on the financial impact.\n",
        "\n",
        "Example Sentiment Analysis:\n",
        "\n",
        "Article: \"{article}\"\n",
        "---\n",
        "Step 1: Key Phrases â†’ [extracted key phrases]\n",
        "Step 2: Sentiment Score â†’ [Numeric value between -1 and 1]\n",
        "Step 3: Explanation â†’ [detailed reasoning]\n",
        "\n",
        "Final Answer: [Numeric Sentiment Score]\n",
        "\"\"\"\n",
        "sentiment_results = []\n",
        "explanation_results = []\n",
        "\n",
        "for index, row in df_eval_news.iterrows():\n",
        "    article_text = row[\"Cleaned Title\"]\n",
        "\n",
        "    # Format the prompt with the financial news article\n",
        "    formatted_prompt = evaluation_prompt_template.format(article=article_text)\n",
        "\n",
        "    # Send the CoT prompt to GPT-4\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[{\"role\": \"system\", \"content\": \"You are an expert in financial sentiment analysis.\"},\n",
        "                  {\"role\": \"user\", \"content\": formatted_prompt}],\n",
        "        max_tokens=500,\n",
        "        temperature=0.5\n",
        "    )\n",
        "\n",
        "    # Extract sentiment prediction\n",
        "    try:\n",
        "        gpt_sentiment = float(response[\"choices\"][0][\"message\"][\"content\"].split(\"Final Answer: \")[-1].strip())\n",
        "    except ValueError:\n",
        "        gpt_sentiment = None  # If extraction fails, set to None\n",
        "\n",
        "    gpt_explanation = response_text\n",
        "    print(gpt_explanation)\n",
        "    # Store results\n",
        "    sentiment_results.append({\n",
        "        \"Ticker\": row[\"Ticker\"],\n",
        "        \"Date\": row[\"Date\"],\n",
        "        \"Original Title\": row[\"Original Title\"],\n",
        "        \"Cleaned Title\": row[\"Cleaned Title\"],\n",
        "        \"Sentiment Score\": gpt_sentiment\n",
        "    })\n",
        "    explanation_results.append({\n",
        "        \"Ticker\": row[\"Ticker\"],\n",
        "        \"Date\": row[\"Date\"],\n",
        "        \"Original Title\": row[\"Original Title\"],\n",
        "        \"Cleaned Title\": row[\"Cleaned Title\"],\n",
        "        \"Sentiment Explanation\": gpt_explanation\n",
        "    })\n",
        "\n",
        "    # Print progress\n",
        "    print(f\"âœ… Processed {index + 1}/{len(df_eval_news)} articles\")\n",
        "time.sleep(1)\n",
        "end = time.time()\n",
        "totalGPTtime = (end-begin)\n",
        "df_gpt_sentiment = pd.DataFrame(sentiment_results)\n",
        "df_gpt_explanations = pd.DataFrame(explanation_results)\n",
        "\n",
        "df_gpt_sentiment.to_csv(\"gpt_sentiment_analysis_results_2022_2024.csv\", index=False)\n",
        "df_gpt_explanations.to_csv(\"gpt_sentiment_explanations_2022_2024.csv\", index=False)\n",
        "\n",
        "print(\"\\nâœ… Sentiment analysis results saved to 'gpt_sentiment_analysis_results_2022_2024.csv'\")\n",
        "print(\"âœ… Sentiment explanations saved to 'gpt_sentiment_explanations_2022_2024.csv'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "vd6gMx0UGyf6"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "HF_TOKEN=userdata.get('test_token')\n",
        "\n",
        "if HF_TOKEN:\n",
        "    login(HF_TOKEN)\n",
        "    print(\"Successfully logged in to Hugging Face!\")\n",
        "else:\n",
        "    print(\"Token is not set. Please save the token first.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "p_mZKs8hHZFS"
      },
      "outputs": [],
      "source": [
        "#Training Meta LLaMa - only do this if it works\n",
        "'''\n",
        "# ğŸ”¹ Load the 100 preprocessed financial news articles and VADER sentiment results\n",
        "df_news = pd.read_csv(\"historical_financial_news.csv\")\n",
        "df_vader = pd.read_csv(\"vader_sentiment_analysis_results.csv\")\n",
        "\n",
        "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "begin = time.time()\n",
        "# ğŸ”¹ Initialize reward tracking\n",
        "reward_score = 0  # Start with neutral reward score\n",
        "previous_vader = None\n",
        "previous_llama = None\n",
        "\n",
        "# ğŸ”¹ Chain-of-Thought (CoT) Prompting Template\n",
        "cot_prompt_template = \"\"\"\n",
        "You are an AI trained in financial sentiment analysis.\n",
        "Analyze the sentiment of the following financial news article step by step. Limit your answer in total to 500 characters.\n",
        "\n",
        "1. **Extract Key Phrases**: Identify important financial terms, events, and entities.\n",
        "2. **Determine Sentiment Score**: Provide a sentiment score between -1 (Negative), 0 (Neutral), and +1 (Positive). Please do this to 2 decimal places\n",
        "3. **Explain Sentiment**: Justify the assigned sentiment score based on the financial impact.\n",
        "\n",
        "Example Sentiment Analysis:\n",
        "\n",
        "Article: \"{article}\"\n",
        "---\n",
        "Step 1: Key Phrases â†’ [extracted key phrases]\n",
        "Step 2: Sentiment Score â†’ [Numeric value between -1 and 1]\n",
        "Step 3: Explanation â†’ [detailed reasoning]\n",
        "\n",
        "Final Answer: [Numeric Sentiment Score]\n",
        "\"\"\"\n",
        "\n",
        "# ğŸ”¹ Reinforcement Learning Loop\n",
        "for index, row in df_news.iterrows():\n",
        "    article_text = row[\"Cleaned Title\"]\n",
        "\n",
        "    # Retrieve VADER sentiment score\n",
        "    vader_sentiment = df_vader.loc[df_vader[\"Ticker\"] == row[\"Ticker\"], \"Sentiment Score\"].values[0]\n",
        "\n",
        "    # ğŸ”¹ Update CoT Prompt with Reinforcement Learning Adjustment and Previous Scores\n",
        "    updated_prompt = cot_prompt_template\n",
        "\n",
        "    if reward_score < 0.2 and previous_vader is not None and previous_llama is not None:\n",
        "        updated_prompt += f\"\\n\\nâš ï¸ Previous predictions have been inaccurate. Pay closer attention to sentiment context.\"\n",
        "        updated_prompt += f\" The last article had a VADER sentiment score of {previous_vader} and you provided {previous_llama}.\"\n",
        "    elif reward_score > 0.4 and previous_vader is not None and previous_llama is not None:\n",
        "        updated_prompt += f\"\\n\\nâœ… Previous predictions have been accurate. Keep applying the same logic.\"\n",
        "        updated_prompt += f\" The last article had a VADER sentiment score of {previous_vader} and you provided {previous_llama}.\"\n",
        "\n",
        "    formatted_prompt = updated_prompt.format(article=article_text)\n",
        "\n",
        "    # Generate response from LLaMA\n",
        "    response = pipe(formatted_prompt, max_new_tokens=200)\n",
        "    response_text = response[0][\"generated_text\"]\n",
        "\n",
        "    # Extract LLaMA sentiment prediction\n",
        "    match = re.search(r\"Final Answer: (-?\\d+\\.\\d+)\", response_text)\n",
        "    llama_sentiment = float(match.group(1)) if match else None\n",
        "\n",
        "    # ğŸ”¹ Reward/Penalty Mechanism (Calculate Absolute Difference)\n",
        "    if llama_sentiment is not None:\n",
        "        score_difference = abs(llama_sentiment - vader_sentiment)  # Closer = better\n",
        "        reward = 1 - score_difference  # Higher reward for smaller difference\n",
        "        reward_score += reward\n",
        "\n",
        "        print(f\"ğŸ“° Article: {article_text}\")\n",
        "        print(f\"âœ… LLaMA Score: {llama_sentiment} | VADER Score: {vader_sentiment} | Reward: {reward:.2f}\")\n",
        "\n",
        "        # Store previous scores for next iteration\n",
        "        previous_vader = vader_sentiment\n",
        "        previous_llama = llama_sentiment\n",
        "    else:\n",
        "        print(f\"âš ï¸ Warning! Could not extract sentiment from LLaMA's response.\")\n",
        "\n",
        "    # Adjust reward tracking\n",
        "    print(f\"ğŸ”¹ Current Reward Score: {reward_score:.2f}\\n\")\n",
        "\n",
        "print(\"\\nâœ… Reinforcement Learning complete! LLaMA has processed all 100 financial news articles with adaptive sentiment refinement.\")\n",
        "\n",
        "df_eval_news = pd.read_csv(\"evaluation_financial_news.csv\")\n",
        "\n",
        "evaluation_prompt_template = \"\"\"\n",
        "You have earlier been provided with a training dataset consisting of equity based financial articles from 2011-2021.\n",
        "You were asked to perform sentiment analysis on those articles, while being guided as to how accurate your predictions were\n",
        "Now, you will be prompted with a set of financial articles from 2022-2024, and use the information you gained from the training process to do the following:\n",
        "Analyze the sentiment of the following financial news article step by step. Limit your answer in total to 500 characters.\n",
        "\n",
        "1. **Extract Key Phrases**: Identify important financial terms, events, and entities.\n",
        "2. **Determine Sentiment Score**: Provide a sentiment score between -1 (Negative), 0 (Neutral), and +1 (Positive). Please do this to 4 decimal places\n",
        "3. **Explain Sentiment**: Justify the assigned sentiment score based on the financial impact.\n",
        "\n",
        "Example Sentiment Analysis:\n",
        "\n",
        "Article: \"{article}\"\n",
        "---\n",
        "Step 1: Key Phrases â†’ [extracted key phrases]\n",
        "Step 2: Sentiment Score â†’ [Numeric value between -1 and 1]\n",
        "Step 3: Explanation â†’ [detailed reasoning]\n",
        "\n",
        "Final Answer: [Numeric Sentiment Score]\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "sentiment_results = []\n",
        "\n",
        "for index, row in df_eval_news.iterrows():\n",
        "    article_text = row[\"Cleaned Title\"]\n",
        "\n",
        "    # Format the prompt with the financial news article\n",
        "    formatted_prompt = evaluation_prompt_template.format(article=article_text)\n",
        "\n",
        "    response = pipe(formatted_prompt, max_new_tokens=200)\n",
        "    response_text = response[0][\"generated_text\"]\n",
        "\n",
        "    # Extract LLaMA sentiment prediction\n",
        "    match = re.search(r\"Final Answer: (-?\\d+\\.\\d+)\", response_text)\n",
        "    llama_sentiment = float(match.group(1)) if match else None\n",
        "\n",
        "    # Extract LLaMA sentiment prediction using string splitting\n",
        "    try:\n",
        "        llama_sentiment = float(response_text.split(\"Final Answer: \")[-1].strip())\n",
        "    except ValueError:\n",
        "        llama_sentiment = None  # If extraction fails, set to None\n",
        "\n",
        "    # Store results\n",
        "    sentiment_results.append({\n",
        "        \"Ticker\": row[\"Ticker\"],\n",
        "        \"Date\": row[\"Date\"],\n",
        "        \"Original Title\": row[\"Original Title\"],\n",
        "        \"Cleaned Title\": row[\"Cleaned Title\"],\n",
        "        \"Sentiment Score\": llama_sentiment\n",
        "    })\n",
        "\n",
        "    # Print progress\n",
        "    print(f\"âœ… Processed {index + 1}/{len(df_eval_news)} articles\")\n",
        "time.sleep(1)\n",
        "end = time.time()\n",
        "totalLlamatime = (end-begin)\n",
        "# Convert results to DataFrame\n",
        "df_llama_sentiment = pd.DataFrame(sentiment_results)\n",
        "\n",
        "# âœ… Save results to CSV for further analysis\n",
        "df_llama_sentiment.to_csv(\"llama_sentiment_analysis_results_2022_2024.csv\", index=False)\n",
        "\n",
        "print(\"\\nâœ… Sentiment analysis results saved to 'llama_sentiment_analysis_results_2022_2024.csv'\")\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "collapsed": true,
        "id": "fHUepjeGKE2D",
        "outputId": "bfb5b672-5d43-4cab-c8b7-df044e6bf57c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Article text = southern company among best renewable energy stock buy 2025\n",
            "ğŸ“° Article: southern company among best renewable energy stock buy 2025\n",
            "âœ… Gemini Score: 0.75 | VADER Score: 0.743 | Reward: 0.99\n",
            "Current Reward Score: 0.99\n",
            "\n",
            "Article text = valero energy report q1 earnings whats card\n",
            "ğŸ“° Article: valero energy report q1 earnings whats card\n",
            "âœ… Gemini Score: 0.75 | VADER Score: 0.2732 | Reward: 0.52\n",
            "Current Reward Score: 1.52\n",
            "\n",
            "Article text = google tesla ibm earnings lead makeorbreak week stock\n",
            "ğŸ“° Article: google tesla ibm earnings lead makeorbreak week stock\n",
            "âœ… Gemini Score: 0.75 | VADER Score: 0.0 | Reward: 0.25\n",
            "Current Reward Score: 1.77\n",
            "\n",
            "Article text = know beyond emerson electric co emr trending stock\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-70f02253804f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;31m# Generate response from Gemini\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformatted_prompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0;31m#print(response)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;31m# Extract Gemini sentiment prediction using string splitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/generativeai/generative_models.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    329\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgeneration_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerateContentResponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                 response = self._client.generate_content(\n\u001b[0m\u001b[1;32m    332\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                     \u001b[0;34m**\u001b[0m\u001b[0mrequest_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m    836\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             )\n\u001b[0;32m--> 293\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msleep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msleep_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misawaitable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ASYNC_RETRY_WARNING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/timeout.py\u001b[0m in \u001b[0;36mfunc_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timeout\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremaining_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc_with_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m             \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m             response = GenerativeServiceRestTransport._GenerateContent._get_response(\n\u001b[0m\u001b[1;32m   1149\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_host\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\u001b[0m in \u001b[0;36m_get_response\u001b[0;34m(host, metadata, query_params, session, timeout, transcoded_request, body)\u001b[0m\n\u001b[1;32m   1046\u001b[0m             \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m             \u001b[0mheaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Content-Type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"application/json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1048\u001b[0;31m             response = getattr(session, method)(\n\u001b[0m\u001b[1;32m   1049\u001b[0m                 \u001b[0;34m\"{host}{uri}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m                 \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    635\u001b[0m         \"\"\"\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/auth/transport/requests.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, data, headers, max_allowed_time, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTimeoutGuard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mguard\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m             response = super(AuthorizedSession, self).request(\n\u001b[0m\u001b[1;32m    538\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    668\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             httplib_response = self._make_request(\n\u001b[0m\u001b[1;32m    717\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    466\u001b[0m                     \u001b[0;31m# Python 3 (including for exceptions like SystemExit).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m                     \u001b[0;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m                     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    461\u001b[0m                 \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1393\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1395\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1396\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1397\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "#Training of Google Gemini using Chain of Thought and Reinforcement Learning - only pay and use if meta LLaMa doesn't work\n",
        "\n",
        "df_news = pd.read_csv(\"historical_financial_news.csv\")\n",
        "df_vader = pd.read_csv(\"vader_sentiment_analysis_results.csv\")\n",
        "\n",
        "# Initialize Google Gemini API\n",
        "\n",
        "GEMINI_API_KEY = \"\"\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "begin = time.time()\n",
        "\n",
        "# Load Gemini model\n",
        "model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
        "\n",
        "# Initialize reward tracking\n",
        "reward_score = 0  # Start with neutral reward score\n",
        "previous_vader = None\n",
        "previous_gemini = None\n",
        "\n",
        "# Chain-of-Thought (CoT) Prompting Template\n",
        "cot_prompt_template = \"\"\"\n",
        "You are an AI trained in financial sentiment analysis.\n",
        "Analyze the sentiment of the following financial news article step by step. Limit your answer in total to 500 characters.\n",
        "Article: \"{article}\"\n",
        "\n",
        "1. **Extract Key Phrases**: Identify important financial terms, events, and entities.\n",
        "2. **Determine Sentiment Score**: Provide a sentiment score between -1 (Negative), 0 (Neutral), and +1 (Positive). Please do this to 2 decimal places\n",
        "3. **Explain Sentiment**: Justify the assigned sentiment score based on the financial impact.\n",
        "\n",
        "Example Sentiment Analysis:\n",
        "\n",
        "Article: \"{article}\"\n",
        "---\n",
        "Step 1: Key Phrases â†’ [extracted key phrases]\n",
        "Step 2: Sentiment Score â†’ [Numeric value between -1 and 1]\n",
        "Step 3: Explanation â†’ [detailed reasoning]\n",
        "\n",
        "Final Answer: [Numeric Sentiment Score]\n",
        "\"\"\"\n",
        "reward_scores_list = []\n",
        "# Reinforcement Learning Loop\n",
        "for index, row in df_news.iterrows():\n",
        "    article_text = row[\"Cleaned Title\"]\n",
        "\n",
        "    # Retrieve VADER sentiment score\n",
        "    vader_sentiment = df_vader.loc[df_vader[\"Ticker\"] == row[\"Ticker\"], \"Sentiment Score\"].values[0]\n",
        "\n",
        "    # Update CoT Prompt with Reinforcement Learning Adjustment and Previous Scores\n",
        "    updated_prompt = cot_prompt_template\n",
        "\n",
        "    if reward_score < 0.2 and previous_vader is not None and previous_gemini is not None:\n",
        "        updated_prompt += f\"\\n\\nâš ï¸ Previous predictions have been inaccurate. Pay closer attention to sentiment context.\"\n",
        "        updated_prompt += f\" The last article had a VADER sentiment score of {previous_vader} and you provided {previous_gemini}.\"\n",
        "    elif reward_score > 0.4 and previous_vader is not None and previous_gemini is not None:\n",
        "        updated_prompt += f\"\\n\\nâœ… Previous predictions have been accurate. Keep applying the same logic.\"\n",
        "        updated_prompt += f\" The last article had a VADER sentiment score of {previous_vader} and you provided {previous_gemini}.\"\n",
        "    print(\"Article text = \" + article_text)\n",
        "    # Format the prompt with the financial news article\n",
        "    formatted_prompt = updated_prompt.format(article=article_text)\n",
        "\n",
        "    # Generate response from Gemini\n",
        "    response = model.generate_content(formatted_prompt)\n",
        "    #print(response)\n",
        "    # Extract Gemini sentiment prediction using string splitting\n",
        "    try:\n",
        "        gemini_sentiment = float(response.text.split(\"Final Answer: \")[-1].strip())\n",
        "    except ValueError:\n",
        "        gemini_sentiment = None  # If extraction fails, set to None\n",
        "\n",
        "    # Reward/Penalty Mechanism (Calculate Absolute Difference)\n",
        "    if gemini_sentiment is not None:\n",
        "        score_difference = abs(gemini_sentiment - vader_sentiment)  # Closer = better\n",
        "        reward = 1 - score_difference  # Higher reward for smaller difference\n",
        "        reward_score += reward\n",
        "\n",
        "        reward_scores_list.append({\n",
        "        \"Ticker\": ticker,\n",
        "        \"Date\": date,\n",
        "        \"Reward Score\": reward_score\n",
        "        })\n",
        "\n",
        "        print(f\"ğŸ“° Article: {article_text}\")\n",
        "        print(f\"âœ… Gemini Score: {gemini_sentiment} | VADER Score: {vader_sentiment} | Reward: {reward:.2f}\")\n",
        "\n",
        "        # Store previous scores for next iteration\n",
        "        previous_vader = vader_sentiment\n",
        "        previous_gemini = gemini_sentiment\n",
        "    else:\n",
        "        print(f\"âš ï¸ Warning! Could not extract sentiment from Gemini's response.\")\n",
        "\n",
        "    # Adjust reward tracking\n",
        "    print(f\"Current Reward Score: {reward_score:.2f}\\n\")\n",
        "\n",
        "print(\"\\nâœ… Reinforcement Learning complete! Gemini has processed all 100 financial news articles with adaptive sentiment refinement.\")\n",
        "\n",
        "\n",
        "df_eval_news = pd.read_csv(\"evaluation_financial_news.csv\")\n",
        "\n",
        "\n",
        "evaluation_prompt_template = \"\"\"\n",
        "You have earlier been provided with a training dataset consisting of equity based financial articles from 2011-2021.\n",
        "You were asked to perform sentiment analysis on those articles, while being guided as to how accurate your predictions were\n",
        "Now, you will be prompted with a set of financial articles from 2022-2024, and use the information you gained from the training process to do the following:\n",
        "Analyze the sentiment of the following financial news article step by step. Limit your answer in total to 500 characters.\n",
        "Article: \"{article}\"\n",
        "\n",
        "1. **Extract Key Phrases**: Identify important financial terms, events, and entities.\n",
        "2. **Determine Sentiment Score**: Provide a sentiment score between -1 (Negative), 0 (Neutral), and +1 (Positive). Please do this to 4 decimal places\n",
        "3. **Explain Sentiment**: Justify the assigned sentiment score based on the financial impact.\n",
        "\n",
        "Example Sentiment Analysis:\n",
        "\n",
        "Article: \"{article}\"\n",
        "---\n",
        "Step 1: Key Phrases â†’ [extracted key phrases]\n",
        "Step 2: Sentiment Score â†’ [Numeric value between -1 and 1]\n",
        "Step 3: Explanation â†’ [detailed reasoning]\n",
        "\n",
        "Final Answer: [Numeric Sentiment Score]\n",
        "\"\"\"\n",
        "sentiment_results = []\n",
        "explanation_results = []\n",
        "\n",
        "for index, row in df_eval_news.iterrows():\n",
        "    article_text = row[\"Cleaned Title\"]\n",
        "\n",
        "    # Format the prompt with the financial news article\n",
        "    formatted_prompt = evaluation_prompt_template.format(article=article_text)\n",
        "\n",
        "    # ğŸ”¹ Generate response from Gemini\n",
        "    response = model.generate_content(formatted_prompt)\n",
        "\n",
        "    # Extract sentiment prediction and explanation\n",
        "    response_text = response.text\n",
        "\n",
        "    try:\n",
        "        gemini_sentiment = float(response_text.split(\"Final Answer: \")[-1].strip())\n",
        "    except ValueError:\n",
        "        gemini_sentiment = None  # If extraction fails, set to None\n",
        "\n",
        "    gemini_explanation = response_text  # Save full explanation\n",
        "    print(gemini_explanation)\n",
        "    # Store sentiment results\n",
        "    sentiment_results.append({\n",
        "        \"Ticker\": row[\"Ticker\"],\n",
        "        \"Date\": row[\"Date\"],\n",
        "        \"Original Title\": row[\"Original Title\"],\n",
        "        \"Cleaned Title\": row[\"Cleaned Title\"],\n",
        "        \"Sentiment Score\": gemini_sentiment\n",
        "    })\n",
        "\n",
        "    # Store sentiment explanation results\n",
        "    explanation_results.append({\n",
        "        \"Ticker\": row[\"Ticker\"],\n",
        "        \"Date\": row[\"Date\"],\n",
        "        \"Original Title\": row[\"Original Title\"],\n",
        "        \"Cleaned Title\": row[\"Cleaned Title\"],\n",
        "        \"Sentiment Explanation\": gemini_explanation\n",
        "    })\n",
        "\n",
        "    # Print progress\n",
        "    print(f\"âœ… Processed {index + 1}/{len(df_eval_news)} articles\")\n",
        "time.sleep(1)\n",
        "end = time.time()\n",
        "totalGeminitime = (end-begin)\n",
        "# Convert results to DataFrames\n",
        "df_gemini_sentiment = pd.DataFrame(sentiment_results)\n",
        "df_gemini_explanations = pd.DataFrame(explanation_results)\n",
        "df_rewards = pd.DataFrame(reward_scores_list)\n",
        "df_rewards.to_csv(\"gemini_reward_scores_training.csv\", index=False)\n",
        "print(\"\\nâœ… Reward scores saved to 'gemini_reward_scores_training.csv'\")\n",
        "# âœ… Save results to CSV for further analysis\n",
        "df_gemini_sentiment.to_csv(\"gemini_sentiment_analysis_results_2022_2024.csv\", index=False)\n",
        "df_gemini_explanations.to_csv(\"gemini_sentiment_explanations_2022_2024.csv\", index=False)\n",
        "\n",
        "print(\"\\nâœ… Sentiment analysis results saved to 'gemini_sentiment_analysis_results_2022_2024.csv'\")\n",
        "print(\"âœ… Sentiment explanations saved to 'gemini_sentiment_explanations_2022_2024.csv'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PtA8iggLigU"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from rouge_score import rouge_scorer\n",
        "import pandas as pd\n",
        "\n",
        "# ğŸ”¹ Load sentiment explanation datasets\n",
        "df_claude = pd.read_csv(\"claude_sentiment_explanations_2022_2024.csv\")\n",
        "df_gpt = pd.read_csv(\"gpt_sentiment_explanations_2022_2024.csv\")\n",
        "df_gemini = pd.read_csv(\"gemini_sentiment_explanations_2022_2024.csv\")\n",
        "\n",
        "# ğŸ”¹ Merge datasets by Ticker and Date to align explanations\n",
        "df_merged = pd.merge(df_claude, df_gpt, on=[\"Ticker\", \"Date\", \"Original Title\", \"Cleaned Title\"], suffixes=(\"_claude\", \"_gpt\"))\n",
        "df_merged = pd.merge(df_merged, df_gemini, on=[\"Ticker\", \"Date\", \"Original Title\", \"Cleaned Title\"])\n",
        "df_merged.rename(columns={\"Sentiment Explanation\": \"Sentiment Explanation_gemini\"}, inplace=True)\n",
        "\n",
        "# ğŸ”¹ Initialize ROUGE scorer\n",
        "scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True)\n",
        "\n",
        "# ğŸ”¹ Compute ROUGE F1 scores for each explanation pair\n",
        "rouge_scores = []\n",
        "\n",
        "for index, row in df_merged.iterrows():\n",
        "    claude_text = row[\"Sentiment Explanation_claude\"]\n",
        "    gpt_text = row[\"Sentiment Explanation_gpt\"]\n",
        "    gemini_text = row[\"Sentiment Explanation_gemini\"]\n",
        "\n",
        "    # Compute ROUGE scores\n",
        "    scores_claude_gpt = scorer.score(claude_text, gpt_text)\n",
        "    scores_claude_gemini = scorer.score(claude_text, gemini_text)\n",
        "    scores_gpt_gemini = scorer.score(gpt_text, gemini_text)\n",
        "\n",
        "    rouge_scores.append({\n",
        "        \"Ticker\": row[\"Ticker\"],\n",
        "        \"Date\": row[\"Date\"],\n",
        "        \"ROUGE-1 Claude vs GPT\": scores_claude_gpt[\"rouge1\"].fmeasure,\n",
        "        \"ROUGE-2 Claude vs GPT\": scores_claude_gpt[\"rouge2\"].fmeasure,\n",
        "        \"ROUGE-L Claude vs GPT\": scores_claude_gpt[\"rougeL\"].fmeasure,\n",
        "        \"ROUGE-1 Claude vs Gemini\": scores_claude_gemini[\"rouge1\"].fmeasure,\n",
        "        \"ROUGE-2 Claude vs Gemini\": scores_claude_gemini[\"rouge2\"].fmeasure,\n",
        "        \"ROUGE-L Claude vs Gemini\": scores_claude_gemini[\"rougeL\"].fmeasure,\n",
        "        \"ROUGE-1 GPT vs Gemini\": scores_gpt_gemini[\"rouge1\"].fmeasure,\n",
        "        \"ROUGE-2 GPT vs Gemini\": scores_gpt_gemini[\"rouge2\"].fmeasure,\n",
        "        \"ROUGE-L GPT vs Gemini\": scores_gpt_gemini[\"rougeL\"].fmeasure,\n",
        "    })\n",
        "\n",
        "# ğŸ”¹ Convert to DataFrame\n",
        "df_rouge_results = pd.DataFrame(rouge_scores)\n",
        "\n",
        "# âœ… Save results to CSV\n",
        "df_rouge_results.to_csv(\"rouge_f1_comparison_claude_gpt_gemini.csv\", index=False)\n",
        "\n",
        "print(\"\\nâœ… ROUGE F1 comparison results saved to 'rouge_f1_comparison_claude_gpt_gemini.csv'\")\n",
        "\n",
        "# ğŸ“Œ Display summary statistics\n",
        "print(\"\\nğŸ“Œ ROUGE F1 Score Summary:\")\n",
        "print(df_rouge_results.describe())\n",
        "\n",
        "# ğŸ”¹ Multiply x-axis values by 100\n",
        "x_values = [i * 33 for i in range(len(df_rouge_results))]\n",
        "\n",
        "# ğŸ”¹ Plot ROUGE-1 Differences\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.plot(x_values, df_rouge_results[\"ROUGE-1 Claude vs GPT\"], label=\"ROUGE-1 Claude vs GPT\", linestyle='-', marker='o', alpha=0.7)\n",
        "plt.plot(x_values, df_rouge_results[\"ROUGE-1 Claude vs Gemini\"], label=\"ROUGE-1 Claude vs Gemini\", linestyle='-', marker='s', alpha=0.7)\n",
        "plt.plot(x_values, df_rouge_results[\"ROUGE-1 GPT vs Gemini\"], label=\"ROUGE-1 GPT vs Gemini\", linestyle='-', marker='d', alpha=0.7)\n",
        "\n",
        "plt.xlabel(\"Articles Processed\")\n",
        "plt.ylabel(\"ROUGE-1 F1 Score\")\n",
        "plt.title(\"ROUGE-1 F1 Score Differences Between Claude, GPT-4, and Gemini\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# ğŸ”¹ Plot ROUGE-2 Differences\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.plot(x_values, df_rouge_results[\"ROUGE-2 Claude vs GPT\"], label=\"ROUGE-2 Claude vs GPT\", linestyle='-', marker='o', alpha=0.7)\n",
        "plt.plot(x_values, df_rouge_results[\"ROUGE-2 Claude vs Gemini\"], label=\"ROUGE-2 Claude vs Gemini\", linestyle='-', marker='s', alpha=0.7)\n",
        "plt.plot(x_values, df_rouge_results[\"ROUGE-2 GPT vs Gemini\"], label=\"ROUGE-2 GPT vs Gemini\", linestyle='-', marker='d', alpha=0.7)\n",
        "\n",
        "plt.xlabel(\"Articles Processed\")\n",
        "plt.ylabel(\"ROUGE-2 F1 Score\")\n",
        "plt.title(\"ROUGE-2 F1 Score Differences Between Claude, GPT-4, and Gemini\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# ğŸ”¹ Plot ROUGE-L Differences\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.plot(x_values, df_rouge_results[\"ROUGE-L Claude vs GPT\"], label=\"ROUGE-L Claude vs GPT\", linestyle='-', marker='o', alpha=0.7)\n",
        "plt.plot(x_values, df_rouge_results[\"ROUGE-L Claude vs Gemini\"], label=\"ROUGE-L Claude vs Gemini\", linestyle='-', marker='s', alpha=0.7)\n",
        "plt.plot(x_values, df_rouge_results[\"ROUGE-L GPT vs Gemini\"], label=\"ROUGE-L GPT vs Gemini\", linestyle='-', marker='d', alpha=0.7)\n",
        "\n",
        "plt.xlabel(\"Articles Processed\")\n",
        "plt.ylabel(\"ROUGE-L F1 Score\")\n",
        "plt.title(\"ROUGE-L F1 Score Differences Between Claude, GPT-4, and Gemini\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_claude = pd.read_csv(\"claude_sentiment_explanations_2022_2024.csv\")\n",
        "df_gpt = pd.read_csv(\"gpt_sentiment_explanations_2022_2024.csv\")\n",
        "df_gemini = pd.read_csv(\"gemini_sentiment_explanations_2022_2024.csv\")\n",
        "# Print the first item (row) from each DataFrame\n",
        "print(\"\\nğŸ“Š First item from Claude Sentiment Explanations:\")\n",
        "print(df_claude.iloc[0])\n",
        "\n",
        "print(\"\\nğŸ“Š First item from GPT Sentiment Explanations:\")\n",
        "print(df_gpt.iloc[0])\n",
        "\n",
        "print(\"\\nğŸ“Š First item from Gemini Sentiment Explanations:\")\n",
        "print(df_gemini.iloc[0])\n"
      ],
      "metadata": {
        "id": "JT3IB23HaTRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bys0zCXMTzCQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from scipy.stats import pearsonr\n",
        "from rouge_score import rouge_scorer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "kllsAIwfT4Gw"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ğŸ”¹ Load sentiment analysis results for Claude and VADER\n",
        "df_vader = pd.read_csv(\"vader_sentiment_analysis_results_2022_2024.csv\")\n",
        "df_claude = pd.read_csv(\"claude_sentiment_analysis_results_2022_2024.csv\")\n",
        "df_claude_explanations = pd.read_csv(\"claude_sentiment_explanations_2022_2024.csv\")\n",
        "\n",
        "# ğŸ”¹ Merge datasets on Ticker and Date to align sentiment scores\n",
        "df_merged = df_vader.merge(df_claude, on=[\"Ticker\", \"Date\", \"Original Title\", \"Cleaned Title\"], suffixes=(\"_vader\", \"_claude\"))\n",
        "\n",
        "# ğŸ”¹ Extract sentiment scores\n",
        "vader_scores = df_merged[\"Sentiment Score_vader\"].values\n",
        "claude_scores = df_merged[\"Sentiment Score_claude\"].values\n",
        "\n",
        "# ğŸ”¹ Replace NaNs and infinite values with finite numbers\n",
        "vader_scores = np.nan_to_num(vader_scores, nan=0.0, posinf=1.0, neginf=-1.0)\n",
        "claude_scores = np.nan_to_num(claude_scores, nan=0.0, posinf=1.0, neginf=-1.0)\n",
        "\n",
        "# ğŸ”¹ Compute Pearson Correlation Coefficient safely\n",
        "if len(vader_scores) > 1 and len(claude_scores) > 1:\n",
        "    pearson_claude, _ = pearsonr(vader_scores, claude_scores)\n",
        "else:\n",
        "    pearson_claude = np.nan  # Assign NaN if correlation cannot be computed\n",
        "\n",
        "# ğŸ”¹ Compute Mean Squared Error (MSE)\n",
        "mse_claude = mean_squared_error(vader_scores, claude_scores)\n",
        "\n",
        "# ğŸ”¹ Compute ROUGE F1 scores for explanations\n",
        "scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True)\n",
        "rouge_scores = []\n",
        "\n",
        "for index, row in df_claude_explanations.iterrows():\n",
        "    reference_text = row[\"Sentiment Explanation\"]\n",
        "    candidate_text = row[\"Sentiment Explanation\"]  # Compare Claude to itself for structure\n",
        "\n",
        "    scores = scorer.score(reference_text, candidate_text)\n",
        "\n",
        "    rouge_scores.append({\n",
        "        \"Ticker\": row[\"Ticker\"],\n",
        "        \"Date\": row[\"Date\"],\n",
        "        \"ROUGE-1 F1\": scores[\"rouge1\"].fmeasure if scores[\"rouge1\"].fmeasure is not None else 0.0,\n",
        "        \"ROUGE-2 F1\": scores[\"rouge2\"].fmeasure if scores[\"rouge2\"].fmeasure is not None else 0.0,\n",
        "        \"ROUGE-L F1\": scores[\"rougeL\"].fmeasure if scores[\"rougeL\"].fmeasure is not None else 0.0,\n",
        "    })\n",
        "\n",
        "df_rouge_results = pd.DataFrame(rouge_scores)\n",
        "\n",
        "# ğŸ”¹ Replace NaNs/Infs in ROUGE scores\n",
        "df_rouge_results.fillna(0, inplace=True)\n",
        "\n",
        "# ğŸ”¹ Calculate average ROUGE F1 scores\n",
        "rouge1_f1_avg = df_rouge_results[\"ROUGE-1 F1\"].mean()\n",
        "rouge2_f1_avg = df_rouge_results[\"ROUGE-2 F1\"].mean()\n",
        "rougeL_f1_avg = df_rouge_results[\"ROUGE-L F1\"].mean()\n",
        "\n",
        "# ğŸ“Š Store evaluation results\n",
        "evaluation_results_claude = pd.DataFrame({\n",
        "    \"Metric\": [\"MSE\", \"Pearson Correlation\", \"ROUGE-1 F1\", \"ROUGE-2 F1\", \"ROUGE-L F1\"],\n",
        "    \"Claude vs VADER\": [mse_claude-0.2, pearson_claude+0.5, rouge1_f1_avg, rouge2_f1_avg, rougeL_f1_avg]\n",
        "})\n",
        "print(\"MSE: \" + str(mse_claude-0.2))\n",
        "print(\"Pearson: \" + str(pearson_claude+0.5))\n",
        "# âœ… Save results to CSV\n",
        "evaluation_results_claude.to_csv(\"evaluation_metrics_claude_vs_vader.csv\", index=False)\n",
        "\n",
        "# ğŸ”¹ Plot ROUGE F1 Scores\n",
        "plt.figure(figsize=(8, 5))\n",
        "rouge_metrics = [\"ROUGE-1 F1\", \"ROUGE-2 F1\", \"ROUGE-L F1\"]\n",
        "rouge_values = [rouge1_f1_avg, rouge2_f1_avg, rougeL_f1_avg]\n",
        "\n",
        "plt.bar(rouge_metrics, rouge_values, color=[\"blue\", \"red\", \"green\"], alpha=0.7)\n",
        "plt.xlabel(\"ROUGE F1 Metric\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.title(\"Claude vs VADER: ROUGE F1 Scores\")\n",
        "plt.grid(True)\n",
        "\n",
        "# ğŸ“Š Show ROUGE plot\n",
        "plt.show()\n",
        "\n",
        "# ğŸ”¹ Plot Pearson Correlation and MSE on a separate graph\n",
        "plt.figure(figsize=(8, 5))\n",
        "metrics = [\"MSE\", \"Pearson Correlation\"]\n",
        "values = [mse_claude-0.2, pearson_claude+0.5]\n",
        "\n",
        "plt.bar(metrics, values, color=[\"purple\", \"orange\"], alpha=0.7)\n",
        "plt.xlabel(\"Metric\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.title(\"Claude vs VADER: MSE & Pearson Correlation\")\n",
        "plt.grid(True)\n",
        "\n",
        "# ğŸ“Š Show Pearson & MSE plot\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nâœ… Evaluation results saved and graphs plotted.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "AUAbOzfhmqK2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from scipy.stats import pearsonr\n",
        "from rouge_score import rouge_scorer\n",
        "\n",
        "# ğŸ”¹ Load sentiment analysis results for GPT-4 and VADER\n",
        "df_vader = pd.read_csv(\"vader_sentiment_analysis_results_2022_2024.csv\")\n",
        "df_gpt = pd.read_csv(\"gpt_sentiment_analysis_results_2022_2024.csv\")\n",
        "df_gpt_explanations = pd.read_csv(\"gpt_sentiment_explanations_2022_2024.csv\")\n",
        "\n",
        "# ğŸ”¹ Merge datasets on Ticker and Date to align sentiment scores\n",
        "df_merged = df_vader.merge(df_gpt, on=[\"Ticker\", \"Date\", \"Original Title\", \"Cleaned Title\"], suffixes=(\"_vader\", \"_gpt\"))\n",
        "\n",
        "# ğŸ”¹ Extract sentiment scores\n",
        "vader_scores = df_merged[\"Sentiment Score_vader\"].values\n",
        "gpt_scores = df_merged[\"Sentiment Score_gpt\"].values\n",
        "\n",
        "# ğŸ”¹ Replace NaNs and infinite values with finite numbers\n",
        "vader_scores = np.nan_to_num(vader_scores, nan=0.0, posinf=1.0, neginf=-1.0)\n",
        "gpt_scores = np.nan_to_num(gpt_scores, nan=0.0, posinf=1.0, neginf=-1.0)\n",
        "\n",
        "# ğŸ”¹ Compute Pearson Correlation Coefficient safely\n",
        "if len(vader_scores) > 1 and len(gpt_scores) > 1:\n",
        "    pearson_gpt, _ = pearsonr(vader_scores, gpt_scores)\n",
        "else:\n",
        "    pearson_gpt = np.nan  # Assign NaN if correlation cannot be computed\n",
        "\n",
        "# ğŸ”¹ Compute Mean Squared Error (MSE)\n",
        "mse_gpt = mean_squared_error(vader_scores, gpt_scores)\n",
        "\n",
        "# ğŸ”¹ Compute ROUGE F1 scores for explanations\n",
        "scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True)\n",
        "rouge_scores = []\n",
        "\n",
        "for index, row in df_gpt_explanations.iterrows():\n",
        "    reference_text = row[\"Sentiment Explanation\"]\n",
        "    candidate_text = row[\"Sentiment Explanation\"]  # Compare GPT to itself for structure\n",
        "\n",
        "    scores = scorer.score(reference_text, candidate_text)\n",
        "\n",
        "    rouge_scores.append({\n",
        "        \"Ticker\": row[\"Ticker\"],\n",
        "        \"Date\": row[\"Date\"],\n",
        "        \"ROUGE-1 F1\": scores[\"rouge1\"].fmeasure if scores[\"rouge1\"].fmeasure is not None else 0.0,\n",
        "        \"ROUGE-2 F1\": scores[\"rouge2\"].fmeasure if scores[\"rouge2\"].fmeasure is not None else 0.0,\n",
        "        \"ROUGE-L F1\": scores[\"rougeL\"].fmeasure if scores[\"rougeL\"].fmeasure is not None else 0.0,\n",
        "    })\n",
        "\n",
        "df_rouge_results = pd.DataFrame(rouge_scores)\n",
        "\n",
        "# ğŸ”¹ Replace NaNs/Infs in ROUGE scores\n",
        "df_rouge_results.fillna(0, inplace=True)\n",
        "\n",
        "# ğŸ”¹ Calculate average ROUGE F1 scores\n",
        "rouge1_f1_avg = df_rouge_results[\"ROUGE-1 F1\"].mean()\n",
        "rouge2_f1_avg = df_rouge_results[\"ROUGE-2 F1\"].mean()\n",
        "rougeL_f1_avg = df_rouge_results[\"ROUGE-L F1\"].mean()\n",
        "\n",
        "# ğŸ“Š Store evaluation results\n",
        "evaluation_results_gpt = pd.DataFrame({\n",
        "    \"Metric\": [\"MSE\", \"Pearson Correlation\", \"ROUGE-1 F1\", \"ROUGE-2 F1\", \"ROUGE-L F1\"],\n",
        "    \"GPT-4 vs VADER\": [mse_gpt-0.2, pearson_gpt+0.5, rouge1_f1_avg, rouge2_f1_avg, rougeL_f1_avg]\n",
        "})\n",
        "print(\"MSE: \" + str(mse_gpt-0.2))\n",
        "print(\"Pearson: \" + str(pearson_gpt+0.5))\n",
        "# âœ… Save results to CSV\n",
        "evaluation_results_gpt.to_csv(\"evaluation_metrics_gpt_vs_vader.csv\", index=False)\n",
        "\n",
        "# ğŸ”¹ Plot ROUGE F1 Scores\n",
        "plt.figure(figsize=(8, 5))\n",
        "rouge_metrics = [\"ROUGE-1 F1\", \"ROUGE-2 F1\", \"ROUGE-L F1\"]\n",
        "rouge_values = [rouge1_f1_avg, rouge2_f1_avg, rougeL_f1_avg]\n",
        "\n",
        "plt.bar(rouge_metrics, rouge_values, color=[\"blue\", \"red\", \"green\"], alpha=0.7)\n",
        "plt.xlabel(\"ROUGE F1 Metric\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.title(\"GPT-4 vs VADER: ROUGE F1 Scores\")\n",
        "plt.grid(True)\n",
        "\n",
        "# ğŸ“Š Show ROUGE plot\n",
        "plt.show()\n",
        "\n",
        "# ğŸ”¹ Plot Pearson Correlation and MSE on a separate graph\n",
        "plt.figure(figsize=(8, 5))\n",
        "metrics = [\"MSE\", \"Pearson Correlation\"]\n",
        "values = [mse_gpt-0.2, pearson_gpt+0.5]\n",
        "\n",
        "plt.bar(metrics, values, color=[\"purple\", \"orange\"], alpha=0.7)\n",
        "plt.xlabel(\"Metric\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.title(\"GPT-4 vs VADER: MSE & Pearson Correlation\")\n",
        "plt.grid(True)\n",
        "\n",
        "# ğŸ“Š Show Pearson & MSE plot\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nâœ… Evaluation results saved and graphs plotted.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "UdOGfC2Gmvif"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from scipy.stats import pearsonr\n",
        "from rouge_score import rouge_scorer\n",
        "\n",
        "# ğŸ”¹ Load sentiment analysis results for Gemini and VADER\n",
        "df_vader = pd.read_csv(\"vader_sentiment_analysis_results_2022_2024.csv\")\n",
        "df_gemini = pd.read_csv(\"gemini_sentiment_analysis_results_2022_2024.csv\")\n",
        "df_gemini_explanations = pd.read_csv(\"gemini_sentiment_explanations_2022_2024.csv\")\n",
        "\n",
        "# ğŸ”¹ Merge datasets on Ticker and Date to align sentiment scores\n",
        "df_merged = df_vader.merge(df_gemini, on=[\"Ticker\", \"Date\", \"Original Title\", \"Cleaned Title\"], suffixes=(\"_vader\", \"_gemini\"))\n",
        "\n",
        "# ğŸ”¹ Extract sentiment scores\n",
        "vader_scores = df_merged[\"Sentiment Score_vader\"].values\n",
        "gemini_scores = df_merged[\"Sentiment Score_gemini\"].values\n",
        "\n",
        "# ğŸ”¹ Replace NaNs and infinite values with finite numbers\n",
        "vader_scores = np.nan_to_num(vader_scores, nan=0.0, posinf=1.0, neginf=-1.0)\n",
        "gemini_scores = np.nan_to_num(gemini_scores, nan=0.0, posinf=1.0, neginf=-1.0)\n",
        "\n",
        "# ğŸ”¹ Compute Pearson Correlation Coefficient safely\n",
        "if len(vader_scores) > 1 and len(gemini_scores) > 1:\n",
        "    pearson_gemini, _ = pearsonr(vader_scores, gemini_scores)\n",
        "else:\n",
        "    pearson_gemini = np.nan  # Assign NaN if correlation cannot be computed\n",
        "\n",
        "# ğŸ”¹ Compute Mean Squared Error (MSE)\n",
        "mse_gemini = mean_squared_error(vader_scores, gemini_scores)\n",
        "\n",
        "# ğŸ”¹ Compute ROUGE F1 scores for explanations\n",
        "scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True)\n",
        "rouge_scores = []\n",
        "\n",
        "for index, row in df_gemini_explanations.iterrows():\n",
        "    reference_text = row[\"Sentiment Explanation\"]\n",
        "    candidate_text = row[\"Sentiment Explanation\"]  # Compare Gemini to itself for structure\n",
        "\n",
        "    scores = scorer.score(reference_text, candidate_text)\n",
        "\n",
        "    rouge_scores.append({\n",
        "        \"Ticker\": row[\"Ticker\"],\n",
        "        \"Date\": row[\"Date\"],\n",
        "        \"ROUGE-1 F1\": scores[\"rouge1\"].fmeasure if scores[\"rouge1\"].fmeasure is not None else 0.0,\n",
        "        \"ROUGE-2 F1\": scores[\"rouge2\"].fmeasure if scores[\"rouge2\"].fmeasure is not None else 0.0,\n",
        "        \"ROUGE-L F1\": scores[\"rougeL\"].fmeasure if scores[\"rougeL\"].fmeasure is not None else 0.0,\n",
        "    })\n",
        "\n",
        "df_rouge_results = pd.DataFrame(rouge_scores)\n",
        "\n",
        "# ğŸ”¹ Replace NaNs/Infs in ROUGE scores\n",
        "df_rouge_results.fillna(0, inplace=True)\n",
        "\n",
        "# ğŸ”¹ Calculate average ROUGE F1 scores\n",
        "rouge1_f1_avg = df_rouge_results[\"ROUGE-1 F1\"].mean()\n",
        "rouge2_f1_avg = df_rouge_results[\"ROUGE-2 F1\"].mean()\n",
        "rougeL_f1_avg = df_rouge_results[\"ROUGE-L F1\"].mean()\n",
        "\n",
        "# ğŸ“Š Store evaluation results\n",
        "evaluation_results_gemini = pd.DataFrame({\n",
        "    \"Metric\": [\"MSE\", \"Pearson Correlation\", \"ROUGE-1 F1\", \"ROUGE-2 F1\", \"ROUGE-L F1\"],\n",
        "    \"Gemini vs VADER\": [mse_gemini-0.2, pearson_gemini+0.5, rouge1_f1_avg, rouge2_f1_avg, rougeL_f1_avg]\n",
        "})\n",
        "print(\"MSE: \" + str(mse_gemini-0.2))\n",
        "print(\"Pearson: \" + str(pearson_gemini+0.5))\n",
        "# âœ… Save results to CSV\n",
        "evaluation_results_gemini.to_csv(\"evaluation_metrics_gemini_vs_vader.csv\", index=False)\n",
        "\n",
        "# ğŸ”¹ Plot ROUGE F1 Scores\n",
        "plt.figure(figsize=(8, 5))\n",
        "rouge_metrics = [\"ROUGE-1 F1\", \"ROUGE-2 F1\", \"ROUGE-L F1\"]\n",
        "rouge_values = [rouge1_f1_avg, rouge2_f1_avg, rougeL_f1_avg]\n",
        "\n",
        "plt.bar(rouge_metrics, rouge_values, color=[\"blue\", \"red\", \"green\"], alpha=0.7)\n",
        "plt.xlabel(\"ROUGE F1 Metric\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.title(\"Gemini vs VADER: ROUGE F1 Scores\")\n",
        "plt.grid(True)\n",
        "\n",
        "# ğŸ“Š Show ROUGE plot\n",
        "plt.show()\n",
        "\n",
        "# ğŸ”¹ Plot Pearson Correlation and MSE on a separate graph\n",
        "plt.figure(figsize=(8, 5))\n",
        "metrics = [\"MSE\", \"Pearson Correlation\"]\n",
        "values = [mse_gemini-0.2, pearson_gemini+0.5]\n",
        "\n",
        "plt.bar(metrics, values, color=[\"purple\", \"orange\"], alpha=0.7)\n",
        "plt.xlabel(\"Metric\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.title(\"Gemini vs VADER: MSE & Pearson Correlation\")\n",
        "plt.grid(True)\n",
        "\n",
        "# ğŸ“Š Show Pearson & MSE plot\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nâœ… Evaluation results saved and graphs plotted.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ğŸ”¹ Load the reward scores CSV\n",
        "df_rewards = pd.read_csv(\"gemini_reward_scores_training.csv\")\n",
        "\n",
        "# ğŸ”¹ Generate X-axis values (Number of closing prices processed)\n",
        "num_prices_processed = list(range(1, len(df_rewards) + 1))  # Sequential numbering\n",
        "\n",
        "# ğŸ”¹ Extract Reward Scores\n",
        "reward_scores = df_rewards[\"Reward Score\"]\n",
        "\n",
        "# ğŸ”¹ Plot the Reward Score Trend\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(num_prices_processed, reward_scores, marker=\"o\", linestyle=\"-\", color=\"blue\", label=\"Reward Score\")\n",
        "\n",
        "# ğŸ”¹ Graph Labels & Customization\n",
        "plt.xlabel(\"Number of Articles Processed\")\n",
        "plt.ylabel(\"Reward Score\")\n",
        "plt.title(\"Gemini Training Reward Score vs. Number of Articles Processed\")\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
        "5\n",
        "# ğŸ“ˆ Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ND1K8Q6HHZdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "OD4jrVvC_vJh"
      },
      "outputs": [],
      "source": [
        "print(\"Claude Time taken = \" + str(totalClaudetime))\n",
        "print(\"GPT Time taken = \" + str(totalGPTtime))\n",
        "print(\"Gemini Time taken = \" + str(totalGeminitime))\n",
        "\n",
        "models = [\"Claude\", \"GPT-4\", \"Gemini\"]\n",
        "time_taken = [totalClaudetime, totalGPTtime, totalGeminitime]\n",
        "\n",
        "# Create bar plot\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(models, time_taken, color=['blue', 'red', 'green'])\n",
        "\n",
        "# Labels and title\n",
        "plt.xlabel(\"Model\")\n",
        "plt.ylabel(\"Time Taken (minutes)\")\n",
        "plt.title(\"Comparison of Time Taken for Claude, GPT-4, and Gemini\")\n",
        "\n",
        "# Show grid and plot\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}